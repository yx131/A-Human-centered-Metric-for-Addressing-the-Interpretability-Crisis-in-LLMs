{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "806fb4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, time, pickle\n",
    "import torch\n",
    "\n",
    "sys.path.insert(0, '../../Utils')\n",
    "from global_constants import gpu_device\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "from BERT_models import BERT_QNLI_MODEL\n",
    "\n",
    "from _utils import sample_random_glue_qnli, get_continuation_mapping, \\\n",
    "                    get_continuous_attributions, get_continuous_raw_inputs, \\\n",
    "                    collect_info_for_metric, save_info, download_HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b0e3ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/user/.cache/huggingface/datasets/glue/qnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e38f47ede28a473bac81a79919cd1cb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/user/.cache/huggingface/datasets/glue/qnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-e6d0a9c9270b6822.arrow\n",
      "Loading cached processed dataset at /home/user/.cache/huggingface/datasets/glue/qnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-c46c5e78d2bda808.arrow\n"
     ]
    }
   ],
   "source": [
    "qnli_data_raw, targets, idxs = sample_random_glue_qnli()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bca0a095",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERT_QNLI_MODEL()\n",
    "tokenizer = model.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e92a7d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define some containers to save some info\n",
    "model_out_list, raw_attr_list, conti_attr_list, raw_input_list = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad13b757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import InputXGradient\n",
    "from captum.attr import visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a26c83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x_gradient  = InputXGradient(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cc7ffbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_record(raw_datum, target): #raw_datum expected to be a tuple/list of 2 sentences\n",
    "    #tokenizer operations\n",
    "    tokenized = tokenizer(raw_datum, truncation=True, return_offsets_mapping=True)\n",
    "    offset_mappings = tokenized['offset_mapping']\n",
    "    #concatenate the two offset_mappings together because they are fed in together\n",
    "    conti_map = get_continuation_mapping(offset_mappings[0]) + get_continuation_mapping(offset_mappings[1])\n",
    "    #change the first input_id of the second sentence to be the last input_id of the 1st sentence (i.e. an [END] token))\n",
    "    tokenized_input_ids = tokenized['input_ids'][0] + \\\n",
    "                        [tokenized['input_ids'][1][i] if i != 0 else tokenized['input_ids'][0][-1] \\\n",
    "                         for i in range(len(tokenized['input_ids'][1]))]\n",
    "    input_ids = torch.tensor(tokenized_input_ids).unsqueeze(0).to(gpu_device)\n",
    "    detokenized = [t.replace('#', '') for t in tokenizer.convert_ids_to_tokens(input_ids[0])]\n",
    "    \n",
    "    #feeding input forward \n",
    "    input_emb = model.get_embeddings(input_ids)\n",
    "    pred_prob = model(input_emb).item()\n",
    "\n",
    "     #categorizing results\n",
    "    pred_class = 'No Entailment' if pred_prob < 0.5 else 'Entailment' \n",
    "    true_class = 'No Entailment' if target < 0.5 else 'Entailment' \n",
    "    \n",
    "    #attribution algorithm working\n",
    "    attribution = input_x_gradient.attribute(input_emb)\n",
    "    word_attributions = attribution.squeeze(0).sum(dim=1)\n",
    "#     word_attributions = attr_normalizing_func(word_attributions)\n",
    "    word_attributions /= torch.norm(word_attributions)\n",
    "    attr_score = torch.sum(word_attributions)\n",
    "    attr_class = 'No Entailment' if attr_score < 0.5 else 'Entailment'\n",
    "    convergence_score = None\n",
    "    \n",
    "    \n",
    "#     #re-organizing tensors and arrays because words get split down\n",
    "    conti_attr = get_continuous_attributions(conti_map, word_attributions)\n",
    "    raw_input = get_continuous_raw_inputs(conti_map, detokenized)\n",
    "\n",
    "#     print(f'word attributions {word_attributions}')\n",
    "    print(f'pred_prob {pred_prob}')\n",
    "#     print(f'pred_class {pred_class}')\n",
    "#     print(f'true_class {true_class}')\n",
    "#     print(f'attribution {attribution}')\n",
    "#     print(f'attr_class {attr_class}')\n",
    "#     print(f'attr_score {attr_score}')\n",
    "#     print(f'raw_input {raw_input}')\n",
    "\n",
    "        \n",
    "# #     collect info for metrics later\n",
    "    collect_info_for_metric(model_out_list, pred_prob, raw_attr_list, attribution, conti_attr_list, conti_attr, raw_input_list, raw_input)\n",
    "        \n",
    "    \n",
    "    visual_record = visualization.VisualizationDataRecord(word_attributions=conti_attr,\n",
    "                                                         pred_prob=pred_prob,\n",
    "                                                         pred_class=pred_class,\n",
    "                                                         true_class=true_class,\n",
    "                                                         attr_class=attr_class,\n",
    "                                                         attr_score=attr_score,\n",
    "                                                         raw_input_ids=raw_input,\n",
    "                                                         convergence_score=convergence_score)\n",
    "        \n",
    "        \n",
    "    return visual_record\n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0321c07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw datum: ['What would a teacher assess the levels of a student on?', 'For example, an experienced teacher and parent described the place of a teacher in learning as follows: \"The real bulk of learning takes place in self-study and problem solving with a lot of feedback around that loop.']\n",
      "GT target: 0\n",
      "word attr tensor([-2.4683e-03, -3.1340e-02, -2.3063e-02,  8.5846e-02, -1.3606e-01,\n",
      "        -5.6050e-02,  1.7835e-02, -1.2950e-01, -2.3075e-02,  2.8824e-02,\n",
      "         7.9517e-02, -1.0998e-01, -3.8824e-01,  1.3514e-01,  2.0214e-01,\n",
      "        -8.6794e-02, -4.3814e-02, -8.9594e-02, -4.3959e-02, -7.5047e-03,\n",
      "        -1.7923e-01, -5.6481e-05, -8.5562e-02,  1.7122e-01,  4.3536e-02,\n",
      "        -2.9848e-01,  9.6469e-02, -8.5471e-03, -6.3962e-02,  2.2039e-02,\n",
      "        -1.4393e-01,  3.8258e-02, -5.2077e-02, -2.8391e-03,  9.6105e-02,\n",
      "        -4.0598e-04,  4.7579e-02,  6.4932e-03, -1.4074e-01,  3.7176e-02,\n",
      "         1.5523e-01,  1.5875e-02, -5.0587e-02,  1.7638e-01,  7.4474e-03,\n",
      "        -6.2674e-03,  1.5195e-01,  1.2051e-01,  1.1640e-01,  4.2975e-02,\n",
      "         7.2501e-03,  8.9933e-02,  5.1321e-02,  3.9967e-02,  1.8308e-01,\n",
      "         7.9316e-02,  1.5876e-01,  9.4657e-02, -5.2389e-01], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(-0.0025, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0313, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0231, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0858, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1361, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0561, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0178, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1295, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0231, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0288, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0795, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2491, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1351, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2021, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0868, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0667, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0440, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0075, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1792, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-5.6481e-05, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0856, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1712, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0435, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2985, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0965, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0085, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0640, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0220, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1439, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0383, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0275, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0478, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0476, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0065, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1407, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0372, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1552, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0159, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0506, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0428, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1520, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1205, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1164, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0430, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0073, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0899, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0513, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0400, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1831, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0793, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.5239, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'what', 'would', 'a', 'teacher', 'assess', 'the', 'levels', 'of', 'a', 'student', 'on', '?', '[SEP]', '[SEP]', 'for', 'example', ',', 'an', 'experienced', 'teacher', 'and', 'parent', 'described', 'the', 'place', 'of', 'a', 'teacher', 'in', 'learning', 'as', 'follows', ':', '\"', 'the', 'real', 'bulk', 'of', 'learning', 'takes', 'place', 'in', 'self', '-', 'study', 'and', 'problem', 'solving', 'with', 'a', 'lot', 'of', 'feedback', 'around', 'that', 'loop', '.', '[SEP]']\n",
      "len conti_raw 52\n",
      "conti_raw ['[CLS]', 'what', 'would', 'a', 'teacher', 'assess', 'the', 'levels', 'of', 'a', 'student', 'on?', '[SEP]', '[SEP]', 'for', 'example,', 'an', 'experienced', 'teacher', 'and', 'parent', 'described', 'the', 'place', 'of', 'a', 'teacher', 'in', 'learning', 'as', 'follows:', '\"the', 'real', 'bulk', 'of', 'learning', 'takes', 'place', 'in', 'self-study', 'and', 'problem', 'solving', 'with', 'a', 'lot', 'of', 'feedback', 'around', 'that', 'loop.', '[SEP]']\n",
      "pred_prob 0.6311678290367126\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.63)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>-0.13</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> what                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> would                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> teacher                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> assess                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> levels                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> student                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> on?                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> for                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> example,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> an                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> experienced                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> teacher                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> parent                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> described                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> place                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> teacher                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> learning                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> follows:                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> \"the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> real                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> bulk                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> learning                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> takes                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> place                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> self-study                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> problem                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> solving                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> with                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> lot                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> feedback                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> around                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> that                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> loop.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 80%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['What company created Doctor Who?', 'Who character by BBC Television in the early 1960s, a myriad of stories have been published about Doctor Who, in different media: apart from the actual television episodes that continue to be produced by the BBC, there have also been novels, comics, short stories, audio books, radio plays, interactive video games, game books, webcasts, DVD extras, and even stage performances.']\n",
      "GT target: 1\n",
      "word attr tensor([-1.7057e-01, -2.7380e-01,  1.2487e-01,  6.1822e-02,  5.1403e-02,\n",
      "        -3.3132e-01, -7.3765e-01, -5.6606e-03,  4.4995e-02,  2.2840e-01,\n",
      "         1.0656e-02, -9.7153e-02, -3.0301e-02, -4.7757e-02,  1.4598e-02,\n",
      "         2.5302e-02, -2.3449e-02,  1.9925e-02,  2.3582e-03,  3.9034e-02,\n",
      "         7.1666e-02, -2.7007e-02,  2.8336e-02, -5.9740e-02,  1.0856e-02,\n",
      "         4.5907e-02, -3.5246e-02,  4.0771e-02, -1.3713e-02, -4.4710e-02,\n",
      "         3.0427e-02, -1.4392e-02,  8.0305e-02,  1.3219e-01, -3.2441e-02,\n",
      "        -4.9899e-03,  4.0614e-02, -1.3866e-02,  3.6947e-02,  3.8824e-03,\n",
      "        -3.4137e-02,  3.9507e-03, -2.7472e-02, -2.8185e-02,  6.6269e-02,\n",
      "         4.3087e-02, -4.5111e-02, -2.5748e-02,  5.2830e-02, -4.7246e-03,\n",
      "         4.6674e-03,  3.5584e-02, -1.9490e-02, -2.3218e-02, -6.8336e-05,\n",
      "        -5.0442e-02, -1.0887e-02,  2.3130e-02, -3.8163e-02, -1.1095e-02,\n",
      "         1.1199e-01,  2.0449e-02,  3.1029e-03,  6.8175e-02,  4.2386e-02,\n",
      "         5.6570e-02,  5.4264e-02,  2.8760e-02,  7.2897e-03, -3.8719e-02,\n",
      "         2.9923e-02,  7.7063e-03, -3.8264e-02,  4.0120e-02, -2.8931e-03,\n",
      "         4.8052e-02, -2.6171e-02, -7.2082e-02,  3.4528e-02,  4.7154e-02,\n",
      "         3.6618e-02, -9.4408e-03,  6.5279e-02,  8.8886e-02, -3.2313e-02,\n",
      "        -1.5192e-01], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(-0.1706, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2738, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1249, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0618, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0514, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.5345, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0057, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0450, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2284, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0107, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0972, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0303, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0478, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0146, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0253, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0234, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0111, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0390, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0717, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0270, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0283, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0597, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0109, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0459, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0352, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0408, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0292, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0304, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0144, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1062, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0324, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0050, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0406, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0139, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0369, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0039, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0341, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0040, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0275, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0282, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0663, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0431, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0451, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0135, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0047, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0047, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0356, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0195, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0116, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0307, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0231, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0246, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1120, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0118, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0682, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0495, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0543, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0288, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0157, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0299, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0153, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0721, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0408, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0366, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0094, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0653, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0283, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1519, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'what', 'company', 'created', 'doctor', 'who', '?', '[SEP]', '[SEP]', 'who', 'character', 'by', 'bbc', 'television', 'in', 'the', 'early', '1960s', ',', 'a', 'myriad', 'of', 'stories', 'have', 'been', 'published', 'about', 'doctor', 'who', ',', 'in', 'different', 'media', ':', 'apart', 'from', 'the', 'actual', 'television', 'episodes', 'that', 'continue', 'to', 'be', 'produced', 'by', 'the', 'bbc', ',', 'there', 'have', 'also', 'been', 'novels', ',', 'comics', ',', 'short', 'stories', ',', 'audio', 'books', ',', 'radio', 'plays', ',', 'interactive', 'video', 'games', ',', 'game', 'books', ',', 'web', 'cast', 's', ',', 'dvd', 'extras', ',', 'and', 'even', 'stage', 'performances', '.', '[SEP]']\n",
      "len conti_raw 69\n",
      "conti_raw ['[CLS]', 'what', 'company', 'created', 'doctor', 'who?', '[SEP]', '[SEP]', 'who', 'character', 'by', 'bbc', 'television', 'in', 'the', 'early', '1960s,', 'a', 'myriad', 'of', 'stories', 'have', 'been', 'published', 'about', 'doctor', 'who,', 'in', 'different', 'media:', 'apart', 'from', 'the', 'actual', 'television', 'episodes', 'that', 'continue', 'to', 'be', 'produced', 'by', 'the', 'bbc,', 'there', 'have', 'also', 'been', 'novels,', 'comics,', 'short', 'stories,', 'audio', 'books,', 'radio', 'plays,', 'interactive', 'video', 'games,', 'game', 'books,', 'webcasts,', 'dvd', 'extras,', 'and', 'even', 'stage', 'performances.', '[SEP]']\n",
      "pred_prob 0.7619203925132751\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.76)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>-0.49</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> what                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> company                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> created                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> doctor                    </font></mark><mark style=\"background-color: hsl(0, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> who?                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> who                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> character                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> by                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> bbc                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> television                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> early                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 1960s,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> myriad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> stories                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> have                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> been                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> published                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> about                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> doctor                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> who,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> different                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> media:                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> apart                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> from                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> actual                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> television                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> episodes                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> that                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> continue                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> be                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> produced                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> by                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> bbc,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> there                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> have                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> also                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> been                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> novels,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> comics,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> short                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> stories,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> audio                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> books,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> radio                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> plays,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> interactive                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> video                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> games,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> game                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> books,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> webcasts,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> dvd                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> extras,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> even                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> stage                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> performances.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['What was the name of the Media Day event for Super Bowl 50?', \"The game's media day, which was typically held on the Tuesday afternoon prior to the game, was moved to the Monday evening and re-branded as Super Bowl Opening Night.\"]\n",
      "GT target: 1\n",
      "word attr tensor([-0.2020, -0.2829,  0.0656, -0.1091,  0.0100, -0.1244, -0.0514,  0.1761,\n",
      "         0.0338, -0.1339,  0.0546, -0.0461, -0.0038,  0.2178, -0.2719,  0.2178,\n",
      "         0.4261, -0.1660, -0.0421,  0.0157, -0.0588,  0.2790,  0.0217,  0.0189,\n",
      "        -0.0676, -0.0232,  0.1329,  0.0023,  0.0173, -0.0405,  0.0845, -0.0151,\n",
      "         0.1170, -0.0334, -0.0406, -0.0522,  0.0141, -0.0215, -0.0108,  0.0083,\n",
      "         0.0238,  0.0175,  0.0066,  0.0165,  0.2044,  0.0414,  0.3047, -0.0781,\n",
      "         0.2325, -0.0060, -0.0011,  0.0497,  0.2721, -0.0341], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(-0.2020, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2829, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0656, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1091, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0100, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1244, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0514, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1761, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0338, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1339, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0546, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0461, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0038, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0270, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.2178, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.4261, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1660, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0360, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.2790, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0203, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0676, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0232, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1329, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0023, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0173, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0405, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0845, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0151, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1170, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0334, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0406, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0190, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0215, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0108, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0083, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0238, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0175, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0066, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0165, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2138, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0781, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2325, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0060, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0011, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1609, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0341, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'what', 'was', 'the', 'name', 'of', 'the', 'media', 'day', 'event', 'for', 'super', 'bowl', '50', '?', '[SEP]', '[SEP]', 'the', 'game', \"'\", 's', 'media', 'day', ',', 'which', 'was', 'typically', 'held', 'on', 'the', 'tuesday', 'afternoon', 'prior', 'to', 'the', 'game', ',', 'was', 'moved', 'to', 'the', 'monday', 'evening', 'and', 're', '-', 'branded', 'as', 'super', 'bowl', 'opening', 'night', '.', '[SEP]']\n",
      "len conti_raw 46\n",
      "conti_raw ['[CLS]', 'what', 'was', 'the', 'name', 'of', 'the', 'media', 'day', 'event', 'for', 'super', 'bowl', '50?', '[SEP]', '[SEP]', 'the', \"game's\", 'media', 'day,', 'which', 'was', 'typically', 'held', 'on', 'the', 'tuesday', 'afternoon', 'prior', 'to', 'the', 'game,', 'was', 'moved', 'to', 'the', 'monday', 'evening', 'and', 're-branded', 'as', 'super', 'bowl', 'opening', 'night.', '[SEP]']\n",
      "pred_prob 0.7368832230567932\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.74)</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>1.17</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> what                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> name                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> media                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> day                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> event                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> for                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> super                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> bowl                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 50?                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> game's                    </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> media                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> day,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> which                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> typically                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> held                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> on                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> tuesday                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> afternoon                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> prior                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> game,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> moved                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> monday                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> evening                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> re-branded                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> super                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> bowl                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> opening                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> night.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['How many Doctor Who soundtracks have been released since 2005?', 'The fourth was released on 4 October 2010 as a two disc special edition and contained music from the 2008–2010 specials (The Next Doctor to End of Time Part 2).']\n",
      "GT target: 0\n",
      "word attr tensor([-1.9108e-01, -1.7691e-01,  8.3361e-02,  4.7193e-02, -7.7874e-02,\n",
      "        -2.2740e-01,  6.2765e-02,  1.6235e-01,  2.0815e-02, -1.2046e-01,\n",
      "         9.1304e-02, -2.1883e-01, -1.3366e-01, -4.5890e-01,  5.2475e-01,\n",
      "         7.2280e-02,  5.2501e-03, -1.3569e-01,  7.3141e-03, -1.1589e-02,\n",
      "         1.1378e-02,  3.4431e-02,  4.6928e-02,  3.9236e-02,  8.7281e-02,\n",
      "         1.7245e-04,  5.6957e-02,  1.5352e-01,  8.5024e-03,  6.9581e-02,\n",
      "        -2.0457e-01,  1.3358e-02, -2.1178e-02, -3.7913e-02,  1.0332e-01,\n",
      "         1.6623e-02, -1.6678e-01, -2.0072e-02,  1.4166e-01,  2.5372e-01,\n",
      "        -6.2432e-02,  3.3829e-02,  5.0872e-02, -1.1545e-02,  1.7290e-02,\n",
      "        -1.8756e-02,  4.5824e-02,  8.4401e-04,  7.6454e-02, -8.8414e-02],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(-0.1911, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1769, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0834, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0472, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0779, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2274, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0628, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1623, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0208, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1205, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0638, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1337, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.4589, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.5247, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0723, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0053, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1357, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0073, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0116, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0114, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0344, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0469, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0392, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0873, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0002, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0570, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1535, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0085, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0696, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2046, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0134, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0212, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0247, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1668, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0608, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.2537, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0624, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0338, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0509, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0115, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0173, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0188, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0499, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0884, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'how', 'many', 'doctor', 'who', 'soundtracks', 'have', 'been', 'released', 'since', '2005', '?', '[SEP]', '[SEP]', 'the', 'fourth', 'was', 'released', 'on', '4', 'october', '2010', 'as', 'a', 'two', 'disc', 'special', 'edition', 'and', 'contained', 'music', 'from', 'the', '2008', '–', '2010', 'specials', '(', 'the', 'next', 'doctor', 'to', 'end', 'of', 'time', 'part', '2', ')', '.', '[SEP]']\n",
      "len conti_raw 44\n",
      "conti_raw ['[CLS]', 'how', 'many', 'doctor', 'who', 'soundtracks', 'have', 'been', 'released', 'since', '2005?', '[SEP]', '[SEP]', 'the', 'fourth', 'was', 'released', 'on', '4', 'october', '2010', 'as', 'a', 'two', 'disc', 'special', 'edition', 'and', 'contained', 'music', 'from', 'the', '2008–2010', 'specials', '(the', 'next', 'doctor', 'to', 'end', 'of', 'time', 'part', '2).', '[SEP]']\n",
      "pred_prob 0.8182130455970764\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.82)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>-0.04</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> how                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> many                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> doctor                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> who                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> soundtracks                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> have                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> been                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> released                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> since                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 2005?                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 82%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 74%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> fourth                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> released                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> on                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 4                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> october                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 2010                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> two                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> disc                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> special                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> edition                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> contained                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> music                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> from                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 2008–2010                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> specials                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> (the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> next                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> doctor                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> end                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> time                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> part                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 2).                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: [\"What is the name of the country's longest continuously running student film society?\", 'Students at the University of Chicago run over 400 clubs and organizations known as Recognized Student Organizations (RSOs).']\n",
      "GT target: 0\n",
      "word attr tensor([ 0.0126, -0.3132, -0.0695, -0.0810,  0.0227, -0.0198,  0.0934, -0.0121,\n",
      "        -0.1446,  0.1678,  0.2868,  0.1358, -0.0951,  0.2214,  0.2305, -0.0305,\n",
      "         0.0703,  0.1554,  0.0117,  0.0164, -0.1320,  0.0468,  0.1543, -0.2606,\n",
      "        -0.3230,  0.1233, -0.1689, -0.2971,  0.0040,  0.0560,  0.0109,  0.0253,\n",
      "         0.0285,  0.1939,  0.2393, -0.0639, -0.1067,  0.0162,  0.1622, -0.2350,\n",
      "         0.1876,  0.0972], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(0.0126, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.3132, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0695, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0810, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0227, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0198, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0934, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0447, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.2868, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1358, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0951, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2214, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2305, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0199, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1554, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0117, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0164, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1320, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0468, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1543, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2606, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.3230, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1233, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1689, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2971, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0040, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0560, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0109, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0253, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0285, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1939, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2393, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0639, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0497, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0972, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'what', 'is', 'the', 'name', 'of', 'the', 'country', \"'\", 's', 'longest', 'continuously', 'running', 'student', 'film', 'society', '?', '[SEP]', '[SEP]', 'students', 'at', 'the', 'university', 'of', 'chicago', 'run', 'over', '400', 'clubs', 'and', 'organizations', 'known', 'as', 'recognized', 'student', 'organizations', '(', 'rs', 'os', ')', '.', '[SEP]']\n",
      "len conti_raw 35\n",
      "conti_raw ['[CLS]', 'what', 'is', 'the', 'name', 'of', 'the', \"country's\", 'longest', 'continuously', 'running', 'student', 'film', 'society?', '[SEP]', '[SEP]', 'students', 'at', 'the', 'university', 'of', 'chicago', 'run', 'over', '400', 'clubs', 'and', 'organizations', 'known', 'as', 'recognized', 'student', 'organizations', '(rsos).', '[SEP]']\n",
      "pred_prob 0.9198501110076904\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.92)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>0.42</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> what                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> name                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> country's                    </font></mark><mark style=\"background-color: hsl(120, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> longest                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> continuously                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> running                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> student                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> film                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> society?                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> students                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> at                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> university                    </font></mark><mark style=\"background-color: hsl(0, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> chicago                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> run                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> over                    </font></mark><mark style=\"background-color: hsl(0, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 400                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> clubs                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> organizations                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> known                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> recognized                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> student                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> organizations                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> (rsos).                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['How many times has the South Florida/Miami area hosted the Super Bowl?', 'The South Florida/Miami area has previously hosted the event 10 times (tied for most with New Orleans), with the most recent one being Super Bowl XLIV in 2010.']\n",
      "GT target: 1\n",
      "word attr tensor([-2.5832e-01, -1.5068e-01,  1.1032e-01,  1.3527e-01,  2.4947e-02,\n",
      "         9.5896e-03,  2.0076e-02, -3.5227e-02, -3.3597e-02, -1.3858e-01,\n",
      "         1.6788e-01, -1.6568e-02,  1.9814e-02,  5.3567e-02, -1.0505e-01,\n",
      "        -3.8594e-01,  1.9672e-01,  5.6277e-02, -2.1089e-02,  3.8273e-02,\n",
      "         5.4735e-03, -5.0711e-02, -8.8931e-02,  7.4081e-02,  1.6816e-04,\n",
      "        -4.5149e-02,  6.5820e-02, -4.2931e-02,  1.1991e-01,  1.9004e-01,\n",
      "         9.6079e-02,  4.9338e-02, -1.2425e-01,  9.2541e-03,  1.4128e-02,\n",
      "        -8.5200e-02,  2.4155e-02,  2.5358e-02,  3.9218e-02,  1.5199e-01,\n",
      "         5.9571e-03, -2.6466e-02, -4.2269e-02,  1.0241e-02,  1.0915e-03,\n",
      "         2.6983e-02,  2.4373e-01, -4.5965e-02, -1.1478e-01, -4.8658e-02,\n",
      "        -5.7566e-02, -1.9422e-02,  5.8169e-01, -2.5344e-01], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(-0.2583, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1507, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1103, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1353, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0249, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0096, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0201, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0865, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1679, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0166, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0198, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0536, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2455, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1967, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0563, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0211, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0383, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0558, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0741, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0002, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0451, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0658, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0429, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1199, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1900, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0961, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0375, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0093, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0141, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0852, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0242, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0060, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0265, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0423, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0102, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0011, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0270, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2437, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0460, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0817, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0576, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2811, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.2534, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'how', 'many', 'times', 'has', 'the', 'south', 'florida', '/', 'miami', 'area', 'hosted', 'the', 'super', 'bowl', '?', '[SEP]', '[SEP]', 'the', 'south', 'florida', '/', 'miami', 'area', 'has', 'previously', 'hosted', 'the', 'event', '10', 'times', '(', 'tied', 'for', 'most', 'with', 'new', 'orleans', ')', ',', 'with', 'the', 'most', 'recent', 'one', 'being', 'super', 'bowl', 'xl', 'iv', 'in', '2010', '.', '[SEP]']\n",
      "len conti_raw 44\n",
      "conti_raw ['[CLS]', 'how', 'many', 'times', 'has', 'the', 'south', 'florida/miami', 'area', 'hosted', 'the', 'super', 'bowl?', '[SEP]', '[SEP]', 'the', 'south', 'florida/miami', 'area', 'has', 'previously', 'hosted', 'the', 'event', '10', 'times', '(tied', 'for', 'most', 'with', 'new', 'orleans),', 'with', 'the', 'most', 'recent', 'one', 'being', 'super', 'bowl', 'xliv', 'in', '2010.', '[SEP]']\n",
      "pred_prob 0.8666946887969971\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.87)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>0.38</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> how                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> many                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> times                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> has                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> south                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> florida/miami                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> area                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hosted                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> super                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> bowl?                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> south                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> florida/miami                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> area                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> has                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> previously                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hosted                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> event                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 10                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> times                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> (tied                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> for                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> most                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> with                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> new                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> orleans),                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> with                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> most                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> recent                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> one                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> being                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> super                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> bowl                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> xliv                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 2010.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['What is different about Paulinella chromatophora?', 'It is not clear whether that symbiont is closely related to the ancestral chloroplast of other eukaryotes.']\n",
      "GT target: 0\n",
      "word attr tensor([-0.2071, -0.1002,  0.0036,  0.0449, -0.1208,  0.0865,  0.1134,  0.1135,\n",
      "         0.0168,  0.0638,  0.0871,  0.1534,  0.0918, -0.4616, -0.4102,  0.0451,\n",
      "         0.0368,  0.1644, -0.0117, -0.1638,  0.0111, -0.0874,  0.0341, -0.0148,\n",
      "         0.0137,  0.1680,  0.0937,  0.2332, -0.0813, -0.1377,  0.0395,  0.0082,\n",
      "         0.0018,  0.0713, -0.0518,  0.0407, -0.0027,  0.0242, -0.0235, -0.2127,\n",
      "         0.1681,  0.0982,  0.0338,  0.4380], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(-0.2071, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1002, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0036, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0449, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1208, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1000, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1032, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.4616, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.4102, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0451, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0368, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1644, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0117, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1638, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0111, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0035, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1680, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0937, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2332, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0813, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1377, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0395, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0169, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0027, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0242, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0477, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.4380, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'what', 'is', 'different', 'about', 'pauline', 'lla', 'ch', 'rom', 'ato', 'ph', 'ora', '?', '[SEP]', '[SEP]', 'it', 'is', 'not', 'clear', 'whether', 'that', 'sy', 'mb', 'ion', 't', 'is', 'closely', 'related', 'to', 'the', 'ancestral', 'ch', 'lor', 'op', 'las', 't', 'of', 'other', 'eu', 'kar', 'yo', 'tes', '.', '[SEP]']\n",
      "len conti_raw 27\n",
      "conti_raw ['[CLS]', 'what', 'is', 'different', 'about', 'paulinella', 'chromatophora?', '[SEP]', '[SEP]', 'it', 'is', 'not', 'clear', 'whether', 'that', 'symbiont', 'is', 'closely', 'related', 'to', 'the', 'ancestral', 'chloroplast', 'of', 'other', 'eukaryotes.', '[SEP]']\n",
      "pred_prob 0.5214384198188782\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.52)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>0.41</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> what                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> different                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> about                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> paulinella                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> chromatophora?                    </font></mark><mark style=\"background-color: hsl(0, 75%, 82%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> it                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> not                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> clear                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> whether                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> that                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> symbiont                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> closely                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> related                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ancestral                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> chloroplast                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> other                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> eukaryotes.                    </font></mark><mark style=\"background-color: hsl(120, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: [\"Who played Doctor Who on stage in the 70's?\", 'Doctor Who has appeared on stage numerous times.']\n",
      "GT target: 0\n",
      "word attr tensor([-0.1014,  0.0435,  0.0941, -0.2531, -0.0376,  0.1163,  0.0994, -0.0107,\n",
      "        -0.1060,  0.1986,  0.1330, -0.0548, -0.4703,  0.0266,  0.1678,  0.4352,\n",
      "        -0.4707, -0.2275,  0.0232, -0.0858,  0.0396,  0.1636,  0.1811,  0.1441,\n",
      "         0.1267], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(-0.1014, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0435, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0941, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2531, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0376, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1163, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0994, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0107, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1060, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2074, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0266, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1678, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.4352, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.4707, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2275, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0232, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0858, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0396, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1636, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1626, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1267, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'who', 'played', 'doctor', 'who', 'on', 'stage', 'in', 'the', '70', \"'\", 's', '?', '[SEP]', '[SEP]', 'doctor', 'who', 'has', 'appeared', 'on', 'stage', 'numerous', 'times', '.', '[SEP]']\n",
      "len conti_raw 21\n",
      "conti_raw ['[CLS]', 'who', 'played', 'doctor', 'who', 'on', 'stage', 'in', 'the', \"70's?\", '[SEP]', '[SEP]', 'doctor', 'who', 'has', 'appeared', 'on', 'stage', 'numerous', 'times.', '[SEP]']\n",
      "pred_prob 0.8973642587661743\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.90)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>0.17</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> who                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> played                    </font></mark><mark style=\"background-color: hsl(0, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> doctor                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> who                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> on                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> stage                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 70's?                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> doctor                    </font></mark><mark style=\"background-color: hsl(0, 75%, 82%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> who                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> has                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> appeared                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> on                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> stage                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> numerous                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> times.                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['Who do clinical pharmacists work with much of the time?', 'Clinical pharmacists often collaborate with physicians and other healthcare professionals to improve pharmaceutical care.']\n",
      "GT target: 1\n",
      "word attr tensor([ 0.0313, -0.1337,  0.0106,  0.1186,  0.0776, -0.1091,  0.0408, -0.1767,\n",
      "        -0.0325,  0.0649,  0.1145, -0.0307, -0.0508, -0.0248, -0.6156, -0.0553,\n",
      "        -0.1918,  0.1969,  0.0723, -0.0440,  0.1862, -0.1578, -0.1914,  0.1802,\n",
      "         0.1891,  0.0307,  0.0585,  0.0936,  0.2202,  0.2019,  0.1645,  0.0914,\n",
      "        -0.2133,  0.0131,  0.1835, -0.2174], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(0.0313, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1337, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0106, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1186, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0821, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0325, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0649, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1145, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0307, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0508, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.3202, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0553, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1918, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1969, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0288, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1914, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1802, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1891, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0307, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0585, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0936, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2202, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2019, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1645, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0914, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2133, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0983, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.2174, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'who', 'do', 'clinical', 'ph', 'arm', 'ac', 'ists', 'work', 'with', 'much', 'of', 'the', 'time', '?', '[SEP]', '[SEP]', 'clinical', 'ph', 'arm', 'ac', 'ists', 'often', 'collaborate', 'with', 'physicians', 'and', 'other', 'healthcare', 'professionals', 'to', 'improve', 'pharmaceutical', 'care', '.', '[SEP]']\n",
      "len conti_raw 28\n",
      "conti_raw ['[CLS]', 'who', 'do', 'clinical', 'pharmacists', 'work', 'with', 'much', 'of', 'the', 'time?', '[SEP]', '[SEP]', 'clinical', 'pharmacists', 'often', 'collaborate', 'with', 'physicians', 'and', 'other', 'healthcare', 'professionals', 'to', 'improve', 'pharmaceutical', 'care.', '[SEP]']\n",
      "pred_prob 0.8218711018562317\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.82)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>0.10</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> who                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> do                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> clinical                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pharmacists                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> work                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> with                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> much                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> time?                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> clinical                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pharmacists                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> often                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> collaborate                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> with                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> physicians                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> other                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> healthcare                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> professionals                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> improve                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pharmaceutical                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> care.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['In which county does Jacksonville reside?', 'It is the county seat of Duval County, with which the city government consolidated in 1968.']\n",
      "GT target: 1\n",
      "word attr tensor([-0.0617, -0.1926, -0.0285,  0.0939, -0.0175, -0.2734, -0.1889, -0.3423,\n",
      "         0.2991,  0.3894, -0.1564, -0.2127,  0.0882,  0.1633, -0.0122,  0.0925,\n",
      "        -0.1932,  0.1306,  0.2787,  0.1697,  0.2116,  0.0389,  0.0160,  0.2719,\n",
      "        -0.1148,  0.0347,  0.1223,  0.1866, -0.1490], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(-0.0617, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1926, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0285, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0939, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0175, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2734, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2656, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.2991, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.3894, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1564, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2127, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0882, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1633, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0122, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0925, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1932, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2046, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1697, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2116, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0389, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0160, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2719, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1148, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0347, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1544, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1490, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'in', 'which', 'county', 'does', 'jacksonville', 'reside', '?', '[SEP]', '[SEP]', 'it', 'is', 'the', 'county', 'seat', 'of', 'duval', 'county', ',', 'with', 'which', 'the', 'city', 'government', 'consolidated', 'in', '1968', '.', '[SEP]']\n",
      "len conti_raw 26\n",
      "conti_raw ['[CLS]', 'in', 'which', 'county', 'does', 'jacksonville', 'reside?', '[SEP]', '[SEP]', 'it', 'is', 'the', 'county', 'seat', 'of', 'duval', 'county,', 'with', 'which', 'the', 'city', 'government', 'consolidated', 'in', '1968.', '[SEP]']\n",
      "pred_prob 0.8931249976158142\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.89)</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>0.64</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> which                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> county                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> does                    </font></mark><mark style=\"background-color: hsl(0, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> jacksonville                    </font></mark><mark style=\"background-color: hsl(0, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> reside?                    </font></mark><mark style=\"background-color: hsl(120, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 81%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> it                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> county                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> seat                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> duval                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> county,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> with                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> which                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> city                    </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> government                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> consolidated                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 1968.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['Who did Genghis Khan charge with finding and punishing the Shah?', 'Genghis Khan ordered the wholesale massacre of many of the civilians, enslaved the rest of the population and executed Inalchuq by pouring molten silver into his ears and eyes, as retribution for his actions.']\n",
      "GT target: 0\n",
      "word attr tensor([-2.5755e-02,  3.2622e-01, -3.8716e-02,  1.7802e-01, -6.8366e-02,\n",
      "         7.1852e-02, -2.5531e-01,  4.3367e-02,  7.6064e-02,  1.2304e-01,\n",
      "         5.2284e-02, -3.1993e-01, -5.4337e-02, -7.8955e-02, -8.1927e-02,\n",
      "        -1.9503e-01, -2.3202e-01, -3.8529e-01,  1.7719e-01, -6.7656e-02,\n",
      "        -1.5182e-02, -1.1228e-01, -1.5378e-01, -1.0520e-01,  3.5301e-04,\n",
      "         2.4123e-02,  2.8695e-02,  3.8878e-02,  1.5767e-02, -4.4685e-02,\n",
      "        -7.8043e-02,  2.2120e-03,  1.2672e-01,  9.8564e-02, -5.8684e-02,\n",
      "         5.1315e-03,  3.7934e-02, -7.3597e-03,  8.2763e-02,  1.3563e-01,\n",
      "        -5.7578e-02, -6.7094e-03,  1.6072e-01,  1.5600e-01,  9.8901e-02,\n",
      "         1.6225e-01,  8.5160e-03,  1.9723e-03,  1.7913e-01,  6.2831e-02,\n",
      "         2.0605e-02,  1.2325e-02, -1.1367e-01, -5.6525e-03,  3.4215e-02,\n",
      "         3.3041e-03,  1.8205e-02,  1.5090e-02,  4.7602e-02,  3.9768e-02,\n",
      "        -3.2399e-01], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(-0.0258, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.3262, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0387, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0633, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.2553, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0434, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0761, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1230, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0523, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1871, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0790, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1385, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.2320, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.3853, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0198, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1123, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1538, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1052, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0004, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0241, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0287, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0389, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0158, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0447, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0379, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1267, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0986, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0587, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0051, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0379, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0074, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0828, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1356, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1101, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0989, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1622, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0085, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0020, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1791, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0628, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0206, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0123, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0597, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0342, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0033, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0182, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0151, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0437, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.3240, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'who', 'did', 'gen', 'ghi', 's', 'khan', 'charge', 'with', 'finding', 'and', 'punish', 'ing', 'the', 'shah', '?', '[SEP]', '[SEP]', 'gen', 'ghi', 's', 'khan', 'ordered', 'the', 'wholesale', 'massacre', 'of', 'many', 'of', 'the', 'civilians', ',', 'enslaved', 'the', 'rest', 'of', 'the', 'population', 'and', 'executed', 'ina', 'lch', 'u', 'q', 'by', 'pouring', 'molten', 'silver', 'into', 'his', 'ears', 'and', 'eyes', ',', 'as', 'retribution', 'for', 'his', 'actions', '.', '[SEP]']\n",
      "len conti_raw 49\n",
      "conti_raw ['[CLS]', 'who', 'did', 'genghis', 'khan', 'charge', 'with', 'finding', 'and', 'punishing', 'the', 'shah?', '[SEP]', '[SEP]', 'genghis', 'khan', 'ordered', 'the', 'wholesale', 'massacre', 'of', 'many', 'of', 'the', 'civilians,', 'enslaved', 'the', 'rest', 'of', 'the', 'population', 'and', 'executed', 'inalchuq', 'by', 'pouring', 'molten', 'silver', 'into', 'his', 'ears', 'and', 'eyes,', 'as', 'retribution', 'for', 'his', 'actions.', '[SEP]']\n",
      "pred_prob 0.7466775178909302\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.75)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>-0.22</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> who                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> did                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> genghis                    </font></mark><mark style=\"background-color: hsl(0, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> khan                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> charge                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> with                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> finding                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> punishing                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> shah?                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> genghis                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> khan                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ordered                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> wholesale                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> massacre                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> many                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> civilians,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> enslaved                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> rest                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> population                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> executed                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> inalchuq                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> by                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pouring                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> molten                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> silver                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> into                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> his                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ears                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> eyes,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> retribution                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> for                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> his                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> actions.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['What entity enforces the Charter of Fundamental Rights of the European Union?', 'In effect, after the Lisbon Treaty, the Charter and the Convention now co-exist under European Union law, though the former is enforced by the European Court of Justice in relation to European Union measures, and the latter by the European Court of Human Rights in relation to measures by member states.']\n",
      "GT target: 1\n",
      "word attr tensor([ 0.0387, -0.0802,  0.1854, -0.5464, -0.1709,  0.0312,  0.0567, -0.0168,\n",
      "        -0.0379,  0.0798,  0.0102,  0.0012, -0.0033,  0.0043, -0.0193,  0.0073,\n",
      "        -0.0523,  0.0696,  0.0116,  0.0449, -0.0014, -0.0024,  0.0243,  0.0177,\n",
      "         0.0599, -0.0722,  0.0255, -0.0099,  0.0357, -0.0090, -0.0472,  0.0055,\n",
      "        -0.0055, -0.0714,  0.0069,  0.0289, -0.0322,  0.0371,  0.0261,  0.0356,\n",
      "         0.0205, -0.1500,  0.5311,  0.1437, -0.1683, -0.1064,  0.1052,  0.2142,\n",
      "        -0.0329, -0.1222,  0.0097, -0.0165, -0.0075,  0.0798, -0.0116,  0.2001,\n",
      "         0.0429, -0.0302,  0.0686, -0.0356,  0.0691, -0.0410,  0.0644,  0.0522,\n",
      "        -0.0334, -0.0382,  0.0308, -0.0277,  0.0067, -0.0024,  0.1413, -0.0113,\n",
      "         0.0407, -0.0088,  0.0275, -0.2208], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(0.0387, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0802, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1854, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.3586, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0312, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0567, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0168, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0379, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0798, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0102, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0012, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0033, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0075, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0073, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0523, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0696, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0283, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0014, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0024, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0243, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0388, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0722, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0255, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0099, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0357, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0090, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0472, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0357, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0069, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0289, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0322, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0316, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0356, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0205, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1500, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.5311, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1437, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1683, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1064, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1052, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2142, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0329, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1222, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0097, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0165, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0075, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0798, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0116, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1215, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0302, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0686, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0356, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0691, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0410, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0644, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0522, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0334, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0382, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0308, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0277, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0067, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0024, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1413, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0113, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0407, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0093, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.2208, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'what', 'entity', 'enforce', 's', 'the', 'charter', 'of', 'fundamental', 'rights', 'of', 'the', 'european', 'union', '?', '[SEP]', '[SEP]', 'in', 'effect', ',', 'after', 'the', 'lisbon', 'treaty', ',', 'the', 'charter', 'and', 'the', 'convention', 'now', 'co', '-', 'exist', 'under', 'european', 'union', 'law', ',', 'though', 'the', 'former', 'is', 'enforced', 'by', 'the', 'european', 'court', 'of', 'justice', 'in', 'relation', 'to', 'european', 'union', 'measures', ',', 'and', 'the', 'latter', 'by', 'the', 'european', 'court', 'of', 'human', 'rights', 'in', 'relation', 'to', 'measures', 'by', 'member', 'states', '.', '[SEP]']\n",
      "len conti_raw 67\n",
      "conti_raw ['[CLS]', 'what', 'entity', 'enforces', 'the', 'charter', 'of', 'fundamental', 'rights', 'of', 'the', 'european', 'union?', '[SEP]', '[SEP]', 'in', 'effect,', 'after', 'the', 'lisbon', 'treaty,', 'the', 'charter', 'and', 'the', 'convention', 'now', 'co-exist', 'under', 'european', 'union', 'law,', 'though', 'the', 'former', 'is', 'enforced', 'by', 'the', 'european', 'court', 'of', 'justice', 'in', 'relation', 'to', 'european', 'union', 'measures,', 'and', 'the', 'latter', 'by', 'the', 'european', 'court', 'of', 'human', 'rights', 'in', 'relation', 'to', 'measures', 'by', 'member', 'states.', '[SEP]']\n",
      "pred_prob 0.3837520182132721\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment (0.38)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>0.45</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> what                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> entity                    </font></mark><mark style=\"background-color: hsl(0, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> enforces                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> charter                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> fundamental                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> rights                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> european                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> union?                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> effect,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> after                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> lisbon                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> treaty,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> charter                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> convention                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> now                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> co-exist                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> under                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> european                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> union                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> law,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> though                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> former                    </font></mark><mark style=\"background-color: hsl(120, 75%, 74%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> enforced                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> by                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> european                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> court                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> justice                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> relation                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> european                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> union                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> measures,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> latter                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> by                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> european                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> court                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> human                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> rights                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> relation                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> measures                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> by                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> member                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> states.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: [\"Most of the museum's collection had been returned by which year?\", 'Before the return of the collections after the war, the Britain Can Make It exhibition was held between September and November 1946, attracting nearly a million and a half visitors.']\n",
      "GT target: 0\n",
      "word attr tensor([-0.2896, -0.0136,  0.0047, -0.0195, -0.1132, -0.0137,  0.0035, -0.0880,\n",
      "        -0.0900,  0.3402, -0.2099, -0.2277, -0.1847,  0.6469, -0.1284,  0.0443,\n",
      "         0.0569, -0.0398, -0.0032,  0.0763, -0.0276, -0.0689,  0.0671, -0.0261,\n",
      "        -0.0312,  0.0437,  0.0375, -0.1040,  0.0886, -0.0805,  0.0564,  0.0134,\n",
      "        -0.1873, -0.1271,  0.0862,  0.0440,  0.1611, -0.1018,  0.1091,  0.0286,\n",
      "        -0.0452, -0.0499,  0.0260, -0.0218, -0.0646, -0.0186, -0.0531,  0.0521,\n",
      "        -0.0736, -0.0857,  0.1083], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(-0.2896, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0136, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0047, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0195, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0300, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0880, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0900, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.3402, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2099, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2277, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1847, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0443, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0569, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0398, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0032, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0763, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0276, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0689, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0671, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0261, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0312, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0406, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1040, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0886, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0805, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0564, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0134, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1873, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1271, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0862, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0440, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1611, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1018, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1091, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0083, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0499, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0260, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0218, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0646, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0186, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0531, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0521, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0797, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1083, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'most', 'of', 'the', 'museum', \"'\", 's', 'collection', 'had', 'been', 'returned', 'by', 'which', 'year', '?', '[SEP]', '[SEP]', 'before', 'the', 'return', 'of', 'the', 'collections', 'after', 'the', 'war', ',', 'the', 'britain', 'can', 'make', 'it', 'exhibition', 'was', 'held', 'between', 'september', 'and', 'november', '1946', ',', 'attracting', 'nearly', 'a', 'million', 'and', 'a', 'half', 'visitors', '.', '[SEP]']\n",
      "len conti_raw 45\n",
      "conti_raw ['[CLS]', 'most', 'of', 'the', \"museum's\", 'collection', 'had', 'been', 'returned', 'by', 'which', 'year?', '[SEP]', '[SEP]', 'before', 'the', 'return', 'of', 'the', 'collections', 'after', 'the', 'war,', 'the', 'britain', 'can', 'make', 'it', 'exhibition', 'was', 'held', 'between', 'september', 'and', 'november', '1946,', 'attracting', 'nearly', 'a', 'million', 'and', 'a', 'half', 'visitors.', '[SEP]']\n",
      "pred_prob 0.8580110669136047\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.86)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>-0.49</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> most                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> museum's                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> collection                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> had                    </font></mark><mark style=\"background-color: hsl(120, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> been                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> returned                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> by                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> which                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> year?                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> before                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> return                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> collections                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> after                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> war,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> britain                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> can                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> make                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> it                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> exhibition                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> held                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> between                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> september                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> november                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 1946,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> attracting                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> nearly                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> million                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> half                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> visitors.                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['Within the 30 days how many digiboxes had been sold?', \"Within 30 days, over 100,000 digiboxes had been sold, which help bolstered BSkyB's decision to give away free digiboxes and minidishes from May 1999.\"]\n",
      "GT target: 1\n",
      "word attr tensor([-0.4044,  0.0530, -0.0280,  0.0735,  0.0136,  0.0656, -0.0911, -0.1431,\n",
      "         0.0276,  0.1149, -0.0504,  0.1219, -0.0829, -0.1821, -0.0032,  0.3016,\n",
      "         0.2014, -0.0226,  0.0105,  0.0227, -0.1509, -0.0257,  0.0110, -0.2313,\n",
      "         0.1620,  0.0745, -0.0874,  0.1656, -0.0968, -0.1475, -0.0009,  0.0508,\n",
      "        -0.1906, -0.0606, -0.0240,  0.0591, -0.0193,  0.0841, -0.0182, -0.0787,\n",
      "        -0.0080,  0.0044, -0.0715, -0.0807,  0.0146,  0.1715, -0.0711,  0.0077,\n",
      "         0.0336,  0.0073,  0.1019,  0.0156, -0.0467,  0.0907, -0.0997, -0.0433,\n",
      "         0.0754,  0.0295,  0.0318,  0.4702, -0.2129], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(-0.4044, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0530, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0280, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0735, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0136, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0656, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0911, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0109, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1219, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0829, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0927, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.3016, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2014, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0226, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0105, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0641, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0257, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0259, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0086, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1475, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0009, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0699, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0606, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0240, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0520, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0417, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0807, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0146, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1715, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0711, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0077, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0384, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0467, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0239, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0754, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0295, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2510, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.2129, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'within', 'the', '30', 'days', 'how', 'many', 'dig', 'ib', 'ox', 'es', 'had', 'been', 'sold', '?', '[SEP]', '[SEP]', 'within', '30', 'days', ',', 'over', '100', ',', '000', 'dig', 'ib', 'ox', 'es', 'had', 'been', 'sold', ',', 'which', 'help', 'bo', 'lster', 'ed', 'bs', 'ky', 'b', \"'\", 's', 'decision', 'to', 'give', 'away', 'free', 'dig', 'ib', 'ox', 'es', 'and', 'mini', 'dis', 'hes', 'from', 'may', '1999', '.', '[SEP]']\n",
      "len conti_raw 38\n",
      "conti_raw ['[CLS]', 'within', 'the', '30', 'days', 'how', 'many', 'digiboxes', 'had', 'been', 'sold?', '[SEP]', '[SEP]', 'within', '30', 'days,', 'over', '100,000', 'digiboxes', 'had', 'been', 'sold,', 'which', 'help', 'bolstered', \"bskyb's\", 'decision', 'to', 'give', 'away', 'free', 'digiboxes', 'and', 'minidishes', 'from', 'may', '1999.', '[SEP]']\n",
      "pred_prob 0.7189930081367493\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.72)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>-0.11</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> within                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 30                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> days                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> how                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> many                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> digiboxes                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> had                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> been                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> sold?                    </font></mark><mark style=\"background-color: hsl(120, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> within                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 30                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> days,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> over                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 100,000                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> digiboxes                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> had                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> been                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> sold,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> which                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> help                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> bolstered                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> bskyb's                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> decision                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> give                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> away                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> free                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> digiboxes                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> minidishes                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> from                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> may                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 1999.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['The receptors on a killer T cell must bind to how many MHC: antigen complexes in order to activate the cell?', \"The MHC:antigen complex is also recognized by the helper cell's CD4 co-receptor, which recruits molecules inside the T cell (e.g., Lck) that are responsible for the T cell's activation.\"]\n",
      "GT target: 0\n",
      "word attr tensor([ 4.0482e-02,  2.4496e-02, -1.2520e-01, -2.0385e-02,  3.1552e-02,\n",
      "        -2.2738e-02, -6.1131e-02,  3.1683e-02, -9.3330e-02, -1.2109e-02,\n",
      "         6.5192e-02, -4.2892e-01, -4.2839e-01, -1.0107e-01,  1.1589e-01,\n",
      "        -2.6925e-01,  1.2054e-01, -1.0664e-01, -1.7005e-01,  4.2882e-02,\n",
      "         1.1409e-01,  1.3522e-01, -1.5796e-02,  1.2221e-01, -3.7039e-01,\n",
      "         1.1029e-01, -1.1853e-01,  1.7805e-01, -3.4971e-02,  3.3599e-02,\n",
      "        -2.0249e-01,  4.5458e-02,  2.6949e-03, -1.1208e-01,  2.7810e-02,\n",
      "         8.1568e-02,  5.0874e-02, -5.3832e-02, -7.6062e-03,  8.4384e-03,\n",
      "         5.2021e-02, -4.8427e-02,  1.3567e-02,  6.0751e-02,  5.0706e-02,\n",
      "         6.5340e-02, -9.8681e-02,  3.6195e-03, -2.6281e-02,  1.7754e-02,\n",
      "         1.0852e-01, -9.1003e-02,  2.3774e-02,  2.4367e-02,  1.8284e-02,\n",
      "         5.8879e-02, -8.3455e-02,  8.0320e-02, -4.5500e-02,  9.4167e-02,\n",
      "        -5.9605e-02,  2.0600e-02,  2.4081e-02, -1.8749e-03,  2.6394e-02,\n",
      "         2.4283e-02, -1.0458e-02, -4.2612e-03,  2.7068e-02,  2.4495e-02,\n",
      "        -1.9339e-04,  3.1189e-02, -3.5678e-02,  3.2200e-03,  1.1206e-01,\n",
      "        -4.1656e-04, -1.7715e-01], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(0.0405, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0245, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1252, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0204, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0316, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0227, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0611, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0317, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0933, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0121, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0652, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.4289, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.4284, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1309, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1205, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1066, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1700, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0429, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1141, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1352, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0158, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1241, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1103, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1185, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1781, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0281, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0027, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1121, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0278, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0816, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0509, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0538, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0077, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0557, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0164, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0178, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1085, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0910, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0238, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0244, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0183, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0589, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0042, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0187, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0243, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0105, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0043, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0271, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0245, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0002, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0558, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1771, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'the', 'receptors', 'on', 'a', 'killer', 't', 'cell', 'must', 'bind', 'to', 'how', 'many', 'm', 'hc', ':', 'antigen', 'complexes', 'in', 'order', 'to', 'activate', 'the', 'cell', '?', '[SEP]', '[SEP]', 'the', 'm', 'hc', ':', 'antigen', 'complex', 'is', 'also', 'recognized', 'by', 'the', 'help', 'er', 'cell', \"'\", 's', 'cd', '4', 'co', '-', 'receptor', ',', 'which', 'recruits', 'molecules', 'inside', 'the', 't', 'cell', '(', 'e', '.', 'g', '.', ',', 'lc', 'k', ')', 'that', 'are', 'responsible', 'for', 'the', 't', 'cell', \"'\", 's', 'activation', '.', '[SEP]']\n",
      "len conti_raw 54\n",
      "conti_raw ['[CLS]', 'the', 'receptors', 'on', 'a', 'killer', 't', 'cell', 'must', 'bind', 'to', 'how', 'many', 'mhc:', 'antigen', 'complexes', 'in', 'order', 'to', 'activate', 'the', 'cell?', '[SEP]', '[SEP]', 'the', 'mhc:antigen', 'complex', 'is', 'also', 'recognized', 'by', 'the', 'helper', \"cell's\", 'cd4', 'co-receptor,', 'which', 'recruits', 'molecules', 'inside', 'the', 't', 'cell', '(e.g.,', 'lck)', 'that', 'are', 'responsible', 'for', 'the', 't', \"cell's\", 'activation.', '[SEP]']\n",
      "pred_prob 0.9368581175804138\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.94)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>-1.09</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> receptors                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> on                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> killer                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> t                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> cell                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> must                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> bind                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(0, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> how                    </font></mark><mark style=\"background-color: hsl(0, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> many                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> mhc:                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> antigen                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> complexes                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> order                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> activate                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> cell?                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> mhc:antigen                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> complex                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> also                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> recognized                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> by                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> helper                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> cell's                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> cd4                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> co-receptor,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> which                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> recruits                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> molecules                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> inside                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> t                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> cell                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> (e.g.,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> lck)                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> that                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> are                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> responsible                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> for                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> t                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> cell's                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> activation.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: [\"How much did Westinghouse pay for Tesla's designs?\", \"In July 1888, Brown and Peck negotiated a licensing deal with George Westinghouse for Tesla's polyphase induction motor and transformer designs for $60,000 in cash and stock and a royalty of $2.50 per AC horsepower produced by each motor.\"]\n",
      "GT target: 1\n",
      "word attr tensor([ 0.0299, -0.3328,  0.0691,  0.1034,  0.0144,  0.0562, -0.0568,  0.1668,\n",
      "         0.1352,  0.0293, -0.0150, -0.0454,  0.0438, -0.1584, -0.0119,  0.0373,\n",
      "         0.1477, -0.1479,  0.0730,  0.0700, -0.2198, -0.2093, -0.1708,  0.0250,\n",
      "         0.1780, -0.2169, -0.0254, -0.0028, -0.1823, -0.0166,  0.0060,  0.0189,\n",
      "         0.0744,  0.1206,  0.0089, -0.0123,  0.0692,  0.0659, -0.0119, -0.0981,\n",
      "         0.0992,  0.0344,  0.1027,  0.1495, -0.0789,  0.0645, -0.1929, -0.0838,\n",
      "         0.0754,  0.1181, -0.1195, -0.1217,  0.0127, -0.2425, -0.0210,  0.1309,\n",
      "         0.0375,  0.0797,  0.0423, -0.0999,  0.1192, -0.0562,  0.0838,  0.0162,\n",
      "         0.1696, -0.0509, -0.0086, -0.0454,  0.1237,  0.0600, -0.3739],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(0.0299, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.3328, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0691, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1034, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0108, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1668, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1352, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0191, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0573, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0119, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0373, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1477, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1479, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0715, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.2198, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2093, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1708, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0250, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1780, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2169, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0254, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0028, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1823, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0068, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0744, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0262, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0278, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0981, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0992, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0344, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1261, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0789, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0645, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0433, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1195, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1217, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0127, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2425, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0210, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1309, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0375, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0797, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0055, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0838, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0162, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1696, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0509, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0086, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0454, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0919, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.3739, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'how', 'much', 'did', 'west', 'ing', 'house', 'pay', 'for', 'tesla', \"'\", 's', 'designs', '?', '[SEP]', '[SEP]', 'in', 'july', '1888', ',', 'brown', 'and', 'peck', 'negotiated', 'a', 'licensing', 'deal', 'with', 'george', 'west', 'ing', 'house', 'for', 'tesla', \"'\", 's', 'poly', 'pha', 'se', 'induction', 'motor', 'and', 'transform', 'er', 'designs', 'for', '$', '60', ',', '000', 'in', 'cash', 'and', 'stock', 'and', 'a', 'royalty', 'of', '$', '2', '.', '50', 'per', 'ac', 'horsepower', 'produced', 'by', 'each', 'motor', '.', '[SEP]']\n",
      "len conti_raw 51\n",
      "conti_raw ['[CLS]', 'how', 'much', 'did', 'westinghouse', 'pay', 'for', \"tesla's\", 'designs?', '[SEP]', '[SEP]', 'in', 'july', '1888,', 'brown', 'and', 'peck', 'negotiated', 'a', 'licensing', 'deal', 'with', 'george', 'westinghouse', 'for', \"tesla's\", 'polyphase', 'induction', 'motor', 'and', 'transformer', 'designs', 'for', '$60,000', 'in', 'cash', 'and', 'stock', 'and', 'a', 'royalty', 'of', '$2.50', 'per', 'ac', 'horsepower', 'produced', 'by', 'each', 'motor.', '[SEP]']\n",
      "pred_prob 0.7738507390022278\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.77)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>-0.37</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> how                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> much                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> did                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> westinghouse                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pay                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> for                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> tesla's                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> designs?                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> july                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 1888,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> brown                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> peck                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> negotiated                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> licensing                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> deal                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> with                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> george                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> westinghouse                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> for                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> tesla's                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> polyphase                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> induction                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> motor                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> transformer                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> designs                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> for                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> $60,000                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> cash                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> stock                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> royalty                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> $2.50                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> per                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ac                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> horsepower                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> produced                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> by                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> each                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> motor.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: [\"What type of movies were produced in Jacksonville's 30 studios?\", 'One converted movie studio site, Norman Studios, remains in Arlington; It has been converted to the Jacksonville Silent Film Museum at Norman Studios.']\n",
      "GT target: 0\n",
      "word attr tensor([ 0.1948, -0.0802, -0.0798, -0.0995,  0.1926, -0.1284, -0.1382, -0.1024,\n",
      "         0.0553, -0.0692,  0.1825, -0.2075,  0.1884,  0.1788, -0.0872, -0.0822,\n",
      "        -0.0127,  0.0279, -0.1481, -0.0233, -0.0721, -0.2017, -0.1757, -0.0054,\n",
      "        -0.0514,  0.0105,  0.1027,  0.2026, -0.0213, -0.1585, -0.2203,  0.0550,\n",
      "         0.1089,  0.0961, -0.1122,  0.1731, -0.0158, -0.1724, -0.1012,  0.0373,\n",
      "        -0.1535,  0.1053,  0.5547, -0.1040], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(0.1948, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0802, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0798, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0995, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1926, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1284, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1382, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1024, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0878, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.2075, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1836, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0872, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0822, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0127, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0279, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1481, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0233, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1369, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1757, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0284, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0105, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1027, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1585, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2203, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0550, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1089, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0961, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1122, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1731, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0158, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1724, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1012, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0373, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1535, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.3300, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1040, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'what', 'type', 'of', 'movies', 'were', 'produced', 'in', 'jacksonville', \"'\", 's', '30', 'studios', '?', '[SEP]', '[SEP]', 'one', 'converted', 'movie', 'studio', 'site', ',', 'norman', 'studios', ',', 'remains', 'in', 'arlington', ';', 'it', 'has', 'been', 'converted', 'to', 'the', 'jacksonville', 'silent', 'film', 'museum', 'at', 'norman', 'studios', '.', '[SEP]']\n",
      "len conti_raw 37\n",
      "conti_raw ['[CLS]', 'what', 'type', 'of', 'movies', 'were', 'produced', 'in', \"jacksonville's\", '30', 'studios?', '[SEP]', '[SEP]', 'one', 'converted', 'movie', 'studio', 'site,', 'norman', 'studios,', 'remains', 'in', 'arlington;', 'it', 'has', 'been', 'converted', 'to', 'the', 'jacksonville', 'silent', 'film', 'museum', 'at', 'norman', 'studios.', '[SEP]']\n",
      "pred_prob 0.575401782989502\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.58)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>-0.36</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> what                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> type                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> movies                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> were                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> produced                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> jacksonville's                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 30                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> studios?                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> one                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> converted                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> movie                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> studio                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> site,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> norman                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> studios,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> remains                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> arlington;                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> it                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> has                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> been                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> converted                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> jacksonville                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> silent                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> film                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> museum                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> at                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> norman                    </font></mark><mark style=\"background-color: hsl(120, 75%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> studios.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['What voyager said that Mombasa was a great harbour and moored small crafts and great ships?', 'The Swahili built Mombasa into a major port city and established trade links with other nearby city-states, as well as commercial centres in Persia, Arabia, and even India.']\n",
      "GT target: 0\n",
      "word attr tensor([-0.1972,  0.0052,  0.0505, -0.4023, -0.0634, -0.1229,  0.1206,  0.0091,\n",
      "         0.0420,  0.0212,  0.1325, -0.1286, -0.0498, -0.1051, -0.1187,  0.2079,\n",
      "        -0.0455, -0.0162,  0.3851, -0.1242,  0.1260,  0.0358,  0.0839,  0.0105,\n",
      "        -0.2427, -0.0014,  0.3090, -0.0339, -0.0674, -0.0366,  0.1072,  0.0029,\n",
      "         0.0728,  0.0565, -0.1963,  0.0521, -0.0300,  0.1409, -0.0049, -0.0803,\n",
      "         0.0219,  0.0268,  0.0268,  0.0663, -0.0805, -0.1149, -0.0268,  0.0050,\n",
      "         0.0600, -0.0004, -0.1389, -0.0361,  0.0481,  0.1474, -0.0155, -0.1447,\n",
      "         0.0403,  0.0751,  0.1129, -0.2893,  0.0381,  0.1191], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(-0.1972, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0052, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0505, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.4023, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0634, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0420, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0212, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1325, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1286, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0498, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1119, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.2079, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0455, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0162, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.3851, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0358, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0839, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0105, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0935, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0339, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0276, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0029, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0728, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0565, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1963, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0521, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0300, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1409, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0049, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0803, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0219, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0268, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0268, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0439, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0050, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0600, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0004, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1389, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0361, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0481, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0522, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0751, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1129, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1256, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1191, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'what', 'voyager', 'said', 'that', 'mom', 'bas', 'a', 'was', 'a', 'great', 'harbour', 'and', 'moore', 'd', 'small', 'crafts', 'and', 'great', 'ships', '?', '[SEP]', '[SEP]', 'the', 'sw', 'ah', 'ili', 'built', 'mom', 'bas', 'a', 'into', 'a', 'major', 'port', 'city', 'and', 'established', 'trade', 'links', 'with', 'other', 'nearby', 'city', '-', 'states', ',', 'as', 'well', 'as', 'commercial', 'centres', 'in', 'persia', ',', 'arabia', ',', 'and', 'even', 'india', '.', '[SEP]']\n",
      "len conti_raw 48\n",
      "conti_raw ['[CLS]', 'what', 'voyager', 'said', 'that', 'mombasa', 'was', 'a', 'great', 'harbour', 'and', 'moored', 'small', 'crafts', 'and', 'great', 'ships?', '[SEP]', '[SEP]', 'the', 'swahili', 'built', 'mombasa', 'into', 'a', 'major', 'port', 'city', 'and', 'established', 'trade', 'links', 'with', 'other', 'nearby', 'city-states,', 'as', 'well', 'as', 'commercial', 'centres', 'in', 'persia,', 'arabia,', 'and', 'even', 'india.', '[SEP]']\n",
      "pred_prob 0.9446513652801514\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.94)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>-0.16</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> what                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> voyager                    </font></mark><mark style=\"background-color: hsl(0, 75%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> said                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> that                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> mombasa                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> great                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> harbour                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> moored                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> small                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> crafts                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 81%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> great                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ships?                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> swahili                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> built                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> mombasa                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> into                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> major                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> port                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> city                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> established                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> trade                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> links                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> with                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> other                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> nearby                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> city-states,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> well                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> commercial                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> centres                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> persia,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> arabia,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> even                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> india.                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['Where is Energiprojekt AB based?', 'Although the reciprocating steam engine is no longer in widespread commercial use, various companies are exploring or exploiting the potential of the engine as an alternative to internal combustion engines.']\n",
      "GT target: 0\n",
      "word attr tensor([ 0.0023, -0.0891, -0.1578,  0.0609,  0.0122, -0.0091, -0.1309, -0.0383,\n",
      "        -0.0712, -0.0550, -0.0768,  0.3568,  0.1896,  0.3732, -0.1848, -0.1619,\n",
      "        -0.0552,  0.0063, -0.1618, -0.0931,  0.0951, -0.1275,  0.0751, -0.0301,\n",
      "        -0.0802, -0.1649,  0.0582, -0.0062, -0.1259, -0.0843, -0.1651,  0.1379,\n",
      "         0.1634,  0.2528, -0.0143,  0.0494, -0.1271, -0.0521,  0.0581,  0.0325,\n",
      "        -0.0813, -0.1101, -0.0603, -0.0441,  0.2446,  0.0542,  0.1566,  0.1413,\n",
      "        -0.0289,  0.3249,  0.1929], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(0.0023, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0891, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1578, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0598, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0550, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1896, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.3732, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1848, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1619, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0931, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0951, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1275, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0751, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0301, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0802, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1649, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0582, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0062, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1051, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1651, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1379, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1634, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2528, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0143, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0389, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0521, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0581, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0325, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0813, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1101, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0603, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0441, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2446, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0542, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1566, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1413, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1480, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1929, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'where', 'is', 'en', 'er', 'gi', 'pro', 'je', 'kt', 'ab', 'based', '?', '[SEP]', '[SEP]', 'although', 'the', 'rec', 'ip', 'ro', 'cating', 'steam', 'engine', 'is', 'no', 'longer', 'in', 'widespread', 'commercial', 'use', ',', 'various', 'companies', 'are', 'exploring', 'or', 'exploit', 'ing', 'the', 'potential', 'of', 'the', 'engine', 'as', 'an', 'alternative', 'to', 'internal', 'combustion', 'engines', '.', '[SEP]']\n",
      "len conti_raw 39\n",
      "conti_raw ['[CLS]', 'where', 'is', 'energiprojekt', 'ab', 'based?', '[SEP]', '[SEP]', 'although', 'the', 'reciprocating', 'steam', 'engine', 'is', 'no', 'longer', 'in', 'widespread', 'commercial', 'use,', 'various', 'companies', 'are', 'exploring', 'or', 'exploiting', 'the', 'potential', 'of', 'the', 'engine', 'as', 'an', 'alternative', 'to', 'internal', 'combustion', 'engines.', '[SEP]']\n",
      "pred_prob 0.8502684831619263\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.85)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>0.45</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> where                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> energiprojekt                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ab                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> based?                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 82%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> although                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> reciprocating                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> steam                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> engine                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> no                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> longer                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> widespread                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> commercial                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> use,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> various                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> companies                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> are                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> exploring                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> or                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> exploiting                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> potential                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> engine                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> an                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> alternative                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> internal                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> combustion                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> engines.                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['Who other than Tesla did Westinghouse consider for the patents?', \"Westinghouse looked into getting a patent on a similar commutator-less, rotating magnetic field-based induction motor presented in a paper in March 1888 by the Italian physicist Galileo Ferraris, but decided Tesla's patent would probably control the market.\"]\n",
      "GT target: 1\n",
      "word attr tensor([-0.3732,  0.0348,  0.2304, -0.0427, -0.0352,  0.3873,  0.0269, -0.0367,\n",
      "        -0.2210, -0.1973,  0.0147,  0.1074, -0.0071, -0.1665,  0.1549,  0.0320,\n",
      "        -0.2311,  0.0015, -0.1369, -0.0852,  0.0977, -0.0554,  0.0268,  0.1009,\n",
      "        -0.0431,  0.0305, -0.0042, -0.0840, -0.0413, -0.0042,  0.0185,  0.0080,\n",
      "         0.0573,  0.0540,  0.1060,  0.0142,  0.0475, -0.0517,  0.0040, -0.0263,\n",
      "        -0.0219,  0.0026, -0.1039,  0.0282,  0.0432, -0.0882, -0.1067,  0.0396,\n",
      "         0.0975, -0.0373,  0.1815,  0.3063,  0.1169,  0.0303,  0.0839,  0.0138,\n",
      "         0.0273,  0.2080,  0.0311,  0.0661,  0.2068, -0.0590, -0.0582, -0.0045,\n",
      "         0.0385, -0.0970,  0.0492, -0.2329], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(-0.3732, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0348, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2304, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0427, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0352, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.3873, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1130, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1973, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0147, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1074, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0868, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1549, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0320, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1259, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0852, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0977, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0554, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0268, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1009, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0431, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0305, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0042, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0288, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0540, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1060, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0104, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0040, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0263, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0219, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0026, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1039, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0282, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0432, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0882, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1067, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0396, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0975, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0373, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1815, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.3063, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0138, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0273, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0928, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.2068, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0590, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0582, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0045, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0385, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0239, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.2329, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'who', 'other', 'than', 'tesla', 'did', 'west', 'ing', 'house', 'consider', 'for', 'the', 'patents', '?', '[SEP]', '[SEP]', 'west', 'ing', 'house', 'looked', 'into', 'getting', 'a', 'patent', 'on', 'a', 'similar', 'com', 'mut', 'ator', '-', 'less', ',', 'rotating', 'magnetic', 'field', '-', 'based', 'induction', 'motor', 'presented', 'in', 'a', 'paper', 'in', 'march', '1888', 'by', 'the', 'italian', 'physicist', 'galileo', 'ferrari', 's', ',', 'but', 'decided', 'tesla', \"'\", 's', 'patent', 'would', 'probably', 'control', 'the', 'market', '.', '[SEP]']\n",
      "len conti_raw 51\n",
      "conti_raw ['[CLS]', 'who', 'other', 'than', 'tesla', 'did', 'westinghouse', 'consider', 'for', 'the', 'patents?', '[SEP]', '[SEP]', 'westinghouse', 'looked', 'into', 'getting', 'a', 'patent', 'on', 'a', 'similar', 'commutator-less,', 'rotating', 'magnetic', 'field-based', 'induction', 'motor', 'presented', 'in', 'a', 'paper', 'in', 'march', '1888', 'by', 'the', 'italian', 'physicist', 'galileo', 'ferraris,', 'but', 'decided', \"tesla's\", 'patent', 'would', 'probably', 'control', 'the', 'market.', '[SEP]']\n",
      "pred_prob 0.7733870148658752\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.77)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>0.47</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> who                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> other                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> than                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> tesla                    </font></mark><mark style=\"background-color: hsl(120, 75%, 81%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> did                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> westinghouse                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> consider                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> for                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> patents?                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> westinghouse                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> looked                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> into                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> getting                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> patent                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> on                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> similar                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> commutator-less,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> rotating                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> magnetic                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> field-based                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> induction                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> motor                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> presented                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> paper                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> march                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 1888                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> by                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> italian                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> physicist                    </font></mark><mark style=\"background-color: hsl(120, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> galileo                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ferraris,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> but                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> decided                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> tesla's                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> patent                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> would                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> probably                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> control                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> market.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['What separates the neuroimmune system and peripheral immune system in humans?', 'In humans, the blood–brain barrier, blood–cerebrospinal fluid barrier, and similar fluid–brain barriers separate the peripheral immune system from the neuroimmune system which protects the brain.']\n",
      "GT target: 1\n",
      "word attr tensor([ 0.0447, -0.2248,  0.0582,  0.1224,  0.0142,  0.0169, -0.0727, -0.0464,\n",
      "         0.0132,  0.0551, -0.0451, -0.0017,  0.0542,  0.0239,  0.0914, -0.0479,\n",
      "        -0.1041,  0.0250,  0.1194, -0.0013,  0.0678,  0.1222,  0.0342, -0.2709,\n",
      "        -0.0593, -0.1020,  0.2663,  0.3552, -0.3997,  0.0115, -0.0021,  0.0427,\n",
      "        -0.0155,  0.0139, -0.1205, -0.0797,  0.0177, -0.1252,  0.0632,  0.2116,\n",
      "         0.1073, -0.3884,  0.2290,  0.1339,  0.0206, -0.0574,  0.0929, -0.0355,\n",
      "         0.0889, -0.0533, -0.0176, -0.0140,  0.0170, -0.0123, -0.0911,  0.0041,\n",
      "         0.0103,  0.0278,  0.0274,  0.0904,  0.0070,  0.1384, -0.1666],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(0.0447, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2248, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0582, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1224, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0121, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0551, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0451, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0017, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0542, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0239, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0914, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0760, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0250, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1194, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0013, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0950, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0342, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1335, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.3107, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0622, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0797, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0538, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0632, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2116, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0442, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1339, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0206, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0574, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0929, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0355, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0889, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0533, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0176, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0221, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0103, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0278, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0274, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0904, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0727, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1666, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'what', 'separates', 'the', 'ne', 'uro', 'im', 'mun', 'e', 'system', 'and', 'peripheral', 'immune', 'system', 'in', 'humans', '?', '[SEP]', '[SEP]', 'in', 'humans', ',', 'the', 'blood', '–', 'brain', 'barrier', ',', 'blood', '–', 'ce', 're', 'bro', 'sp', 'inal', 'fluid', 'barrier', ',', 'and', 'similar', 'fluid', '–', 'brain', 'barriers', 'separate', 'the', 'peripheral', 'immune', 'system', 'from', 'the', 'ne', 'uro', 'im', 'mun', 'e', 'system', 'which', 'protects', 'the', 'brain', '.', '[SEP]']\n",
      "len conti_raw 40\n",
      "conti_raw ['[CLS]', 'what', 'separates', 'the', 'neuroimmune', 'system', 'and', 'peripheral', 'immune', 'system', 'in', 'humans?', '[SEP]', '[SEP]', 'in', 'humans,', 'the', 'blood–brain', 'barrier,', 'blood–cerebrospinal', 'fluid', 'barrier,', 'and', 'similar', 'fluid–brain', 'barriers', 'separate', 'the', 'peripheral', 'immune', 'system', 'from', 'the', 'neuroimmune', 'system', 'which', 'protects', 'the', 'brain.', '[SEP]']\n",
      "pred_prob 0.8900112509727478\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.89)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>0.28</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> what                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> separates                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> neuroimmune                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> system                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> peripheral                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> immune                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> system                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> humans?                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> humans,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> blood–brain                    </font></mark><mark style=\"background-color: hsl(120, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> barrier,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> blood–cerebrospinal                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> fluid                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> barrier,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> similar                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> fluid–brain                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> barriers                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> separate                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> peripheral                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> immune                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> system                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> from                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> neuroimmune                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> system                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> which                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> protects                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> brain.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: [\"What did Kublai's government have to balance between?\", \"Kublai's government after 1262 was a compromise between preserving Mongol interests in China and satisfying the demands of his Chinese subjects.\"]\n",
      "GT target: 1\n",
      "word attr tensor([ 0.1286,  0.0367,  0.0289,  0.0153, -0.0641, -0.0605, -0.0513, -0.0155,\n",
      "        -0.0955, -0.0777, -0.1689,  0.3612, -0.0986,  0.3783, -0.1406, -0.3089,\n",
      "        -0.1184, -0.0007, -0.0121, -0.0836, -0.0622, -0.0266, -0.0561, -0.1226,\n",
      "         0.0869,  0.1014, -0.0389,  0.2052,  0.3916,  0.0007, -0.0260, -0.1369,\n",
      "        -0.0726, -0.0317,  0.1366, -0.1400,  0.2232, -0.0281, -0.0989,  0.0912,\n",
      "        -0.0646,  0.0041, -0.1315, -0.3397], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(0.1286, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0367, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0289, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0312, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0955, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0777, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1689, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.3612, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1399, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1406, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.3089, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0610, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0266, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0561, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0179, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1014, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0389, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2052, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.3916, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0007, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0260, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1369, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0726, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0317, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1366, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1400, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2232, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0281, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0989, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0912, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0646, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0637, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.3397, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'what', 'did', 'ku', 'bla', 'i', \"'\", 's', 'government', 'have', 'to', 'balance', 'between', '?', '[SEP]', '[SEP]', 'ku', 'bla', 'i', \"'\", 's', 'government', 'after', '126', '2', 'was', 'a', 'compromise', 'between', 'preserving', 'mongol', 'interests', 'in', 'china', 'and', 'satisfying', 'the', 'demands', 'of', 'his', 'chinese', 'subjects', '.', '[SEP]']\n",
      "len conti_raw 33\n",
      "conti_raw ['[CLS]', 'what', 'did', \"kublai's\", 'government', 'have', 'to', 'balance', 'between?', '[SEP]', '[SEP]', \"kublai's\", 'government', 'after', '1262', 'was', 'a', 'compromise', 'between', 'preserving', 'mongol', 'interests', 'in', 'china', 'and', 'satisfying', 'the', 'demands', 'of', 'his', 'chinese', 'subjects.', '[SEP]']\n",
      "pred_prob 0.13032764196395874\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment (0.13)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>-0.48</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> what                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> did                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> kublai's                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> government                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> have                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(120, 75%, 82%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> balance                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> between?                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> kublai's                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> government                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> after                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 1262                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> compromise                    </font></mark><mark style=\"background-color: hsl(120, 75%, 81%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> between                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> preserving                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> mongol                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> interests                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> china                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> satisfying                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> demands                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> his                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> chinese                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> subjects.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: [\"What did Gasquet's book blame the plague on?\", 'The historian Francis Aidan Gasquet wrote about the \\'Great Pestilence\\' in 1893 and suggested that \"it would appear to be some form of the ordinary Eastern or bubonic plague\".']\n",
      "GT target: 0\n",
      "word attr tensor([ 0.0704, -0.0772, -0.1814, -0.0005, -0.0262, -0.0675,  0.0491, -0.0885,\n",
      "         0.2175,  0.1309,  0.3099,  0.1016,  0.1150, -0.3491, -0.3816, -0.0964,\n",
      "        -0.0461, -0.0208,  0.0297,  0.1657, -0.0741,  0.1157, -0.0715, -0.0147,\n",
      "        -0.0672, -0.0944, -0.1323, -0.0299,  0.0742,  0.0521, -0.1579, -0.0635,\n",
      "        -0.0285,  0.2211, -0.0026,  0.0485,  0.0794, -0.1394,  0.0816,  0.0197,\n",
      "         0.0702,  0.0353,  0.0699,  0.0266,  0.0172, -0.1357, -0.2035,  0.1362,\n",
      "        -0.0857,  0.0237,  0.1005,  0.2778,  0.1284,  0.2244,  0.1361],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(0.0704, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0772, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1814, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0044, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0885, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2175, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1309, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.3099, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.3491, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.3816, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0964, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0461, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0208, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0297, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0458, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1157, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0715, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0147, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0808, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0243, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1579, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0635, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0285, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2211, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0026, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0639, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1394, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0816, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0197, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0702, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0353, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0699, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0266, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0172, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1357, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2035, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1362, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0347, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.2138, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1361, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'what', 'did', 'gas', 'quet', \"'\", 's', 'book', 'blame', 'the', 'plague', 'on', '?', '[SEP]', '[SEP]', 'the', 'historian', 'francis', 'aidan', 'gas', 'quet', 'wrote', 'about', 'the', \"'\", 'great', 'pest', 'ile', 'nce', \"'\", 'in', '1893', 'and', 'suggested', 'that', '\"', 'it', 'would', 'appear', 'to', 'be', 'some', 'form', 'of', 'the', 'ordinary', 'eastern', 'or', 'bu', 'bon', 'ic', 'plague', '\"', '.', '[SEP]']\n",
      "len conti_raw 41\n",
      "conti_raw ['[CLS]', 'what', 'did', \"gasquet's\", 'book', 'blame', 'the', 'plague', 'on?', '[SEP]', '[SEP]', 'the', 'historian', 'francis', 'aidan', 'gasquet', 'wrote', 'about', 'the', \"'great\", \"pestilence'\", 'in', '1893', 'and', 'suggested', 'that', '\"it', 'would', 'appear', 'to', 'be', 'some', 'form', 'of', 'the', 'ordinary', 'eastern', 'or', 'bubonic', 'plague\".', '[SEP]']\n",
      "pred_prob 0.7593749761581421\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.76)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>0.49</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> what                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> did                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> gasquet's                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> book                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> blame                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> plague                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> on?                    </font></mark><mark style=\"background-color: hsl(0, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> historian                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> francis                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> aidan                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> gasquet                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> wrote                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> about                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 'great                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pestilence'                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 1893                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> suggested                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> that                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> \"it                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> would                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> appear                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> be                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> some                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> form                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ordinary                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> eastern                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> or                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> bubonic                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> plague\".                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['Who shared sideline duties with Evan Washburn?', 'In the United States, the game was televised by CBS, as part of a cycle between the three main broadcast television partners of the NFL.']\n",
      "GT target: 0\n",
      "word attr tensor([-2.4679e-01,  3.0539e-02, -7.6253e-04,  2.1786e-02,  1.5375e-01,\n",
      "        -3.9642e-02, -1.5022e-03,  7.1946e-02, -3.0963e-02,  3.5575e-01,\n",
      "        -3.2321e-01,  1.0548e-01,  2.4530e-01,  9.6338e-02,  4.8007e-02,\n",
      "        -6.1826e-01,  8.5038e-03,  6.9226e-02,  5.1297e-02, -3.9808e-02,\n",
      "         1.9296e-01, -7.8887e-02, -1.9337e-02,  1.7841e-01,  1.2111e-01,\n",
      "        -2.9602e-02,  5.5690e-02, -3.9709e-02, -2.3146e-02,  3.3205e-02,\n",
      "         1.2785e-01,  2.5333e-03,  1.2079e-03, -1.8718e-02,  9.2810e-02,\n",
      "         8.1311e-02,  6.6002e-02,  8.9550e-03, -5.9939e-02,  2.0529e-01,\n",
      "         1.4657e-01,  1.8209e-06], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(-0.2468, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0305, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0008, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0878, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0396, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0015, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0719, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0804, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1055, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2453, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0963, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0480, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.6183, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0389, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0513, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0398, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1930, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0789, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0193, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1498, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0296, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0557, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0397, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0231, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0332, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1278, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0025, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0012, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0187, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0928, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0813, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0660, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0090, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0599, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1759, device='cuda:0', grad_fn=<DivBackward0>), tensor(1.8209e-06, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'who', 'shared', 'side', 'line', 'duties', 'with', 'evan', 'wash', 'burn', '?', '[SEP]', '[SEP]', 'in', 'the', 'united', 'states', ',', 'the', 'game', 'was', 'televised', 'by', 'cbs', ',', 'as', 'part', 'of', 'a', 'cycle', 'between', 'the', 'three', 'main', 'broadcast', 'television', 'partners', 'of', 'the', 'nfl', '.', '[SEP]']\n",
      "len conti_raw 36\n",
      "conti_raw ['[CLS]', 'who', 'shared', 'sideline', 'duties', 'with', 'evan', 'washburn?', '[SEP]', '[SEP]', 'in', 'the', 'united', 'states,', 'the', 'game', 'was', 'televised', 'by', 'cbs,', 'as', 'part', 'of', 'a', 'cycle', 'between', 'the', 'three', 'main', 'broadcast', 'television', 'partners', 'of', 'the', 'nfl.', '[SEP]']\n",
      "pred_prob 0.9370878338813782\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.94)</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>1.00</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> who                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> shared                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> sideline                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> duties                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> with                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> evan                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> washburn?                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 76%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> united                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> states,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> game                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> televised                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> by                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> cbs,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> part                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> cycle                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> between                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> three                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> main                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> broadcast                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> television                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> partners                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> nfl.                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['Who was added to party as Washington went on the way?', 'Washington left with a small party, picking up along the way Jacob Van Braam as an interpreter; Christopher Gist, a company surveyor working in the area; and a few Mingo led by Tanaghrisson.']\n",
      "GT target: 1\n",
      "word attr tensor([-1.4564e-01,  3.0722e-02, -2.4900e-02,  4.7872e-02, -5.7249e-03,\n",
      "         1.4348e-01,  3.3142e-02,  8.5666e-03,  1.0608e-02, -4.7759e-03,\n",
      "         4.7360e-05,  7.4177e-02, -3.6079e-01, -4.4730e-01, -2.3973e-01,\n",
      "         1.3905e-01,  3.0961e-02, -6.8741e-03,  5.1501e-02, -4.6229e-02,\n",
      "         1.8271e-01,  1.0361e-01,  3.0205e-02, -1.5341e-02,  4.9237e-02,\n",
      "        -9.9976e-02,  1.0068e-01, -5.8617e-02,  2.2561e-02,  6.5729e-02,\n",
      "         1.3069e-01, -8.7377e-02, -7.3516e-03, -2.0081e-01,  4.0140e-02,\n",
      "         1.3831e-01,  4.6900e-02,  1.4892e-02,  4.6692e-02, -5.4148e-04,\n",
      "         9.1417e-02, -3.6207e-01, -9.4159e-03,  4.2486e-02, -8.7413e-03,\n",
      "        -1.7713e-01,  2.5510e-01,  2.3417e-01, -5.7121e-02,  3.2625e-02,\n",
      "         5.7523e-02, -8.4298e-02,  1.0608e-01,  1.6356e-01, -4.6264e-02,\n",
      "         5.2868e-02,  7.0386e-02,  8.1066e-02, -2.3867e-02,  7.5147e-02],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(-0.1456, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0307, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0249, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0479, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0057, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1435, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0331, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0086, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0106, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0048, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(4.7360e-05, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1433, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.4473, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2397, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1390, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0310, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0069, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0515, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0462, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1432, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0302, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0153, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0492, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1000, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1007, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0586, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0226, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0982, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0874, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0074, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0803, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1383, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0388, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0005, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0914, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.3621, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0094, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0425, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0087, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0390, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.2342, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0571, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0326, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0134, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1061, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1636, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0175, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0751, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'who', 'was', 'added', 'to', 'party', 'as', 'washington', 'went', 'on', 'the', 'way', '?', '[SEP]', '[SEP]', 'washington', 'left', 'with', 'a', 'small', 'party', ',', 'picking', 'up', 'along', 'the', 'way', 'jacob', 'van', 'bra', 'am', 'as', 'an', 'interpreter', ';', 'christopher', 'gi', 'st', ',', 'a', 'company', 'surveyor', 'working', 'in', 'the', 'area', ';', 'and', 'a', 'few', 'ming', 'o', 'led', 'by', 'tan', 'agh', 'ris', 'son', '.', '[SEP]']\n",
      "len conti_raw 48\n",
      "conti_raw ['[CLS]', 'who', 'was', 'added', 'to', 'party', 'as', 'washington', 'went', 'on', 'the', 'way?', '[SEP]', '[SEP]', 'washington', 'left', 'with', 'a', 'small', 'party,', 'picking', 'up', 'along', 'the', 'way', 'jacob', 'van', 'braam', 'as', 'an', 'interpreter;', 'christopher', 'gist,', 'a', 'company', 'surveyor', 'working', 'in', 'the', 'area;', 'and', 'a', 'few', 'mingo', 'led', 'by', 'tanaghrisson.', '[SEP]']\n",
      "pred_prob 0.8867630362510681\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.89)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>0.28</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> who                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> added                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> party                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> washington                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> went                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> on                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> way?                    </font></mark><mark style=\"background-color: hsl(0, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> washington                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> left                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> with                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> small                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> party,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> picking                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> up                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> along                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> way                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> jacob                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> van                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> braam                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> an                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> interpreter;                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> christopher                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> gist,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> company                    </font></mark><mark style=\"background-color: hsl(0, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> surveyor                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> working                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> area;                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> few                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> mingo                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> led                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> by                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> tanaghrisson.                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['What did Queen Elizabeth II open in Newcastle in 1981?', \"It was opened in five phases between 1980 and 1984, and was Britain's first urban light rail transit system; two extensions were opened in 1991 and 2002.\"]\n",
      "GT target: 0\n",
      "word attr tensor([-0.1429, -0.1179,  0.0050,  0.3993,  0.0308, -0.0607,  0.0352,  0.1857,\n",
      "        -0.1090,  0.0548, -0.0821,  0.1181, -0.0031, -0.0023, -0.0876, -0.0645,\n",
      "         0.0562, -0.1431,  0.1176,  0.2090,  0.0055, -0.2195, -0.0151, -0.0939,\n",
      "         0.1057,  0.0007,  0.0285,  0.1379,  0.0663, -0.0533,  0.1004, -0.1489,\n",
      "         0.0236, -0.0762, -0.1399, -0.0039,  0.1369, -0.1827, -0.0271, -0.0204,\n",
      "        -0.0614,  0.0636, -0.0104,  0.1145, -0.0961,  0.5230, -0.3556],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(-0.1429, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1179, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0050, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.3993, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0308, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0607, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0352, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1857, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1090, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0548, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0180, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0031, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0023, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0876, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0645, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0562, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1431, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1176, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2090, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0055, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2195, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0151, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0059, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0007, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0285, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0244, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1004, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1489, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0236, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0762, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1399, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0665, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1827, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0271, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0204, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0614, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0636, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0104, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1145, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2135, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.3556, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'what', 'did', 'queen', 'elizabeth', 'ii', 'open', 'in', 'newcastle', 'in', '1981', '?', '[SEP]', '[SEP]', 'it', 'was', 'opened', 'in', 'five', 'phases', 'between', '1980', 'and', '1984', ',', 'and', 'was', 'britain', \"'\", 's', 'first', 'urban', 'light', 'rail', 'transit', 'system', ';', 'two', 'extensions', 'were', 'opened', 'in', '1991', 'and', '2002', '.', '[SEP]']\n",
      "len conti_raw 41\n",
      "conti_raw ['[CLS]', 'what', 'did', 'queen', 'elizabeth', 'ii', 'open', 'in', 'newcastle', 'in', '1981?', '[SEP]', '[SEP]', 'it', 'was', 'opened', 'in', 'five', 'phases', 'between', '1980', 'and', '1984,', 'and', 'was', \"britain's\", 'first', 'urban', 'light', 'rail', 'transit', 'system;', 'two', 'extensions', 'were', 'opened', 'in', '1991', 'and', '2002.', '[SEP]']\n",
      "pred_prob 0.8243213295936584\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.82)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>0.20</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> what                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> did                    </font></mark><mark style=\"background-color: hsl(120, 75%, 81%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> queen                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> elizabeth                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ii                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> open                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> newcastle                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 1981?                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> it                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> opened                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> five                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> phases                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> between                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 1980                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 1984,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> britain's                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> first                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> urban                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> light                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> rail                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> transit                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> system;                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> two                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> extensions                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> were                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> opened                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 1991                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 2002.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['What writing inspired the name Great Yuan?', 'Furthermore, the Yuan is sometimes known as the \"Empire of the Great Khan\" or \"Khanate of the Great Khan\", which particularly appeared on some Yuan maps, since Yuan emperors held the nominal title of Great Khan.']\n",
      "GT target: 0\n",
      "word attr tensor([-0.0515,  0.2624,  0.0360,  0.4559,  0.1164, -0.0040, -0.0226,  0.1358,\n",
      "        -0.1820, -0.1958, -0.2457,  0.0767, -0.0815,  0.1546,  0.0290, -0.0286,\n",
      "         0.1462, -0.0950, -0.0032,  0.0161, -0.0386,  0.2614,  0.0296,  0.0097,\n",
      "        -0.0179, -0.0677, -0.0310,  0.1409,  0.0360, -0.1163,  0.0896,  0.0239,\n",
      "        -0.0123, -0.0866, -0.0613,  0.0313, -0.0930,  0.0384,  0.0825,  0.0079,\n",
      "        -0.0505,  0.0243,  0.2850,  0.2141, -0.0701,  0.0187,  0.2537,  0.0526,\n",
      "         0.0093,  0.0330, -0.0662,  0.3096,  0.0093, -0.0997, -0.1476,  0.0318,\n",
      "        -0.0024], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(-0.0515, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2624, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0360, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.4559, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1164, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0040, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0226, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0231, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1958, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2457, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0024, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1546, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0290, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0286, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1462, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0950, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0032, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0161, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0296, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0097, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0179, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0493, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1409, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0247, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0239, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0123, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0866, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0540, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0384, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0825, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0079, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0505, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0243, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2850, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0187, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2537, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0526, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0093, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0330, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0662, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.3096, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0093, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0997, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0579, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0024, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'what', 'writing', 'inspired', 'the', 'name', 'great', 'yuan', '?', '[SEP]', '[SEP]', 'furthermore', ',', 'the', 'yuan', 'is', 'sometimes', 'known', 'as', 'the', '\"', 'empire', 'of', 'the', 'great', 'khan', '\"', 'or', '\"', 'khan', 'ate', 'of', 'the', 'great', 'khan', '\"', ',', 'which', 'particularly', 'appeared', 'on', 'some', 'yuan', 'maps', ',', 'since', 'yuan', 'emperors', 'held', 'the', 'nominal', 'title', 'of', 'great', 'khan', '.', '[SEP]']\n",
      "len conti_raw 47\n",
      "conti_raw ['[CLS]', 'what', 'writing', 'inspired', 'the', 'name', 'great', 'yuan?', '[SEP]', '[SEP]', 'furthermore,', 'the', 'yuan', 'is', 'sometimes', 'known', 'as', 'the', '\"empire', 'of', 'the', 'great', 'khan\"', 'or', '\"khanate', 'of', 'the', 'great', 'khan\",', 'which', 'particularly', 'appeared', 'on', 'some', 'yuan', 'maps,', 'since', 'yuan', 'emperors', 'held', 'the', 'nominal', 'title', 'of', 'great', 'khan.', '[SEP]']\n",
      "pred_prob 0.9457733035087585\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.95)</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>1.55</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> what                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> writing                    </font></mark><mark style=\"background-color: hsl(120, 75%, 78%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> inspired                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> name                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> great                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> yuan?                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> furthermore,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> yuan                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> sometimes                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> known                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> \"empire                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> great                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> khan\"                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> or                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> \"khanate                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> great                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> khan\",                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> which                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> particularly                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> appeared                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> on                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> some                    </font></mark><mark style=\"background-color: hsl(120, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> yuan                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> maps,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> since                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> yuan                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> emperors                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> held                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> nominal                    </font></mark><mark style=\"background-color: hsl(120, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> title                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> great                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> khan.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['What happened to the East India Trading Company in 1767?', 'In 1599 the British East India Company was established and was chartered by Queen Elizabeth in the following year.']\n",
      "GT target: 0\n",
      "word attr tensor([ 0.0744,  0.0650,  0.0835,  0.0096,  0.0193, -0.1900,  0.0896,  0.2474,\n",
      "         0.2669, -0.3222, -0.3924, -0.0145, -0.0752, -0.1325,  0.6041, -0.0192,\n",
      "        -0.2238, -0.0504, -0.0660, -0.1489,  0.0529,  0.1132, -0.0419,  0.0646,\n",
      "        -0.0329, -0.0129,  0.0703,  0.0371, -0.0115,  0.1166,  0.0502, -0.0416,\n",
      "         0.0094, -0.0210,  0.0613,  0.1705], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(0.0744, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0650, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0835, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0096, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0193, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1900, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0896, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2474, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2669, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.3222, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2034, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0752, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1325, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.6041, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1215, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0504, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0660, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1489, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0529, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1132, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0419, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0646, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0329, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0129, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0703, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0371, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0115, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1166, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0502, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0416, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0094, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0202, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1705, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'what', 'happened', 'to', 'the', 'east', 'india', 'trading', 'company', 'in', '1767', '?', '[SEP]', '[SEP]', 'in', '159', '9', 'the', 'british', 'east', 'india', 'company', 'was', 'established', 'and', 'was', 'chartered', 'by', 'queen', 'elizabeth', 'in', 'the', 'following', 'year', '.', '[SEP]']\n",
      "len conti_raw 33\n",
      "conti_raw ['[CLS]', 'what', 'happened', 'to', 'the', 'east', 'india', 'trading', 'company', 'in', '1767?', '[SEP]', '[SEP]', 'in', '1599', 'the', 'british', 'east', 'india', 'company', 'was', 'established', 'and', 'was', 'chartered', 'by', 'queen', 'elizabeth', 'in', 'the', 'following', 'year.', '[SEP]']\n",
      "pred_prob 0.7392330169677734\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.74)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>0.41</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> what                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> happened                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> east                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> india                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> trading                    </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> company                    </font></mark><mark style=\"background-color: hsl(0, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 1767?                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 70%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 1599                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> british                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> east                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> india                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> company                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> established                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> chartered                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> by                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> queen                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> elizabeth                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> following                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> year.                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['The principle of faunal succession was developed 100 years before whose theory of evolution?', \"Based on principles laid out by William Smith almost a hundred years before the publication of Charles Darwin's theory of evolution, the principles of succession were developed independently of evolutionary thought.\"]\n",
      "GT target: 1\n",
      "word attr tensor([ 0.3175, -0.1711, -0.0305, -0.0865,  0.0844, -0.0788, -0.0181, -0.0656,\n",
      "         0.0537, -0.0153, -0.0781,  0.1700, -0.1341, -0.1746,  0.0501,  0.0718,\n",
      "        -0.0980, -0.1329, -0.3224,  0.0180,  0.1586, -0.0553,  0.0170,  0.1311,\n",
      "         0.0745,  0.0025, -0.0300, -0.0335, -0.0051,  0.0646,  0.0806, -0.0345,\n",
      "         0.1329, -0.1218,  0.0398, -0.2245, -0.1451,  0.1604,  0.3186, -0.3007,\n",
      "        -0.0467, -0.0987, -0.0814,  0.0611, -0.0854, -0.1520,  0.0324, -0.0558,\n",
      "         0.0735, -0.0127, -0.2163, -0.0579,  0.0247, -0.1505, -0.3061],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(0.3175, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1711, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0305, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0865, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0028, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0181, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0656, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0537, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0153, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0781, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1700, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1341, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1746, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0501, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0131, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1329, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.3224, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0180, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1586, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0553, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0170, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1311, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0745, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0025, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0300, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0335, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0051, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0646, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0806, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0345, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1329, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1218, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0398, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2245, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1631, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.3007, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0467, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0900, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0611, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0854, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1520, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0324, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0558, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0735, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0127, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2163, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0579, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0629, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.3061, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'the', 'principle', 'of', 'fauna', 'l', 'succession', 'was', 'developed', '100', 'years', 'before', 'whose', 'theory', 'of', 'evolution', '?', '[SEP]', '[SEP]', 'based', 'on', 'principles', 'laid', 'out', 'by', 'william', 'smith', 'almost', 'a', 'hundred', 'years', 'before', 'the', 'publication', 'of', 'charles', 'darwin', \"'\", 's', 'theory', 'of', 'evolution', ',', 'the', 'principles', 'of', 'succession', 'were', 'developed', 'independently', 'of', 'evolutionary', 'thought', '.', '[SEP]']\n",
      "len conti_raw 49\n",
      "conti_raw ['[CLS]', 'the', 'principle', 'of', 'faunal', 'succession', 'was', 'developed', '100', 'years', 'before', 'whose', 'theory', 'of', 'evolution?', '[SEP]', '[SEP]', 'based', 'on', 'principles', 'laid', 'out', 'by', 'william', 'smith', 'almost', 'a', 'hundred', 'years', 'before', 'the', 'publication', 'of', 'charles', \"darwin's\", 'theory', 'of', 'evolution,', 'the', 'principles', 'of', 'succession', 'were', 'developed', 'independently', 'of', 'evolutionary', 'thought.', '[SEP]']\n",
      "pred_prob 0.3316514492034912\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment (0.33)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>-1.48</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> principle                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> faunal                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> succession                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> developed                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 100                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> years                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> before                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> whose                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> theory                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> evolution?                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> based                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> on                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> principles                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> laid                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> out                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> by                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> william                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> smith                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> almost                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hundred                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> years                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> before                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> publication                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> charles                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> darwin's                    </font></mark><mark style=\"background-color: hsl(0, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> theory                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> evolution,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> principles                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> succession                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> were                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> developed                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> independently                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> evolutionary                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> thought.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['How many times did Luther preach in Halle in 1545 and 1546?', 'In 1545 and 1546 Luther preached three times in the Market Church in Halle, staying with his friend Justus Jonas during Christmas.']\n",
      "GT target: 1\n",
      "word attr tensor([ 0.2357, -0.0856,  0.1613,  0.0221,  0.1189, -0.2768,  0.0202,  0.1749,\n",
      "         0.0873,  0.1590, -0.2555,  0.0155,  0.0907, -0.0772,  0.1580, -0.5121,\n",
      "         0.0728,  0.1113,  0.2282, -0.0560, -0.1002,  0.0972, -0.0814, -0.1457,\n",
      "        -0.0089, -0.1188, -0.0090,  0.2151,  0.0801, -0.0151,  0.1260, -0.1436,\n",
      "         0.1963, -0.1258,  0.0025, -0.1292, -0.0091, -0.0094, -0.1964, -0.0382,\n",
      "         0.1496, -0.0685,  0.0800,  0.0798,  0.0853,  0.0826], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(0.2357, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0856, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1613, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0221, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1189, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2768, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0202, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1749, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0873, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1590, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1200, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0907, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2359, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0728, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1113, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2282, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0781, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0972, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1135, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0089, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1188, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0090, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2151, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0801, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0151, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1260, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1436, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1963, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0616, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1292, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0091, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0094, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1964, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0557, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0685, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0800, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0826, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0826, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'how', 'many', 'times', 'did', 'luther', 'preach', 'in', 'halle', 'in', '154', '5', 'and', '154', '6', '?', '[SEP]', '[SEP]', 'in', '154', '5', 'and', '154', '6', 'luther', 'preached', 'three', 'times', 'in', 'the', 'market', 'church', 'in', 'halle', ',', 'staying', 'with', 'his', 'friend', 'just', 'us', 'jonas', 'during', 'christmas', '.', '[SEP]']\n",
      "len conti_raw 38\n",
      "conti_raw ['[CLS]', 'how', 'many', 'times', 'did', 'luther', 'preach', 'in', 'halle', 'in', '1545', 'and', '1546?', '[SEP]', '[SEP]', 'in', '1545', 'and', '1546', 'luther', 'preached', 'three', 'times', 'in', 'the', 'market', 'church', 'in', 'halle,', 'staying', 'with', 'his', 'friend', 'justus', 'jonas', 'during', 'christmas.', '[SEP]']\n",
      "pred_prob 0.909346342086792\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.91)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>0.39</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> how                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> many                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> times                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> did                    </font></mark><mark style=\"background-color: hsl(0, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> luther                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> preach                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> halle                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 1545                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 1546?                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 1545                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 1546                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> luther                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> preached                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> three                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> times                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> market                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> church                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> halle,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> staying                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> with                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> his                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> friend                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> justus                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> jonas                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> during                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> christmas.                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['What part of the Rhine flows through North Rhine-Westphalia?', 'Here the Rhine flows through the largest conurbation in Germany, the Rhine-Ruhr region.']\n",
      "GT target: 0\n",
      "word attr tensor([-0.2017,  0.0393, -0.1332, -0.0104,  0.0294, -0.0394, -0.0785, -0.0418,\n",
      "        -0.1237,  0.0448,  0.0040, -0.1160,  0.1668,  0.0762,  0.5360, -0.4220,\n",
      "        -0.2415,  0.0874,  0.0435, -0.0954, -0.0807,  0.1345,  0.1087, -0.0792,\n",
      "         0.3954,  0.0151, -0.2431, -0.1179,  0.1200,  0.0170,  0.0704, -0.0748,\n",
      "         0.1083, -0.0015, -0.0417,  0.1088], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(-0.2017, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0393, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1332, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0104, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0294, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0394, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0785, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0418, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1237, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0605, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0762, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.5360, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.4220, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2415, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0874, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0435, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0954, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0807, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1345, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2051, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0151, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1805, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1200, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0464, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0216, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1088, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'what', 'part', 'of', 'the', 'rhine', 'flows', 'through', 'north', 'rhine', '-', 'westphalia', '?', '[SEP]', '[SEP]', 'here', 'the', 'rhine', 'flows', 'through', 'the', 'largest', 'con', 'ur', 'bation', 'in', 'germany', ',', 'the', 'rhine', '-', 'ru', 'hr', 'region', '.', '[SEP]']\n",
      "len conti_raw 26\n",
      "conti_raw ['[CLS]', 'what', 'part', 'of', 'the', 'rhine', 'flows', 'through', 'north', 'rhine-westphalia?', '[SEP]', '[SEP]', 'here', 'the', 'rhine', 'flows', 'through', 'the', 'largest', 'conurbation', 'in', 'germany,', 'the', 'rhine-ruhr', 'region.', '[SEP]']\n",
      "pred_prob 0.7328494191169739\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.73)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>-0.04</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> what                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> part                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> rhine                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> flows                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> through                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> north                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> rhine-westphalia?                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 74%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> here                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> rhine                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> flows                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> through                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> largest                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> conurbation                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> germany,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> rhine-ruhr                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> region.                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['What is the most important thing apicoplasts do?', 'The most important apicoplast function is isopentenyl pyrophosphate synthesis—in fact, apicomplexans die when something interferes with this apicoplast function, and when apicomplexans are grown in an isopentenyl pyrophosphate-rich medium, they dump the organelle.']\n",
      "GT target: 1\n",
      "word attr tensor([ 2.3665e-01, -1.6204e-01,  3.4930e-03,  2.5884e-02,  3.7798e-02,\n",
      "        -3.2547e-03, -2.4182e-01, -4.2485e-02,  1.8996e-01,  2.3087e-02,\n",
      "         4.9893e-02,  4.9627e-02, -9.4926e-02, -1.0012e-01,  5.7768e-02,\n",
      "        -1.9041e-01, -9.8339e-02,  1.4886e-01, -8.9620e-02,  5.3609e-02,\n",
      "         9.9374e-02, -6.4204e-02, -3.1820e-02, -1.9704e-01,  2.5178e-03,\n",
      "        -8.1230e-02,  7.0688e-03,  8.2892e-02, -1.8923e-02,  3.2325e-02,\n",
      "        -5.3076e-02, -1.8174e-02,  1.7703e-01, -4.2283e-01, -1.2265e-01,\n",
      "        -7.0287e-02, -1.7832e-02, -1.0674e-02, -6.3931e-02, -3.2887e-04,\n",
      "        -6.6162e-02, -7.1197e-02,  9.4055e-02,  6.4153e-02,  4.0869e-02,\n",
      "         1.1863e-01,  8.0209e-02,  1.0127e-01,  2.5201e-02,  6.4254e-03,\n",
      "        -1.2384e-04,  1.3128e-02, -1.3043e-01, -2.6359e-02, -1.2246e-02,\n",
      "        -1.6262e-02, -9.3276e-03, -5.7608e-02, -7.3676e-02, -6.4267e-02,\n",
      "        -9.7455e-02, -2.0008e-02,  2.9155e-02, -6.2164e-02, -2.1226e-02,\n",
      "         3.0093e-02,  8.5846e-03, -3.4613e-02,  4.0006e-02, -4.9818e-02,\n",
      "        -3.0656e-02, -6.0130e-03, -4.6516e-03,  3.9527e-02, -1.2554e-01,\n",
      "         2.3520e-02, -1.2575e-02,  2.6986e-02, -1.3888e-02,  3.0049e-01,\n",
      "         7.1722e-02,  8.2635e-02, -3.5418e-01, -8.0166e-02,  2.0716e-01,\n",
      "         2.7555e-02], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(0.2367, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1620, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0035, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0259, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0378, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0033, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2418, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0494, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0975, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0578, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1904, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0983, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1489, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0896, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0128, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1970, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0025, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1707, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0571, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0373, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0209, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0642, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0409, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1186, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0252, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0064, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0442, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0143, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0093, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0576, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0516, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0292, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0622, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0212, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0301, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0182, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0143, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0065, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.3005, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0717, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0826, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0050, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0276, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'what', 'is', 'the', 'most', 'important', 'thing', 'api', 'co', 'pl', 'ast', 's', 'do', '?', '[SEP]', '[SEP]', 'the', 'most', 'important', 'api', 'co', 'pl', 'ast', 'function', 'is', 'iso', 'pen', 'ten', 'yl', 'p', 'yr', 'op', 'hos', 'phate', 'synthesis', '—', 'in', 'fact', ',', 'api', 'com', 'plex', 'ans', 'die', 'when', 'something', 'interfere', 's', 'with', 'this', 'api', 'co', 'pl', 'ast', 'function', ',', 'and', 'when', 'api', 'com', 'plex', 'ans', 'are', 'grown', 'in', 'an', 'iso', 'pen', 'ten', 'yl', 'p', 'yr', 'op', 'hos', 'phate', '-', 'rich', 'medium', ',', 'they', 'dump', 'the', 'organ', 'elle', '.', '[SEP]']\n",
      "len conti_raw 45\n",
      "conti_raw ['[CLS]', 'what', 'is', 'the', 'most', 'important', 'thing', 'apicoplasts', 'do?', '[SEP]', '[SEP]', 'the', 'most', 'important', 'apicoplast', 'function', 'is', 'isopentenyl', 'pyrophosphate', 'synthesis—in', 'fact,', 'apicomplexans', 'die', 'when', 'something', 'interferes', 'with', 'this', 'apicoplast', 'function,', 'and', 'when', 'apicomplexans', 'are', 'grown', 'in', 'an', 'isopentenyl', 'pyrophosphate-rich', 'medium,', 'they', 'dump', 'the', 'organelle.', '[SEP]']\n",
      "pred_prob 0.7642964720726013\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.76)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>-0.93</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> what                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> most                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> important                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> thing                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> apicoplasts                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> do?                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> most                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> important                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> apicoplast                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> function                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> isopentenyl                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pyrophosphate                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> synthesis—in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> fact,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> apicomplexans                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> die                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> when                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> something                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> interferes                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> with                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> this                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> apicoplast                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> function,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> when                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> apicomplexans                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> are                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> grown                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> an                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> isopentenyl                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pyrophosphate-rich                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> medium,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> they                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> dump                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> organelle.                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: [\"When did ABC begin airing Dick Clark's New Year's Rockin' Eve?\", \"Since 1974, ABC has generally aired Dick Clark's New Year's Rockin' Eve on New Year's Eve (hosted first by its creator Dick Clark, and later by his successor Ryan Seacrest); the only exception was in 1999, when ABC put it on a one-year hiatus to provide coverage of the international millennium festivities, though Clark's traditional countdown from Times Square was still featured within the coverage.\"]\n",
      "GT target: 1\n",
      "word attr tensor([ 0.1482,  0.0488,  0.0354, -0.1185, -0.0493, -0.0528,  0.0010,  0.0368,\n",
      "        -0.0041, -0.0140,  0.0112,  0.0474, -0.0334, -0.0410,  0.0831,  0.0041,\n",
      "        -0.0683,  0.0792, -0.0169, -0.3009, -0.2616, -0.0254,  0.0893, -0.0314,\n",
      "        -0.1308, -0.0478,  0.0408,  0.0696, -0.0534,  0.0085, -0.0098, -0.0522,\n",
      "         0.0044, -0.0087, -0.0359,  0.0231,  0.0307,  0.0203, -0.0039,  0.0293,\n",
      "        -0.0388,  0.0108, -0.0670,  0.0627,  0.0137,  0.0822, -0.1148, -0.0234,\n",
      "         0.0529, -0.0175,  0.0450,  0.0137,  0.0172, -0.0645,  0.0187,  0.0186,\n",
      "        -0.0107, -0.1228,  0.0366,  0.0266, -0.0541, -0.2152, -0.1525,  0.0450,\n",
      "        -0.1238, -0.1007,  0.1406, -0.2600,  0.2206,  0.2528, -0.3557,  0.1220,\n",
      "         0.0779,  0.0376,  0.0862,  0.0553, -0.0438,  0.0538, -0.0323,  0.0716,\n",
      "         0.0095,  0.0780,  0.0107,  0.0080, -0.0812, -0.0141,  0.0071,  0.0051,\n",
      "         0.0059, -0.0425, -0.0143,  0.0503, -0.1403,  0.1294,  0.0129,  0.2641,\n",
      "        -0.0749,  0.0701, -0.0642,  0.0317, -0.0106,  0.0495, -0.1249,  0.0344,\n",
      "         0.0926, -0.1356, -0.0984, -0.0386], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(0.1482, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0488, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0354, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1185, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0493, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0528, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0010, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0112, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0170, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0123, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0311, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.3009, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2616, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0254, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0289, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1308, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0478, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0408, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0696, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0534, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0264, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0044, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0108, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0293, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0388, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0108, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0058, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0822, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0691, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0529, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0175, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0450, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0137, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0172, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0229, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0186, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0107, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1228, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0366, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0266, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0541, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0966, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1007, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1406, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2600, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2206, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2528, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1168, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0779, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0376, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0862, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0553, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0438, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0538, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0146, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0780, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0107, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0080, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0812, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0141, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0071, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0051, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0059, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0284, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0503, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.2641, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0749, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0701, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0642, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0317, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0106, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0495, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1249, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0344, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0926, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1170, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0386, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'when', 'did', 'abc', 'begin', 'airing', 'dick', 'clark', \"'\", 's', 'new', 'year', \"'\", 's', 'rock', 'in', \"'\", 'eve', '?', '[SEP]', '[SEP]', 'since', '1974', ',', 'abc', 'has', 'generally', 'aired', 'dick', 'clark', \"'\", 's', 'new', 'year', \"'\", 's', 'rock', 'in', \"'\", 'eve', 'on', 'new', 'year', \"'\", 's', 'eve', '(', 'hosted', 'first', 'by', 'its', 'creator', 'dick', 'clark', ',', 'and', 'later', 'by', 'his', 'successor', 'ryan', 'sea', 'crest', ')', ';', 'the', 'only', 'exception', 'was', 'in', '1999', ',', 'when', 'abc', 'put', 'it', 'on', 'a', 'one', '-', 'year', 'hiatus', 'to', 'provide', 'coverage', 'of', 'the', 'international', 'millennium', 'festivities', ',', 'though', 'clark', \"'\", 's', 'traditional', 'countdown', 'from', 'times', 'square', 'was', 'still', 'featured', 'within', 'the', 'coverage', '.', '[SEP]']\n",
      "len conti_raw 80\n",
      "conti_raw ['[CLS]', 'when', 'did', 'abc', 'begin', 'airing', 'dick', \"clark's\", 'new', \"year's\", \"rockin'\", 'eve?', '[SEP]', '[SEP]', 'since', '1974,', 'abc', 'has', 'generally', 'aired', 'dick', \"clark's\", 'new', \"year's\", \"rockin'\", 'eve', 'on', 'new', \"year's\", 'eve', '(hosted', 'first', 'by', 'its', 'creator', 'dick', 'clark,', 'and', 'later', 'by', 'his', 'successor', 'ryan', 'seacrest);', 'the', 'only', 'exception', 'was', 'in', '1999,', 'when', 'abc', 'put', 'it', 'on', 'a', 'one-year', 'hiatus', 'to', 'provide', 'coverage', 'of', 'the', 'international', 'millennium', 'festivities,', 'though', \"clark's\", 'traditional', 'countdown', 'from', 'times', 'square', 'was', 'still', 'featured', 'within', 'the', 'coverage.', '[SEP]']\n",
      "pred_prob 0.7005867958068848\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.70)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>-0.76</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> when                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> did                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> abc                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> begin                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> airing                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> dick                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> clark's                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> new                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> year's                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> rockin'                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> eve?                    </font></mark><mark style=\"background-color: hsl(0, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> since                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 1974,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> abc                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> has                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> generally                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> aired                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> dick                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> clark's                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> new                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> year's                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> rockin'                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> eve                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> on                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> new                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> year's                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> eve                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> (hosted                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> first                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> by                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> its                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> creator                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> dick                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> clark,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> later                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> by                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> his                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> successor                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ryan                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> seacrest);                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> only                    </font></mark><mark style=\"background-color: hsl(0, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> exception                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 1999,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> when                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> abc                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> put                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> it                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> on                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> one-year                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hiatus                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> provide                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> coverage                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> international                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> millennium                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> festivities,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> though                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> clark's                    </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> traditional                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> countdown                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> from                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> times                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> square                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> still                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> featured                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> within                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> coverage.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['The Kronenberg Palace had been an exceptional example of what type of architecture?', 'Despite that the Warsaw University of Technology building (1899–1902) is the most interesting of the late 19th-century architecture.']\n",
      "GT target: 0\n",
      "word attr tensor([ 0.3058, -0.0731,  0.0797,  0.0201, -0.0674,  0.0939, -0.0377,  0.0396,\n",
      "        -0.1091, -0.1941, -0.0475, -0.1220,  0.1548,  0.1257, -0.0355,  0.0654,\n",
      "         0.1146, -0.1434, -0.4570,  0.3473, -0.1111, -0.0424,  0.1035,  0.0140,\n",
      "        -0.2954,  0.1938,  0.2364,  0.0718, -0.0188, -0.1431,  0.0143,  0.0829,\n",
      "        -0.0520, -0.0717, -0.1991, -0.0410, -0.2263, -0.0748,  0.1271, -0.0408,\n",
      "         0.0866,  0.0048,  0.0211,  0.1463,  0.1037], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(0.3058, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0731, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0087, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0939, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0377, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0396, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1091, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1941, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0475, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1220, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1548, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1257, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0355, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1434, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.4570, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.3473, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1111, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0424, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1035, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0140, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2954, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1938, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2364, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0305, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0520, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0717, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1991, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0410, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2263, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0748, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1271, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0139, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1037, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'the', 'k', 'rone', 'nberg', 'palace', 'had', 'been', 'an', 'exceptional', 'example', 'of', 'what', 'type', 'of', 'architecture', '?', '[SEP]', '[SEP]', 'despite', 'that', 'the', 'warsaw', 'university', 'of', 'technology', 'building', '(', '1899', '–', '1902', ')', 'is', 'the', 'most', 'interesting', 'of', 'the', 'late', '19th', '-', 'century', 'architecture', '.', '[SEP]']\n",
      "len conti_raw 35\n",
      "conti_raw ['[CLS]', 'the', 'kronenberg', 'palace', 'had', 'been', 'an', 'exceptional', 'example', 'of', 'what', 'type', 'of', 'architecture?', '[SEP]', '[SEP]', 'despite', 'that', 'the', 'warsaw', 'university', 'of', 'technology', 'building', '(1899–1902)', 'is', 'the', 'most', 'interesting', 'of', 'the', 'late', '19th-century', 'architecture.', '[SEP]']\n",
      "pred_prob 0.5980805158615112\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.60)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>-0.05</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> kronenberg                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> palace                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> had                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> been                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> an                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> exceptional                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> example                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> what                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> type                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> architecture?                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 82%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> despite                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> that                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> warsaw                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> university                    </font></mark><mark style=\"background-color: hsl(0, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> technology                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> building                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> (1899–1902)                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> most                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> interesting                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> late                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 19th-century                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> architecture.                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['What was the definition of professionals, for this study?', 'It is important to note, however, that the British study referenced above is the only one of its kind and consisted of \"a random ... probability sample of 2,869 young people between the ages of 18 and 24 in a computer-assisted study\" and that the questions referred to \"sexual abuse with a professional,\" not necessarily a teacher.']\n",
      "GT target: 0\n",
      "word attr tensor([ 0.0678, -0.0111, -0.1101,  0.1280, -0.0680, -0.0261, -0.1090, -0.1033,\n",
      "        -0.1056, -0.0216,  0.0895, -0.0630,  0.1129,  0.0426,  0.0291, -0.1225,\n",
      "         0.0244, -0.0659, -0.0469, -0.0117, -0.0548, -0.1263, -0.1454, -0.0252,\n",
      "         0.0155,  0.1403,  0.0654, -0.0554, -0.1770, -0.0327,  0.0186,  0.0054,\n",
      "         0.0082,  0.0394, -0.0996, -0.0258,  0.0458, -0.0427, -0.0236, -0.0091,\n",
      "        -0.0549, -0.0575, -0.0688, -0.1077, -0.1220, -0.0083,  0.0402, -0.0608,\n",
      "         0.0038, -0.0265, -0.0940,  0.0589, -0.0451, -0.1536,  0.0603, -0.0310,\n",
      "        -0.0326,  0.0551, -0.0079,  0.0464, -0.0235,  0.0081,  0.1844, -0.0336,\n",
      "         0.0368,  0.0326,  0.0934,  0.0825, -0.0718,  0.0636, -0.4186,  0.0501,\n",
      "         0.3751,  0.0647,  0.0089, -0.1474,  0.0194,  0.0551,  0.1484, -0.1907,\n",
      "         0.1727,  0.1217, -0.1330,  0.3388,  0.1019, -0.0992, -0.0323],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(0.0678, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0111, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1101, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1280, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0680, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0261, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1062, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1056, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0216, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0132, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1129, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0426, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0291, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1225, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0244, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0659, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0293, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0906, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1454, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0252, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0155, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1403, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0654, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0554, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1770, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0327, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0186, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0054, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0082, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0394, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0996, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0258, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0458, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0427, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0164, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0549, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0855, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1220, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0083, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0402, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0607, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0589, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0451, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1536, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0603, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0310, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0326, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0551, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0079, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0464, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0235, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0081, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0561, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0630, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0825, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0718, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0636, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.4186, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0501, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.3751, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0368, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1474, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0194, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0551, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0757, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1217, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1330, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.3388, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0323, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'what', 'was', 'the', 'definition', 'of', 'professionals', ',', 'for', 'this', 'study', '?', '[SEP]', '[SEP]', 'it', 'is', 'important', 'to', 'note', ',', 'however', ',', 'that', 'the', 'british', 'study', 'referenced', 'above', 'is', 'the', 'only', 'one', 'of', 'its', 'kind', 'and', 'consisted', 'of', '\"', 'a', 'random', '.', '.', '.', 'probability', 'sample', 'of', '2', ',', '86', '9', 'young', 'people', 'between', 'the', 'ages', 'of', '18', 'and', '24', 'in', 'a', 'computer', '-', 'assisted', 'study', '\"', 'and', 'that', 'the', 'questions', 'referred', 'to', '\"', 'sexual', 'abuse', 'with', 'a', 'professional', ',', '\"', 'not', 'necessarily', 'a', 'teacher', '.', '[SEP]']\n",
      "len conti_raw 70\n",
      "conti_raw ['[CLS]', 'what', 'was', 'the', 'definition', 'of', 'professionals,', 'for', 'this', 'study?', '[SEP]', '[SEP]', 'it', 'is', 'important', 'to', 'note,', 'however,', 'that', 'the', 'british', 'study', 'referenced', 'above', 'is', 'the', 'only', 'one', 'of', 'its', 'kind', 'and', 'consisted', 'of', '\"a', 'random', '...', 'probability', 'sample', 'of', '2,869', 'young', 'people', 'between', 'the', 'ages', 'of', '18', 'and', '24', 'in', 'a', 'computer-assisted', 'study\"', 'and', 'that', 'the', 'questions', 'referred', 'to', '\"sexual', 'abuse', 'with', 'a', 'professional,\"', 'not', 'necessarily', 'a', 'teacher.', '[SEP]']\n",
      "pred_prob 0.42063799500465393\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment (0.42)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>-0.65</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> what                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> definition                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> professionals,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> for                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> this                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> study?                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> it                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> important                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> note,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> however,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> that                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> british                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> study                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> referenced                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> above                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> only                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> one                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> its                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> kind                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> consisted                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> \"a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> random                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ...                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> probability                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> sample                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 2,869                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> young                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> people                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> between                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ages                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 18                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 24                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> computer-assisted                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> study\"                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> that                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> questions                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> referred                    </font></mark><mark style=\"background-color: hsl(120, 75%, 82%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> \"sexual                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> abuse                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> with                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> professional,\"                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> not                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> necessarily                    </font></mark><mark style=\"background-color: hsl(120, 75%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> teacher.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['bassett focuses on what to illustrate his idea?', 'To better illustrate this idea, Bassett focuses his analysis of the role of nineteenth-century maps during the \"scramble for Africa\".']\n",
      "GT target: 1\n",
      "word attr tensor([ 0.0604,  0.0489, -0.2172, -0.1365, -0.3883, -0.0989,  0.2456, -0.1741,\n",
      "        -0.0091, -0.4505,  0.1061,  0.0955,  0.0769,  0.0226, -0.0113,  0.0154,\n",
      "        -0.0866, -0.1968,  0.0835, -0.2817,  0.0648,  0.0466, -0.0116,  0.1072,\n",
      "         0.2018,  0.0760,  0.0221, -0.0570,  0.2996,  0.1207,  0.0692, -0.1314,\n",
      "         0.0384,  0.2133,  0.1130, -0.0639,  0.0953, -0.1392, -0.1652],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(0.0604, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0489, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2172, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1365, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.3883, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0989, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2456, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1741, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2298, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1061, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0955, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0769, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0226, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0113, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0154, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1417, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0835, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2817, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0648, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0466, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0116, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1072, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2018, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0760, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1207, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0692, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1314, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1258, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1130, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0618, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1652, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'bassett', 'focuses', 'on', 'what', 'to', 'illustrate', 'his', 'idea', '?', '[SEP]', '[SEP]', 'to', 'better', 'illustrate', 'this', 'idea', ',', 'bassett', 'focuses', 'his', 'analysis', 'of', 'the', 'role', 'of', 'nineteenth', '-', 'century', 'maps', 'during', 'the', '\"', 'scramble', 'for', 'africa', '\"', '.', '[SEP]']\n",
      "len conti_raw 32\n",
      "conti_raw ['[CLS]', 'bassett', 'focuses', 'on', 'what', 'to', 'illustrate', 'his', 'idea?', '[SEP]', '[SEP]', 'to', 'better', 'illustrate', 'this', 'idea,', 'bassett', 'focuses', 'his', 'analysis', 'of', 'the', 'role', 'of', 'nineteenth-century', 'maps', 'during', 'the', '\"scramble', 'for', 'africa\".', '[SEP]']\n",
      "pred_prob 0.5277463793754578\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.53)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>-0.40</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> bassett                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> focuses                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> on                    </font></mark><mark style=\"background-color: hsl(0, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> what                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> illustrate                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> his                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> idea?                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> better                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> illustrate                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> this                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> idea,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> bassett                    </font></mark><mark style=\"background-color: hsl(0, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> focuses                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> his                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> analysis                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> role                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> nineteenth-century                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> maps                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> during                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> \"scramble                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> for                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> africa\".                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['Where did Tesla believe his talents came from?', \"Tesla's mother, Đuka Tesla (née Mandić), whose father was also an Orthodox priest,:10 had a talent for making home craft tools, mechanical appliances, and the ability to memorize Serbian epic poems.\"]\n",
      "GT target: 0\n",
      "word attr tensor([ 0.0878,  0.0848, -0.1026,  0.0207, -0.0632, -0.0038, -0.0589, -0.1917,\n",
      "         0.2220, -0.2727, -0.1337, -0.0420, -0.0442, -0.0443, -0.0344, -0.2523,\n",
      "        -0.0307,  0.0749, -0.0469,  0.0708,  0.0254, -0.1308, -0.0401,  0.0987,\n",
      "         0.2210,  0.0549, -0.1818, -0.2664,  0.0839,  0.1563, -0.1751,  0.1317,\n",
      "         0.1301, -0.0635, -0.0683,  0.3644,  0.2307,  0.0798,  0.0447, -0.0039,\n",
      "        -0.0071, -0.0639,  0.1507,  0.2224, -0.0699,  0.0940,  0.1389,  0.0509,\n",
      "         0.0628, -0.0387,  0.0854,  0.0147, -0.0822, -0.0264, -0.0725, -0.1813,\n",
      "        -0.0895, -0.2016, -0.0239], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(0.0878, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0848, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1026, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0207, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0632, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0038, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0589, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1917, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0254, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1337, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0420, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0393, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1415, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0140, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0708, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0527, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1818, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2664, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0839, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1563, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1751, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1317, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1734, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.2307, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0798, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0447, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0039, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0071, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0639, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1507, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0763, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0940, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0949, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0628, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0387, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0854, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0147, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0543, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0725, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1813, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1455, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0239, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'where', 'did', 'tesla', 'believe', 'his', 'talents', 'came', 'from', '?', '[SEP]', '[SEP]', 'tesla', \"'\", 's', 'mother', ',', 'đ', 'uka', 'tesla', '(', 'nee', 'man', 'dic', ')', ',', 'whose', 'father', 'was', 'also', 'an', 'orthodox', 'priest', ',', ':', '10', 'had', 'a', 'talent', 'for', 'making', 'home', 'craft', 'tools', ',', 'mechanical', 'appliances', ',', 'and', 'the', 'ability', 'to', 'memo', 'rize', 'serbian', 'epic', 'poems', '.', '[SEP]']\n",
      "len conti_raw 43\n",
      "conti_raw ['[CLS]', 'where', 'did', 'tesla', 'believe', 'his', 'talents', 'came', 'from?', '[SEP]', '[SEP]', \"tesla's\", 'mother,', 'đuka', 'tesla', '(nee', 'mandic),', 'whose', 'father', 'was', 'also', 'an', 'orthodox', 'priest,:10', 'had', 'a', 'talent', 'for', 'making', 'home', 'craft', 'tools,', 'mechanical', 'appliances,', 'and', 'the', 'ability', 'to', 'memorize', 'serbian', 'epic', 'poems.', '[SEP]']\n",
      "pred_prob 0.7914941310882568\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.79)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>-0.11</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> where                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> did                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> tesla                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> believe                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> his                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> talents                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> came                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> from?                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> tesla's                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> mother,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> đuka                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> tesla                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> (nee                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> mandic),                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> whose                    </font></mark><mark style=\"background-color: hsl(0, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> father                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> also                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> an                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> orthodox                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> priest,:10                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> had                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> talent                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> for                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> making                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> home                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> craft                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> tools,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> mechanical                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> appliances,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ability                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> memorize                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> serbian                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> epic                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> poems.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['Who was given the esteemed status of MVP for Super Bowl 50?', 'Denver linebacker Von Miller was named Super Bowl MVP, recording five solo tackles, 2½ sacks, and two forced fumbles.']\n",
      "GT target: 1\n",
      "word attr tensor([ 2.0476e-01,  1.0954e-02, -1.2488e-02, -6.4944e-02,  5.4619e-02,\n",
      "        -6.9529e-02, -2.4769e-02, -1.8565e-03, -9.2744e-03, -4.1930e-02,\n",
      "         5.8074e-02, -8.6415e-02, -1.0395e-03,  1.2681e-02,  1.9648e-01,\n",
      "        -1.5156e-01, -7.2392e-01,  8.7740e-02,  2.1759e-01,  3.3761e-01,\n",
      "         5.1764e-02, -1.5253e-01,  2.0756e-02, -1.1131e-01, -4.6366e-02,\n",
      "         1.1621e-01, -7.7345e-02,  2.5053e-02,  3.8635e-02, -2.4628e-04,\n",
      "         1.7104e-01, -1.2023e-01,  1.0754e-02, -3.4471e-02, -3.4589e-02,\n",
      "        -8.5741e-02, -4.5610e-02,  2.8359e-02,  6.3386e-02, -4.8836e-03,\n",
      "         5.9855e-02,  1.4866e-01,  1.7015e-01], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(0.2048, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0110, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0125, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0649, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0546, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0471, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0019, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0093, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0419, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0581, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0864, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0010, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1046, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1516, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.7239, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0877, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2176, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.3376, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0518, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1525, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0208, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1113, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0464, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0194, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0251, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0386, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0002, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0254, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0119, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0602, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0456, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0284, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0634, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0881, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1701, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'who', 'was', 'given', 'the', 'esteem', 'ed', 'status', 'of', 'mvp', 'for', 'super', 'bowl', '50', '?', '[SEP]', '[SEP]', 'denver', 'linebacker', 'von', 'miller', 'was', 'named', 'super', 'bowl', 'mvp', ',', 'recording', 'five', 'solo', 'tackles', ',', '2', '½', 'sacks', ',', 'and', 'two', 'forced', 'fumble', 's', '.', '[SEP]']\n",
      "len conti_raw 35\n",
      "conti_raw ['[CLS]', 'who', 'was', 'given', 'the', 'esteemed', 'status', 'of', 'mvp', 'for', 'super', 'bowl', '50?', '[SEP]', '[SEP]', 'denver', 'linebacker', 'von', 'miller', 'was', 'named', 'super', 'bowl', 'mvp,', 'recording', 'five', 'solo', 'tackles,', '2½', 'sacks,', 'and', 'two', 'forced', 'fumbles.', '[SEP]']\n",
      "pred_prob 0.9407644867897034\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.94)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>0.18</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> who                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> given                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> esteemed                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> status                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> mvp                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> for                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> super                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> bowl                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 50?                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 72%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> denver                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> linebacker                    </font></mark><mark style=\"background-color: hsl(120, 75%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> von                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> miller                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> named                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> super                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> bowl                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> mvp,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> recording                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> five                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> solo                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> tackles,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 2½                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> sacks,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> two                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> forced                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> fumbles.                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['What was the percentage of Black or African-Americans living in the city?', 'Hispanic or Latino of any race were 39.9% of the population.']\n",
      "GT target: 0\n",
      "word attr tensor([-0.0831,  0.1107,  0.1672,  0.3297, -0.1759, -0.0547,  0.0629,  0.0677,\n",
      "         0.0778,  0.0696, -0.1511, -0.0748, -0.0452,  0.1237,  0.0198,  0.2659,\n",
      "        -0.2058, -0.4453, -0.0161, -0.0121,  0.2670,  0.1759, -0.2846,  0.0086,\n",
      "         0.0202,  0.0546,  0.1176,  0.0940,  0.3935,  0.0950,  0.0489,  0.1489,\n",
      "         0.1421, -0.1219], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(-0.0831, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1107, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1672, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.3297, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1759, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0547, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0629, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0677, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0387, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0748, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0452, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1237, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1429, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.2058, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.4453, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0161, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0121, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2670, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1759, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2846, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0086, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0202, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2418, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0950, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0489, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1455, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1219, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'what', 'was', 'the', 'percentage', 'of', 'black', 'or', 'african', '-', 'americans', 'living', 'in', 'the', 'city', '?', '[SEP]', '[SEP]', 'hispanic', 'or', 'latino', 'of', 'any', 'race', 'were', '39', '.', '9', '%', 'of', 'the', 'population', '.', '[SEP]']\n",
      "len conti_raw 27\n",
      "conti_raw ['[CLS]', 'what', 'was', 'the', 'percentage', 'of', 'black', 'or', 'african-americans', 'living', 'in', 'the', 'city?', '[SEP]', '[SEP]', 'hispanic', 'or', 'latino', 'of', 'any', 'race', 'were', '39.9%', 'of', 'the', 'population.', '[SEP]']\n",
      "pred_prob 0.9827529191970825\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.98)</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>1.19</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> what                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(120, 75%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> percentage                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> black                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> or                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> african-americans                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> living                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> city?                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hispanic                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> or                    </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> latino                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> any                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> race                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> were                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 39.9%                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> population.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['What was the result of the 2007 election?', 'With International Criminal Court trial dates in 2013 for both President Kenyatta and Deputy President William Ruto related to the 2007 election aftermath, US President Barack Obama chose not to visit the country during his mid-2013 African trip.']\n",
      "GT target: 1\n",
      "word attr tensor([ 0.0550,  0.3968, -0.3173,  0.0047,  0.0374, -0.0361, -0.0187,  0.2652,\n",
      "         0.2064,  0.4509, -0.1167,  0.0670, -0.1791,  0.0122,  0.0701, -0.1218,\n",
      "        -0.0039,  0.0691, -0.1188,  0.0195,  0.0401,  0.0366, -0.0752,  0.0653,\n",
      "         0.0861,  0.0077, -0.0973, -0.0340,  0.1248, -0.0180, -0.1102,  0.0961,\n",
      "         0.0147,  0.0655, -0.2629, -0.1229,  0.0435, -0.0287,  0.0416,  0.0512,\n",
      "        -0.1229, -0.1562,  0.0515,  0.0587, -0.1585, -0.0169, -0.0146,  0.0096,\n",
      "         0.0495,  0.0603,  0.1049, -0.0709, -0.2255, -0.0137,  0.0972,  0.0426,\n",
      "         0.1017], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(0.0550, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.3968, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.3173, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0047, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0374, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0361, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0187, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2652, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.3287, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1167, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0670, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1791, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0122, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0701, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1218, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0039, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0691, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1188, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0195, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0401, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0366, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0752, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0757, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0077, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0973, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0340, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1248, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0641, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0961, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0147, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0655, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2629, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1229, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0074, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0416, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0512, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1229, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1562, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0515, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0587, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1585, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0169, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0146, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0096, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0495, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0603, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1043, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0137, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0699, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1017, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'what', 'was', 'the', 'result', 'of', 'the', '2007', 'election', '?', '[SEP]', '[SEP]', 'with', 'international', 'criminal', 'court', 'trial', 'dates', 'in', '2013', 'for', 'both', 'president', 'kenya', 'tta', 'and', 'deputy', 'president', 'william', 'ru', 'to', 'related', 'to', 'the', '2007', 'election', 'aftermath', ',', 'us', 'president', 'barack', 'obama', 'chose', 'not', 'to', 'visit', 'the', 'country', 'during', 'his', 'mid', '-', '2013', 'african', 'trip', '.', '[SEP]']\n",
      "len conti_raw 50\n",
      "conti_raw ['[CLS]', 'what', 'was', 'the', 'result', 'of', 'the', '2007', 'election?', '[SEP]', '[SEP]', 'with', 'international', 'criminal', 'court', 'trial', 'dates', 'in', '2013', 'for', 'both', 'president', 'kenyatta', 'and', 'deputy', 'president', 'william', 'ruto', 'related', 'to', 'the', '2007', 'election', 'aftermath,', 'us', 'president', 'barack', 'obama', 'chose', 'not', 'to', 'visit', 'the', 'country', 'during', 'his', 'mid-2013', 'african', 'trip.', '[SEP]']\n",
      "pred_prob 0.3425130546092987\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment (0.34)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>0.46</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 81%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> what                    </font></mark><mark style=\"background-color: hsl(0, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> result                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 2007                    </font></mark><mark style=\"background-color: hsl(120, 75%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> election?                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> with                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> international                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> criminal                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> court                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> trial                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> dates                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 2013                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> for                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> both                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> president                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> kenyatta                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> deputy                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> president                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> william                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ruto                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> related                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 2007                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> election                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> aftermath,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> us                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> president                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> barack                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> obama                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> chose                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> not                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> visit                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> country                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> during                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> his                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> mid-2013                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> african                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> trip.                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['What equation currently decribes the physics of force.', 'The notion \"force\" keeps its meaning in quantum mechanics, though one is now dealing with operators instead of classical variables and though the physics is now described by the Schrödinger equation instead of Newtonian equations.']\n",
      "GT target: 1\n",
      "word attr tensor([-0.0276, -0.0724, -0.1979,  0.0113,  0.0652, -0.0979,  0.1065, -0.0349,\n",
      "        -0.0766,  0.0949, -0.0081, -0.1211,  0.0961,  0.0257, -0.1071, -0.0039,\n",
      "        -0.0801,  0.0880, -0.1064,  0.0996, -0.1210, -0.0033,  0.0259, -0.0362,\n",
      "         0.1922, -0.0615,  0.0157, -0.0461, -0.0422, -0.0016, -0.0161, -0.0419,\n",
      "        -0.0427, -0.0166,  0.0681, -0.0634, -0.1145,  0.0050,  0.0361,  0.0391,\n",
      "        -0.0639,  0.1934,  0.4349, -0.0869, -0.0066,  0.2020,  0.0489, -0.0941,\n",
      "         0.0771, -0.0585, -0.0322,  0.2282,  0.0897, -0.0991, -0.0909,  0.1957,\n",
      "        -0.2200, -0.5349], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(-0.0276, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0724, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1979, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0113, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0451, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0349, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0766, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0949, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0646, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0961, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0257, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1071, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0039, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0512, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0996, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1210, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0033, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0259, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0362, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0654, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0157, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0461, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0422, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0016, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0161, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0419, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0427, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0166, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0681, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0634, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1145, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0050, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0361, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0391, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0639, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1934, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.4349, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0869, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0066, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2020, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0156, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0322, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2282, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0897, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0950, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0121, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.5349, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'what', 'equation', 'currently', 'dec', 'ri', 'bes', 'the', 'physics', 'of', 'force', '.', '[SEP]', '[SEP]', 'the', 'notion', '\"', 'force', '\"', 'keeps', 'its', 'meaning', 'in', 'quantum', 'mechanics', ',', 'though', 'one', 'is', 'now', 'dealing', 'with', 'operators', 'instead', 'of', 'classical', 'variables', 'and', 'though', 'the', 'physics', 'is', 'now', 'described', 'by', 'the', 'sc', 'hr', 'od', 'inger', 'equation', 'instead', 'of', 'newton', 'ian', 'equations', '.', '[SEP]']\n",
      "len conti_raw 47\n",
      "conti_raw ['[CLS]', 'what', 'equation', 'currently', 'decribes', 'the', 'physics', 'of', 'force.', '[SEP]', '[SEP]', 'the', 'notion', '\"force\"', 'keeps', 'its', 'meaning', 'in', 'quantum', 'mechanics,', 'though', 'one', 'is', 'now', 'dealing', 'with', 'operators', 'instead', 'of', 'classical', 'variables', 'and', 'though', 'the', 'physics', 'is', 'now', 'described', 'by', 'the', 'schrodinger', 'equation', 'instead', 'of', 'newtonian', 'equations.', '[SEP]']\n",
      "pred_prob 0.23880738019943237\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment (0.24)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>-0.39</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> what                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> equation                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> currently                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> decribes                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> physics                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> force.                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> notion                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> \"force\"                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> keeps                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> its                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> meaning                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> quantum                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> mechanics,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> though                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> one                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> now                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> dealing                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> with                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> operators                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> instead                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> classical                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> variables                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> though                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> physics                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> now                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> described                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> by                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> schrodinger                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> equation                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> instead                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> newtonian                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> equations.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['What did Iqbal fear would weaken the spiritual foundations of Islam and Muslim society?', 'In his travels to Egypt, Afghanistan, Palestine and Syria, he promoted ideas of greater Islamic political co-operation and unity, calling for the shedding of nationalist differences.']\n",
      "GT target: 0\n",
      "word attr tensor([-0.0989,  0.0917, -0.1992, -0.1109, -0.0734, -0.0923, -0.1603,  0.1448,\n",
      "         0.1389,  0.0864,  0.0781,  0.1653, -0.0557,  0.0722,  0.1652,  0.2551,\n",
      "        -0.2239,  0.1126, -0.0186, -0.0033, -0.2765, -0.0435, -0.0341, -0.3229,\n",
      "         0.1297, -0.1844,  0.1127, -0.1604, -0.0319, -0.1351,  0.1590, -0.1860,\n",
      "         0.1920,  0.0292, -0.1159,  0.0978, -0.0232, -0.0854,  0.0013, -0.1219,\n",
      "        -0.0040, -0.0310, -0.1099,  0.1772, -0.0741,  0.0449,  0.1411,  0.0574,\n",
      "         0.0097,  0.0982, -0.0604,  0.3220, -0.1318], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(-0.0989, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0917, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1992, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1109, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0734, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0923, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1603, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1448, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1389, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0864, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0781, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1653, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0557, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0722, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2102, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.2239, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1126, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0186, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0033, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2765, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0435, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1785, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0273, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1127, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1604, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0835, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1590, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1860, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1920, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0292, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1159, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0978, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0232, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0820, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0040, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0705, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1772, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0741, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0449, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0992, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0097, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0982, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1308, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1318, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'what', 'did', 'iqbal', 'fear', 'would', 'weaken', 'the', 'spiritual', 'foundations', 'of', 'islam', 'and', 'muslim', 'society', '?', '[SEP]', '[SEP]', 'in', 'his', 'travels', 'to', 'egypt', ',', 'afghanistan', ',', 'palestine', 'and', 'syria', ',', 'he', 'promoted', 'ideas', 'of', 'greater', 'islamic', 'political', 'co', '-', 'operation', 'and', 'unity', ',', 'calling', 'for', 'the', 'shed', 'ding', 'of', 'nationalist', 'differences', '.', '[SEP]']\n",
      "len conti_raw 44\n",
      "conti_raw ['[CLS]', 'what', 'did', 'iqbal', 'fear', 'would', 'weaken', 'the', 'spiritual', 'foundations', 'of', 'islam', 'and', 'muslim', 'society?', '[SEP]', '[SEP]', 'in', 'his', 'travels', 'to', 'egypt,', 'afghanistan,', 'palestine', 'and', 'syria,', 'he', 'promoted', 'ideas', 'of', 'greater', 'islamic', 'political', 'co-operation', 'and', 'unity,', 'calling', 'for', 'the', 'shedding', 'of', 'nationalist', 'differences.', '[SEP]']\n",
      "pred_prob 0.38441193103790283\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment (0.38)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>-0.29</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> what                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> did                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> iqbal                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> fear                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> would                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> weaken                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> spiritual                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> foundations                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> islam                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> muslim                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> society?                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> his                    </font></mark><mark style=\"background-color: hsl(0, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> travels                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> egypt,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> afghanistan,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> palestine                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> syria,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> he                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> promoted                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ideas                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> greater                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> islamic                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> political                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> co-operation                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> unity,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> calling                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> for                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> shedding                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> nationalist                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> differences.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['In what meeting did Shirley lay out plans for 1756?', 'At a meeting in Albany in December 1755, he laid out his plans for 1756.']\n",
      "GT target: 1\n",
      "word attr tensor([-0.4957,  0.2288, -0.2925,  0.0115, -0.0321, -0.1189,  0.1418, -0.0988,\n",
      "        -0.0965,  0.1266,  0.3623, -0.0547, -0.1723, -0.1002,  0.0381, -0.2102,\n",
      "         0.1685,  0.1481, -0.0447,  0.1762,  0.0334,  0.0689, -0.0335,  0.0638,\n",
      "         0.1897,  0.0953,  0.0168,  0.2384,  0.1807,  0.0757, -0.0423, -0.2990],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(-0.4957, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2288, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2925, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0115, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0321, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1189, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1418, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0988, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0965, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1266, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1538, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1723, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1002, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0381, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2102, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1685, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1481, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0447, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1762, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0334, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0177, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0638, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1897, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0953, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0168, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2384, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1807, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0167, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.2990, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'in', 'what', 'meeting', 'did', 'shirley', 'lay', 'out', 'plans', 'for', '1756', '?', '[SEP]', '[SEP]', 'at', 'a', 'meeting', 'in', 'albany', 'in', 'december', '1755', ',', 'he', 'laid', 'out', 'his', 'plans', 'for', '1756', '.', '[SEP]']\n",
      "len conti_raw 29\n",
      "conti_raw ['[CLS]', 'in', 'what', 'meeting', 'did', 'shirley', 'lay', 'out', 'plans', 'for', '1756?', '[SEP]', '[SEP]', 'at', 'a', 'meeting', 'in', 'albany', 'in', 'december', '1755,', 'he', 'laid', 'out', 'his', 'plans', 'for', '1756.', '[SEP]']\n",
      "pred_prob 0.6875017881393433\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.69)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>0.27</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 81%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> what                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> meeting                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> did                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> shirley                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> lay                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> out                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> plans                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> for                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 1756?                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> at                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> meeting                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> albany                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> december                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 1755,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> he                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> laid                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> out                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> his                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> plans                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> for                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 1756.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: [\"In autoimmune disorders, the immune system doesn't distinguish between what types of cells?\", 'One of the functions of specialized cells (located in the thymus and bone marrow) is to present young lymphocytes with self antigens produced throughout the body and to eliminate those cells that recognize self-antigens, preventing autoimmunity.']\n",
      "GT target: 0\n",
      "word attr tensor([ 1.0039e-01,  3.8116e-03,  8.7569e-02,  9.4984e-03, -1.2080e-01,\n",
      "         6.0907e-02,  6.6665e-02, -1.5446e-02, -1.6813e-02,  6.4608e-02,\n",
      "         6.3432e-02, -1.7587e-01, -1.2068e-01, -2.0387e-03, -1.5924e-01,\n",
      "        -1.7890e-01,  1.4090e-01,  2.0202e-01, -1.6266e-01,  3.5750e-01,\n",
      "         1.8672e-01, -2.1307e-01, -3.6138e-01,  1.2375e-02, -2.0793e-02,\n",
      "         2.4650e-01, -6.0585e-02,  1.3399e-02,  3.3099e-02,  5.6555e-02,\n",
      "        -7.7692e-02,  1.1798e-01, -6.0894e-02,  1.0830e-01, -1.4241e-01,\n",
      "        -1.0765e-02,  8.4387e-06,  1.0147e-01, -3.1370e-02, -1.3043e-01,\n",
      "        -2.8426e-02,  7.6458e-02, -7.5437e-02, -1.5380e-02, -1.6356e-02,\n",
      "         2.6195e-02, -2.9904e-01,  7.1189e-02, -6.1650e-04, -1.9136e-01,\n",
      "         4.9181e-02, -8.3520e-03,  1.1645e-01,  6.0707e-02, -1.5394e-02,\n",
      "         8.9370e-02,  2.9557e-02,  6.9047e-03, -3.6744e-02, -9.0568e-02,\n",
      "         2.1464e-02, -1.0980e-01,  6.2058e-02, -5.3041e-02, -1.1596e-01,\n",
      "         3.4666e-02, -1.3910e-02, -6.5733e-03,  4.7295e-02, -2.3686e-02,\n",
      "         4.9337e-02, -1.0122e-01, -7.7782e-02,  2.8011e-02, -1.7031e-01],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(0.1004, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0038, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0124, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0256, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0168, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0646, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0634, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0752, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1592, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1789, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1409, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2020, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1627, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2721, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.2131, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.3614, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0124, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0208, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2465, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0606, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0134, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0331, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0566, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0201, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0609, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1083, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0766, device='cuda:0', grad_fn=<DivBackward0>), tensor(8.4387e-06, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1015, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0809, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0284, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0765, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0754, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0154, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0379, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0006, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1914, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0204, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1164, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0607, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0154, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0894, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0296, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0069, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0367, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0906, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0215, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1098, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0621, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0130, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0473, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0165, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1703, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'in', 'auto', 'im', 'mun', 'e', 'disorders', ',', 'the', 'immune', 'system', 'doesn', \"'\", 't', 'distinguish', 'between', 'what', 'types', 'of', 'cells', '?', '[SEP]', '[SEP]', 'one', 'of', 'the', 'functions', 'of', 'specialized', 'cells', '(', 'located', 'in', 'the', 'thy', 'mus', 'and', 'bone', 'marrow', ')', 'is', 'to', 'present', 'young', 'l', 'ym', 'ph', 'ocytes', 'with', 'self', 'antigen', 's', 'produced', 'throughout', 'the', 'body', 'and', 'to', 'eliminate', 'those', 'cells', 'that', 'recognize', 'self', '-', 'antigen', 's', ',', 'preventing', 'auto', 'im', 'mun', 'ity', '.', '[SEP]']\n",
      "len conti_raw 53\n",
      "conti_raw ['[CLS]', 'in', 'autoimmune', 'disorders,', 'the', 'immune', 'system', \"doesn't\", 'distinguish', 'between', 'what', 'types', 'of', 'cells?', '[SEP]', '[SEP]', 'one', 'of', 'the', 'functions', 'of', 'specialized', 'cells', '(located', 'in', 'the', 'thymus', 'and', 'bone', 'marrow)', 'is', 'to', 'present', 'young', 'lymphocytes', 'with', 'self', 'antigens', 'produced', 'throughout', 'the', 'body', 'and', 'to', 'eliminate', 'those', 'cells', 'that', 'recognize', 'self-antigens,', 'preventing', 'autoimmunity.', '[SEP]']\n",
      "pred_prob 0.8891812562942505\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.89)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>-0.71</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> autoimmune                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> disorders,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> immune                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> system                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> doesn't                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> distinguish                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> between                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> what                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> types                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> cells?                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> one                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> functions                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> specialized                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> cells                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> (located                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> thymus                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> bone                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> marrow)                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> present                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> young                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> lymphocytes                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> with                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> self                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> antigens                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> produced                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> throughout                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> body                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> eliminate                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> those                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> cells                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> that                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> recognize                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> self-antigens,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> preventing                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> autoimmunity.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['Which husband and wife modern furniture design team are represented in the V&A furniture collection?', 'One of the finest pieces of continental furniture in the collection is the Rococo Augustus Rex Bureau Cabinet dated c1750 from Germany, with especially fine marquetry and ormolu mounts.']\n",
      "GT target: 0\n",
      "word attr tensor([-1.1308e-01,  2.3274e-02, -5.0867e-01, -7.2099e-02, -3.0861e-01,\n",
      "         9.2733e-05,  4.0648e-02,  2.0463e-01,  2.3129e-01, -1.3377e-01,\n",
      "         5.2293e-02,  1.0014e-01,  6.0770e-02, -9.8150e-02, -3.4768e-02,\n",
      "         1.1307e-02, -1.7190e-01,  6.1213e-03,  3.3086e-01,  1.4714e-01,\n",
      "         5.7469e-02, -1.5405e-01, -6.3870e-02, -6.5857e-02,  5.1358e-02,\n",
      "        -5.1459e-02, -9.6139e-02,  3.2604e-01,  1.0769e-01, -1.6144e-01,\n",
      "        -5.4788e-02, -9.3239e-02, -7.8780e-03, -9.5093e-02,  5.5863e-02,\n",
      "         1.1607e-01, -9.7645e-02,  7.1133e-02,  6.7008e-02, -1.4523e-02,\n",
      "         6.4484e-02,  1.4999e-01, -8.4158e-04,  7.8421e-02, -2.8814e-02,\n",
      "         4.9942e-02, -2.6094e-02,  1.0904e-02, -1.2456e-02,  3.6180e-02,\n",
      "         2.6443e-02, -9.3892e-02, -1.7225e-02,  1.4729e-02, -2.8689e-02,\n",
      "         1.2300e-02,  2.6085e-02,  3.1131e-02,  9.6789e-02, -1.1575e-01],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(-0.1131, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0233, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.5087, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0721, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.3086, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(9.2733e-05, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0406, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2046, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2313, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1338, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0523, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1001, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0608, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0276, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1719, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1685, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1471, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0575, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1540, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0639, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0659, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0514, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0515, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0961, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.3260, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1077, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1614, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0548, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0932, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0079, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0951, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0860, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0976, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0711, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0670, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0145, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0645, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0765, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0288, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0119, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0109, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0125, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0362, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0255, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0147, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0089, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0640, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1158, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'which', 'husband', 'and', 'wife', 'modern', 'furniture', 'design', 'team', 'are', 'represented', 'in', 'the', 'v', '&', 'a', 'furniture', 'collection', '?', '[SEP]', '[SEP]', 'one', 'of', 'the', 'finest', 'pieces', 'of', 'continental', 'furniture', 'in', 'the', 'collection', 'is', 'the', 'roc', 'oco', 'augustus', 'rex', 'bureau', 'cabinet', 'dated', 'c1', '75', '0', 'from', 'germany', ',', 'with', 'especially', 'fine', 'mar', 'quet', 'ry', 'and', 'or', 'mo', 'lu', 'mounts', '.', '[SEP]']\n",
      "len conti_raw 48\n",
      "conti_raw ['[CLS]', 'which', 'husband', 'and', 'wife', 'modern', 'furniture', 'design', 'team', 'are', 'represented', 'in', 'the', 'v&a', 'furniture', 'collection?', '[SEP]', '[SEP]', 'one', 'of', 'the', 'finest', 'pieces', 'of', 'continental', 'furniture', 'in', 'the', 'collection', 'is', 'the', 'rococo', 'augustus', 'rex', 'bureau', 'cabinet', 'dated', 'c1750', 'from', 'germany,', 'with', 'especially', 'fine', 'marquetry', 'and', 'ormolu', 'mounts.', '[SEP]']\n",
      "pred_prob 0.918213963508606\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.92)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>-0.06</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> which                    </font></mark><mark style=\"background-color: hsl(0, 75%, 80%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> husband                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> wife                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> modern                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> furniture                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> design                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> team                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> are                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> represented                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> v&a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> furniture                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> collection?                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> one                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> finest                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pieces                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> continental                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> furniture                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> collection                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> rococo                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> augustus                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> rex                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> bureau                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> cabinet                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> dated                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> c1750                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> from                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> germany,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> with                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> especially                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> fine                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> marquetry                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ormolu                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> mounts.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['Why did oil start getting priced in terms of gold?', \"Because oil was priced in dollars, oil producers' real income decreased.\"]\n",
      "GT target: 1\n",
      "word attr tensor([ 0.2537,  0.2003,  0.0231, -0.1810,  0.0376, -0.0620, -0.0995, -0.0400,\n",
      "         0.0424, -0.1011, -0.0974,  0.3238, -0.2235, -0.4741,  0.1017,  0.1737,\n",
      "         0.0647, -0.0459,  0.1950, -0.2706, -0.3569, -0.1048,  0.1411, -0.1993,\n",
      "         0.1737, -0.0315, -0.1309, -0.1519, -0.1301], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(0.2537, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2003, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0231, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1810, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0376, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0620, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0995, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0400, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0424, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1011, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1132, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.2235, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.4741, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1017, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1737, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0647, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0459, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1950, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.3137, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1048, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0291, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1737, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0315, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1414, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1301, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'why', 'did', 'oil', 'start', 'getting', 'priced', 'in', 'terms', 'of', 'gold', '?', '[SEP]', '[SEP]', 'because', 'oil', 'was', 'priced', 'in', 'dollars', ',', 'oil', 'producers', \"'\", 'real', 'income', 'decreased', '.', '[SEP]']\n",
      "len conti_raw 25\n",
      "conti_raw ['[CLS]', 'why', 'did', 'oil', 'start', 'getting', 'priced', 'in', 'terms', 'of', 'gold?', '[SEP]', '[SEP]', 'because', 'oil', 'was', 'priced', 'in', 'dollars,', 'oil', \"producers'\", 'real', 'income', 'decreased.', '[SEP]']\n",
      "pred_prob 0.3373945653438568\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment (0.34)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>-0.97</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> why                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> did                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> oil                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> start                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> getting                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> priced                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> terms                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> gold?                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 82%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> because                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> oil                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> priced                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> dollars,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> oil                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> producers'                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> real                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> income                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> decreased.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['Who did Britain exploit in India?', 'Although a substantial number of colonies had been designed to provide economic profit and to ship resources to home ports in the seventeenth and eighteenth centuries, Fieldhouse suggests that in the nineteenth and twentieth centuries in places such as Africa and Asia, this idea is not necessarily valid:']\n",
      "GT target: 0\n",
      "word attr tensor([-3.6541e-02, -1.7885e-02, -8.5177e-02, -4.4000e-03, -1.2685e-02,\n",
      "        -2.6675e-02, -1.8557e-01, -3.5055e-01,  3.4683e-01,  3.5934e-01,\n",
      "        -1.0337e-01, -7.0243e-02,  3.0363e-03, -4.0789e-02, -2.5609e-02,\n",
      "         4.5579e-02, -2.2030e-02,  9.5143e-05, -3.9767e-02, -3.9843e-03,\n",
      "        -3.9355e-02,  9.6562e-02, -2.4047e-02, -2.8292e-03,  2.4544e-02,\n",
      "         3.1649e-02, -2.9933e-02, -7.7694e-03, -3.1601e-02, -4.4408e-02,\n",
      "         4.7799e-02, -5.0609e-02,  2.6368e-02,  1.0798e-01,  1.8693e-02,\n",
      "         2.5499e-02, -9.8141e-02, -4.0911e-02, -2.9776e-02,  9.9172e-02,\n",
      "        -1.9845e-02, -4.7971e-02, -1.2303e-01,  8.9119e-02, -5.5805e-02,\n",
      "        -1.4792e-01,  7.6249e-02,  1.1787e-01,  5.3959e-02, -4.3757e-02,\n",
      "        -1.5316e-02,  1.4608e-01, -4.2158e-03,  1.3219e-01,  1.1375e-01,\n",
      "        -3.0750e-02,  2.4768e-02, -5.9011e-02,  1.0215e-01,  1.1414e-01,\n",
      "         1.3491e-02,  3.2665e-01, -4.9137e-01], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(-0.0365, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0179, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0852, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0044, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0127, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0267, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2681, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.3468, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.3593, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1034, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0702, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0030, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0408, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0256, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0456, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0220, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(9.5143e-05, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0398, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0040, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0394, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0966, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0240, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0028, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0245, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0316, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0299, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0078, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0316, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0444, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0478, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0506, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0264, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1080, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0187, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0363, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0353, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0992, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0198, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0480, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1230, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0891, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0558, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1479, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0762, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1179, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0540, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0438, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0153, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1461, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0042, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0307, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0248, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0590, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1021, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1141, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1701, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.4914, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'who', 'did', 'britain', 'exploit', 'in', 'india', '?', '[SEP]', '[SEP]', 'although', 'a', 'substantial', 'number', 'of', 'colonies', 'had', 'been', 'designed', 'to', 'provide', 'economic', 'profit', 'and', 'to', 'ship', 'resources', 'to', 'home', 'ports', 'in', 'the', 'seventeenth', 'and', 'eighteenth', 'centuries', ',', 'field', 'house', 'suggests', 'that', 'in', 'the', 'nineteenth', 'and', 'twentieth', 'centuries', 'in', 'places', 'such', 'as', 'africa', 'and', 'asia', ',', 'this', 'idea', 'is', 'not', 'necessarily', 'valid', ':', '[SEP]']\n",
      "len conti_raw 58\n",
      "conti_raw ['[CLS]', 'who', 'did', 'britain', 'exploit', 'in', 'india?', '[SEP]', '[SEP]', 'although', 'a', 'substantial', 'number', 'of', 'colonies', 'had', 'been', 'designed', 'to', 'provide', 'economic', 'profit', 'and', 'to', 'ship', 'resources', 'to', 'home', 'ports', 'in', 'the', 'seventeenth', 'and', 'eighteenth', 'centuries,', 'fieldhouse', 'suggests', 'that', 'in', 'the', 'nineteenth', 'and', 'twentieth', 'centuries', 'in', 'places', 'such', 'as', 'africa', 'and', 'asia,', 'this', 'idea', 'is', 'not', 'necessarily', 'valid:', '[SEP]']\n",
      "pred_prob 0.6999862194061279\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.70)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>0.08</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> who                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> did                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> britain                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> exploit                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> india?                    </font></mark><mark style=\"background-color: hsl(120, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> although                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> substantial                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> number                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> colonies                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> had                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> been                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> designed                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> provide                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> economic                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> profit                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ship                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> resources                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> home                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ports                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> seventeenth                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> eighteenth                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> centuries,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> fieldhouse                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> suggests                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> that                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> nineteenth                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> twentieth                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> centuries                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> places                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> such                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> africa                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> asia,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> this                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> idea                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> not                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> necessarily                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> valid:                    </font></mark><mark style=\"background-color: hsl(0, 75%, 81%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['What popular environmentalist is also a university alumni member?', 'In science, alumni include astronomers Carl Sagan, a prominent contributor to the scientific research of extraterrestrial life, and Edwin Hubble, known for \"Hubble\\'s Law\", NASA astronaut John M. Grunsfeld, geneticist James Watson, best known as one of the co-discoverers of the structure of DNA, experimental physicist Luis Alvarez, popular environmentalist David Suzuki, balloonist Jeannette Piccard, biologists Ernest Everett']\n",
      "GT target: 1\n",
      "word attr tensor([ 0.0657, -0.0958,  0.0485,  0.0011,  0.1158,  0.0301, -0.0571,  0.0166,\n",
      "         0.0190,  0.1208,  0.0955, -0.4183,  0.1129,  0.1966, -0.0511,  0.0316,\n",
      "        -0.0916,  0.2298,  0.0602, -0.0824, -0.0843,  0.0123, -0.0319, -0.0756,\n",
      "        -0.0505,  0.0344,  0.0935, -0.0148, -0.0266, -0.0050,  0.0094, -0.0232,\n",
      "         0.0074, -0.0190,  0.0198, -0.0054, -0.0143, -0.0253, -0.0190, -0.0181,\n",
      "         0.0410, -0.0697,  0.0438, -0.0033, -0.0188, -0.0316,  0.0352, -0.0254,\n",
      "        -0.0209, -0.0028, -0.0222,  0.0307, -0.0712,  0.1761,  0.1328, -0.1001,\n",
      "        -0.0760, -0.0574, -0.0265,  0.0154, -0.1072,  0.0036,  0.0202,  0.0269,\n",
      "        -0.0009,  0.0024, -0.0415, -0.0205,  0.0762, -0.0089, -0.0214,  0.0132,\n",
      "         0.0065, -0.0491,  0.0037,  0.0343, -0.0552,  0.0246, -0.0245, -0.0234,\n",
      "        -0.0685,  0.0090,  0.1568, -0.0687,  0.0391, -0.0656, -0.0727,  0.0928,\n",
      "        -0.1447,  0.2285,  0.3397, -0.0735, -0.0168, -0.1881, -0.0422, -0.0986,\n",
      "        -0.1880,  0.0640,  0.0340,  0.0028,  0.0743, -0.1974, -0.0986,  0.0429,\n",
      "        -0.2758, -0.1380,  0.0806], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(0.0657, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0958, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0485, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0585, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0301, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0571, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0166, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0190, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1208, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1614, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1129, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1966, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0511, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0300, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.2298, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0602, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0824, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0843, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0427, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0505, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0344, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0935, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0148, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0266, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0050, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0094, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0232, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0198, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0190, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0181, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0147, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0033, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0188, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0096, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0334, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1761, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1328, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1001, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0667, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0031, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0130, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0024, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0310, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0762, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0089, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0214, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0132, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0065, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0491, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0245, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0234, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0685, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0090, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0441, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0391, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0656, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0727, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0259, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.2285, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1331, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0168, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1151, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1433, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0490, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0794, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0278, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.2758, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1380, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0806, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'what', 'popular', 'environmental', 'ist', 'is', 'also', 'a', 'university', 'alumni', 'member', '?', '[SEP]', '[SEP]', 'in', 'science', ',', 'alumni', 'include', 'astronomers', 'carl', 'saga', 'n', ',', 'a', 'prominent', 'contributor', 'to', 'the', 'scientific', 'research', 'of', 'extra', 'ter', 'rest', 'rial', 'life', ',', 'and', 'edwin', 'hub', 'ble', ',', 'known', 'for', '\"', 'hub', 'ble', \"'\", 's', 'law', '\"', ',', 'nasa', 'astronaut', 'john', 'm', '.', 'gr', 'un', 'sf', 'eld', ',', 'genetic', 'ist', 'james', 'watson', ',', 'best', 'known', 'as', 'one', 'of', 'the', 'co', '-', 'discover', 'ers', 'of', 'the', 'structure', 'of', 'dna', ',', 'experimental', 'physicist', 'luis', 'alvarez', ',', 'popular', 'environmental', 'ist', 'david', 'suzuki', ',', 'balloon', 'ist', 'jeanne', 'tte', 'pic', 'card', ',', 'biologist', 's', 'ernest', 'everett', '[SEP]']\n",
      "len conti_raw 71\n",
      "conti_raw ['[CLS]', 'what', 'popular', 'environmentalist', 'is', 'also', 'a', 'university', 'alumni', 'member?', '[SEP]', '[SEP]', 'in', 'science,', 'alumni', 'include', 'astronomers', 'carl', 'sagan,', 'a', 'prominent', 'contributor', 'to', 'the', 'scientific', 'research', 'of', 'extraterrestrial', 'life,', 'and', 'edwin', 'hubble,', 'known', 'for', '\"hubble\\'s', 'law\",', 'nasa', 'astronaut', 'john', 'm.', 'grunsfeld,', 'geneticist', 'james', 'watson,', 'best', 'known', 'as', 'one', 'of', 'the', 'co-discoverers', 'of', 'the', 'structure', 'of', 'dna,', 'experimental', 'physicist', 'luis', 'alvarez,', 'popular', 'environmentalist', 'david', 'suzuki,', 'balloonist', 'jeannette', 'piccard,', 'biologists', 'ernest', 'everett', '[SEP]']\n",
      "pred_prob 0.31498053669929504\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment (0.31)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>-0.65</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> what                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> popular                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> environmentalist                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> also                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> university                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> alumni                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> member?                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> science,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> alumni                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> include                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> astronomers                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> carl                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> sagan,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> prominent                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> contributor                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> scientific                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> research                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> extraterrestrial                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> life,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> edwin                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hubble,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> known                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> for                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> \"hubble's                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> law\",                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> nasa                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> astronaut                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> john                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> m.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> grunsfeld,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> geneticist                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> james                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> watson,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> best                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> known                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> one                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> co-discoverers                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> structure                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> dna,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> experimental                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> physicist                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> luis                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> alvarez,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> popular                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> environmentalist                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> david                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> suzuki,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> balloonist                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> jeannette                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> piccard,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> biologists                    </font></mark><mark style=\"background-color: hsl(0, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ernest                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> everett                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['What publication did Philip Howard work for?', 'Responding to the findings of the survey in The Times newspaper, journalist Philip Howard maintained that, \"to compare the violence of Dr Who, sired by a horse-laugh out of a nightmare, with the more realistic violence of other television series, where actors who look like human beings bleed paint that looks like blood, is like comparing Monopoly with the property market in London: both are fantasies, but one is meant to be taken seriously.\"']\n",
      "GT target: 1\n",
      "word attr tensor([-0.1491, -0.1364, -0.0582,  0.0584, -0.1525,  0.1899, -0.0835,  0.0986,\n",
      "        -0.2427,  0.2560,  0.2106, -0.0625, -0.0102,  0.0391, -0.2448,  0.0287,\n",
      "         0.0024, -0.0760,  0.3384, -0.1034,  0.2044,  0.2851,  0.1278,  0.0172,\n",
      "        -0.1430,  0.1527, -0.0713, -0.0336,  0.0761,  0.0849, -0.0311, -0.0155,\n",
      "         0.0549, -0.0270,  0.0808,  0.0201, -0.0503,  0.0556, -0.1277,  0.0109,\n",
      "        -0.0241, -0.0700,  0.0426,  0.0470,  0.0270,  0.0032, -0.0187, -0.0175,\n",
      "         0.0722, -0.0048,  0.0086,  0.0750, -0.0301, -0.0591,  0.0537,  0.0663,\n",
      "         0.0376, -0.0124,  0.0502,  0.0734,  0.0914, -0.0205,  0.0441,  0.0204,\n",
      "         0.0022,  0.0054, -0.1141,  0.0171,  0.0109,  0.0062, -0.0299, -0.0754,\n",
      "         0.0953,  0.0047, -0.0875,  0.1341, -0.1934, -0.0235, -0.0995,  0.1302,\n",
      "         0.0114, -0.0437,  0.2068,  0.0065, -0.0313, -0.0263,  0.1083,  0.0886,\n",
      "         0.0362,  0.0244, -0.0182, -0.0358,  0.0734,  0.0405,  0.0200,  0.0553,\n",
      "         0.1299,  0.0517, -0.0149], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(-0.1491, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1364, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0582, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0584, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1525, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1899, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0835, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0721, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.2560, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2106, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0625, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0102, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0391, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2448, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0287, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0024, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0760, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.3384, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1034, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2044, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2064, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0172, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1430, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1527, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0713, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0213, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0269, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0155, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0549, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0270, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0808, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0201, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0026, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.1277, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0109, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0241, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0167, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0270, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0032, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0187, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0273, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0048, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0086, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0750, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0301, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0591, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0537, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0663, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0376, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0189, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0734, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0914, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0205, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0441, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0204, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0022, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0054, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1141, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0171, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0109, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0062, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0299, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0100, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0047, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0875, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1341, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1934, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0235, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0995, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1302, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0114, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0437, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1066, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0313, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0263, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0984, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0362, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0244, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0182, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0358, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0734, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0405, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0200, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0722, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0149, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'what', 'publication', 'did', 'philip', 'howard', 'work', 'for', '?', '[SEP]', '[SEP]', 'responding', 'to', 'the', 'findings', 'of', 'the', 'survey', 'in', 'the', 'times', 'newspaper', ',', 'journalist', 'philip', 'howard', 'maintained', 'that', ',', '\"', 'to', 'compare', 'the', 'violence', 'of', 'dr', 'who', ',', 'sired', 'by', 'a', 'horse', '-', 'laugh', 'out', 'of', 'a', 'nightmare', ',', 'with', 'the', 'more', 'realistic', 'violence', 'of', 'other', 'television', 'series', ',', 'where', 'actors', 'who', 'look', 'like', 'human', 'beings', 'bleed', 'paint', 'that', 'looks', 'like', 'blood', ',', 'is', 'like', 'comparing', 'monopoly', 'with', 'the', 'property', 'market', 'in', 'london', ':', 'both', 'are', 'fantasies', ',', 'but', 'one', 'is', 'meant', 'to', 'be', 'taken', 'seriously', '.', '\"', '[SEP]']\n",
      "len conti_raw 85\n",
      "conti_raw ['[CLS]', 'what', 'publication', 'did', 'philip', 'howard', 'work', 'for?', '[SEP]', '[SEP]', 'responding', 'to', 'the', 'findings', 'of', 'the', 'survey', 'in', 'the', 'times', 'newspaper,', 'journalist', 'philip', 'howard', 'maintained', 'that,', '\"to', 'compare', 'the', 'violence', 'of', 'dr', 'who,', 'sired', 'by', 'a', 'horse-laugh', 'out', 'of', 'a', 'nightmare,', 'with', 'the', 'more', 'realistic', 'violence', 'of', 'other', 'television', 'series,', 'where', 'actors', 'who', 'look', 'like', 'human', 'beings', 'bleed', 'paint', 'that', 'looks', 'like', 'blood,', 'is', 'like', 'comparing', 'monopoly', 'with', 'the', 'property', 'market', 'in', 'london:', 'both', 'are', 'fantasies,', 'but', 'one', 'is', 'meant', 'to', 'be', 'taken', 'seriously.\"', '[SEP]']\n",
      "pred_prob 0.7388923764228821\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment (0.74)</b></text></td><td><text style=\"padding-right:2em\"><b>Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>1.50</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> what                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> publication                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> did                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> philip                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> howard                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> work                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> for?                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> responding                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> findings                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> survey                    </font></mark><mark style=\"background-color: hsl(120, 75%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> times                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> newspaper,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> journalist                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> philip                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> howard                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> maintained                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> that,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> \"to                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> compare                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> violence                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> dr                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> who,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> sired                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> by                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> horse-laugh                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> out                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> nightmare,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> with                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> more                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> realistic                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> violence                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> other                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> television                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> series,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> where                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> actors                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> who                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> look                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> like                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> human                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> beings                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> bleed                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> paint                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> that                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> looks                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> like                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> blood,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> like                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> comparing                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> monopoly                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> with                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> property                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> market                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> london:                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> both                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> are                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> fantasies,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> but                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> one                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> meant                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> be                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> taken                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> seriously.\"                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "Raw datum: ['If the apparant force of two fermions is attractive, what is the spin function?', 'If two identical fermions (e.g. electrons) have a symmetric spin function (e.g. parallel spins) the spatial variables must be antisymmetric (i.e. they exclude each other from their places much as if there was a repulsive force), and vice versa, i.e. for antiparallel spins the position variables must be symmetric (i.e. the apparent force must be attractive).']\n",
      "GT target: 1\n",
      "word attr tensor([ 1.8835e-01, -7.3944e-02, -2.9347e-02, -6.8511e-02,  6.0602e-03,\n",
      "        -4.9025e-02,  3.1911e-02, -7.9235e-02, -1.8376e-02, -5.6219e-04,\n",
      "         1.2540e-02,  2.2602e-02,  1.5829e-01,  4.7460e-02, -1.0607e-01,\n",
      "        -2.1238e-01,  5.9499e-02, -2.4640e-02, -2.4201e-02,  9.3849e-02,\n",
      "        -1.2835e-01,  2.1887e-01,  1.8123e-01, -9.6763e-02, -1.0319e-01,\n",
      "        -7.6532e-02,  2.7614e-02, -1.6905e-02,  1.2554e-02,  3.3259e-02,\n",
      "         4.0247e-02, -9.7427e-03,  6.8936e-02, -6.4498e-03, -3.4268e-02,\n",
      "        -3.2980e-02, -2.8968e-02,  9.7295e-02,  6.2120e-02,  1.1241e-01,\n",
      "         8.5893e-02, -2.1069e-02,  4.6246e-02, -1.1192e-01,  6.2421e-02,\n",
      "        -1.1961e-01,  7.9637e-03, -2.1897e-03, -4.4628e-02,  3.9153e-02,\n",
      "         5.6091e-02,  4.5954e-02,  1.3333e-02,  2.7899e-02,  1.4086e-02,\n",
      "        -7.2487e-02,  2.8677e-02, -1.4346e-02,  1.0725e-01, -4.3202e-02,\n",
      "         4.2602e-02,  1.2995e-01, -1.0083e-03, -1.8467e-02, -5.1923e-02,\n",
      "        -5.7712e-02,  1.6917e-04,  2.3141e-02,  1.9768e-02, -1.4122e-02,\n",
      "         1.8827e-02,  1.1689e-02, -3.5878e-02,  2.7607e-02,  1.1693e-02,\n",
      "        -6.2373e-02,  1.3930e-02, -5.5520e-03, -6.5353e-02,  5.0248e-04,\n",
      "        -1.1381e-02, -4.2460e-02,  3.4025e-02,  1.7857e-03, -5.8461e-03,\n",
      "        -2.8979e-02, -1.4079e-03, -7.9794e-02,  4.2030e-02, -1.9393e-02,\n",
      "         4.1999e-02,  3.2436e-02, -1.3271e-02,  1.6818e-02, -4.9383e-02,\n",
      "         1.2853e-01, -3.4279e-02, -7.1245e-02, -1.7492e-01,  2.4581e-01,\n",
      "         1.3666e-01, -1.6174e-01, -4.7451e-02, -2.3803e-01,  6.9945e-02,\n",
      "        -3.8636e-01,  1.6358e-01,  1.8123e-01,  5.5454e-02, -1.6566e-01,\n",
      "         1.7935e-01,  2.0101e-01, -1.1778e-01, -9.3350e-02,  4.2505e-02],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "conti attr [tensor(0.1884, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0739, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0293, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0401, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0319, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0792, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0184, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0143, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1583, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0293, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.2124, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0595, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0246, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0242, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0172, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.2189, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1812, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0968, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1032, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0765, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0090, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0174, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0336, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0290, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0973, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0621, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1124, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0859, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0566, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0080, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0234, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0392, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0561, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0460, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0133, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0279, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0073, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0413, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0185, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0519, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0577, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0002, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0231, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0198, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0141, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0188, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0117, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0359, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0276, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0117, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0624, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0042, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0219, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0425, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0340, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0020, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0027, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0194, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0144, device='cuda:0', grad_fn=<DivBackward0>), tensor(-0.0494, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1285, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0343, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0712, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1749, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.2458, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1367, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.2185, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.1636, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1812, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.0555, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.1657, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(0.1794, device='cuda:0', grad_fn=<UnbindBackward0>), tensor(-0.0259, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0425, device='cuda:0', grad_fn=<UnbindBackward0>)]\n",
      "detokenized ['[CLS]', 'if', 'the', 'app', 'aran', 't', 'force', 'of', 'two', 'fe', 'rmi', 'ons', 'is', 'attractive', ',', 'what', 'is', 'the', 'spin', 'function', '?', '[SEP]', '[SEP]', 'if', 'two', 'identical', 'fe', 'rmi', 'ons', '(', 'e', '.', 'g', '.', 'electrons', ')', 'have', 'a', 'symmetric', 'spin', 'function', '(', 'e', '.', 'g', '.', 'parallel', 'spins', ')', 'the', 'spatial', 'variables', 'must', 'be', 'anti', 'sy', 'mme', 'tric', '(', 'i', '.', 'e', '.', 'they', 'exclude', 'each', 'other', 'from', 'their', 'places', 'much', 'as', 'if', 'there', 'was', 'a', 'rep', 'ulsive', 'force', ')', ',', 'and', 'vice', 'versa', ',', 'i', '.', 'e', '.', 'for', 'anti', 'para', 'lle', 'l', 'spins', 'the', 'position', 'variables', 'must', 'be', 'symmetric', '(', 'i', '.', 'e', '.', 'the', 'apparent', 'force', 'must', 'be', 'attractive', ')', '.', '[SEP]']\n",
      "len conti_raw 74\n",
      "conti_raw ['[CLS]', 'if', 'the', 'apparant', 'force', 'of', 'two', 'fermions', 'is', 'attractive,', 'what', 'is', 'the', 'spin', 'function?', '[SEP]', '[SEP]', 'if', 'two', 'identical', 'fermions', '(e.g.', 'electrons)', 'have', 'a', 'symmetric', 'spin', 'function', '(e.g.', 'parallel', 'spins)', 'the', 'spatial', 'variables', 'must', 'be', 'antisymmetric', '(i.e.', 'they', 'exclude', 'each', 'other', 'from', 'their', 'places', 'much', 'as', 'if', 'there', 'was', 'a', 'repulsive', 'force),', 'and', 'vice', 'versa,', 'i.e.', 'for', 'antiparallel', 'spins', 'the', 'position', 'variables', 'must', 'be', 'symmetric', '(i.e.', 'the', 'apparent', 'force', 'must', 'be', 'attractive).', '[SEP]']\n",
      "pred_prob 0.3203403353691101\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment (0.32)</b></text></td><td><text style=\"padding-right:2em\"><b>No Entailment</b></text></td><td><text style=\"padding-right:2em\"><b>0.18</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> if                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> apparant                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> force                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> two                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> fermions                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> attractive,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> what                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> spin                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> function?                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> if                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> two                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> identical                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> fermions                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> (e.g.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> electrons)                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> have                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> symmetric                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> spin                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> function                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> (e.g.                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> parallel                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> spins)                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> spatial                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> variables                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> must                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> be                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> antisymmetric                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> (i.e.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> they                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> exclude                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> each                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> other                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> from                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> their                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> places                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> much                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> if                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> there                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> repulsive                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> force),                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> vice                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> versa,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> i.e.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> for                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> antiparallel                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> spins                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> position                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> variables                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> must                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> be                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> symmetric                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> (i.e.                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> apparent                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> force                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> must                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> be                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> attractive).                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n"
     ]
    }
   ],
   "source": [
    "for i, (datum_raw, target) in enumerate(zip(qnli_data_raw, targets), start=1):\n",
    "#     example_1 = \"How many times has the South Florida/Miami area hosted the Super Bowl?\"\n",
    "#     example_2 = \"The South Florida/Miami area has previously hosted the event 10 times (tied for most with New Orleans), with the most recent one being Super Bowl XLIV in 2010.\"\n",
    "    \n",
    "#     example_1 = \"When did the third Digimon series begin?\"\n",
    "#     example_2 = \"Unlike the two seasons before it and most of the seasons that followed, Digimon Tamers takes a darker and more realistic approach to its story featuring Digimon who do not reincarnate after their deaths and more complex character development in the original Japanese.\"\n",
    "#     datum_raw, target = [example_1, example_2], 1\n",
    "    print(f'Raw datum: {datum_raw}') #datum expected to be a list of 2 sentences\n",
    "    print(f'GT target: {target}')\n",
    "    visual_record=generate_record(datum_raw, target)\n",
    "    print(visualization.visualize_text([visual_record])) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5ca5004",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_base = 'Input_X_Gradients'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce01966e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'indices': [4013,\n",
       "  2281,\n",
       "  2771,\n",
       "  5109,\n",
       "  1852,\n",
       "  2016,\n",
       "  642,\n",
       "  3912,\n",
       "  4427,\n",
       "  2330,\n",
       "  4581,\n",
       "  2611,\n",
       "  5186,\n",
       "  2700,\n",
       "  4920,\n",
       "  4335,\n",
       "  1246,\n",
       "  2811,\n",
       "  5290,\n",
       "  5385,\n",
       "  4774,\n",
       "  653,\n",
       "  2816,\n",
       "  916,\n",
       "  3297,\n",
       "  3459,\n",
       "  1475,\n",
       "  1287,\n",
       "  4548,\n",
       "  1476,\n",
       "  2328,\n",
       "  2208,\n",
       "  2772,\n",
       "  5301,\n",
       "  869,\n",
       "  4968,\n",
       "  4456,\n",
       "  4711,\n",
       "  1929,\n",
       "  634,\n",
       "  3774,\n",
       "  5389,\n",
       "  497,\n",
       "  4901,\n",
       "  4602,\n",
       "  831,\n",
       "  1292,\n",
       "  1087,\n",
       "  3159,\n",
       "  3492],\n",
       " 'raw_data': [['What would a teacher assess the levels of a student on?',\n",
       "   'For example, an experienced teacher and parent described the place of a teacher in learning as follows: \"The real bulk of learning takes place in self-study and problem solving with a lot of feedback around that loop.'],\n",
       "  ['What company created Doctor Who?',\n",
       "   'Who character by BBC Television in the early 1960s, a myriad of stories have been published about Doctor Who, in different media: apart from the actual television episodes that continue to be produced by the BBC, there have also been novels, comics, short stories, audio books, radio plays, interactive video games, game books, webcasts, DVD extras, and even stage performances.'],\n",
       "  ['What was the name of the Media Day event for Super Bowl 50?',\n",
       "   \"The game's media day, which was typically held on the Tuesday afternoon prior to the game, was moved to the Monday evening and re-branded as Super Bowl Opening Night.\"],\n",
       "  ['How many Doctor Who soundtracks have been released since 2005?',\n",
       "   'The fourth was released on 4 October 2010 as a two disc special edition and contained music from the 2008–2010 specials (The Next Doctor to End of Time Part 2).'],\n",
       "  [\"What is the name of the country's longest continuously running student film society?\",\n",
       "   'Students at the University of Chicago run over 400 clubs and organizations known as Recognized Student Organizations (RSOs).'],\n",
       "  ['How many times has the South Florida/Miami area hosted the Super Bowl?',\n",
       "   'The South Florida/Miami area has previously hosted the event 10 times (tied for most with New Orleans), with the most recent one being Super Bowl XLIV in 2010.'],\n",
       "  ['What is different about Paulinella chromatophora?',\n",
       "   'It is not clear whether that symbiont is closely related to the ancestral chloroplast of other eukaryotes.'],\n",
       "  [\"Who played Doctor Who on stage in the 70's?\",\n",
       "   'Doctor Who has appeared on stage numerous times.'],\n",
       "  ['Who do clinical pharmacists work with much of the time?',\n",
       "   'Clinical pharmacists often collaborate with physicians and other healthcare professionals to improve pharmaceutical care.'],\n",
       "  ['In which county does Jacksonville reside?',\n",
       "   'It is the county seat of Duval County, with which the city government consolidated in 1968.'],\n",
       "  ['Who did Genghis Khan charge with finding and punishing the Shah?',\n",
       "   'Genghis Khan ordered the wholesale massacre of many of the civilians, enslaved the rest of the population and executed Inalchuq by pouring molten silver into his ears and eyes, as retribution for his actions.'],\n",
       "  ['What entity enforces the Charter of Fundamental Rights of the European Union?',\n",
       "   'In effect, after the Lisbon Treaty, the Charter and the Convention now co-exist under European Union law, though the former is enforced by the European Court of Justice in relation to European Union measures, and the latter by the European Court of Human Rights in relation to measures by member states.'],\n",
       "  [\"Most of the museum's collection had been returned by which year?\",\n",
       "   'Before the return of the collections after the war, the Britain Can Make It exhibition was held between September and November 1946, attracting nearly a million and a half visitors.'],\n",
       "  ['Within the 30 days how many digiboxes had been sold?',\n",
       "   \"Within 30 days, over 100,000 digiboxes had been sold, which help bolstered BSkyB's decision to give away free digiboxes and minidishes from May 1999.\"],\n",
       "  ['The receptors on a killer T cell must bind to how many MHC: antigen complexes in order to activate the cell?',\n",
       "   \"The MHC:antigen complex is also recognized by the helper cell's CD4 co-receptor, which recruits molecules inside the T cell (e.g., Lck) that are responsible for the T cell's activation.\"],\n",
       "  [\"How much did Westinghouse pay for Tesla's designs?\",\n",
       "   \"In July 1888, Brown and Peck negotiated a licensing deal with George Westinghouse for Tesla's polyphase induction motor and transformer designs for $60,000 in cash and stock and a royalty of $2.50 per AC horsepower produced by each motor.\"],\n",
       "  [\"What type of movies were produced in Jacksonville's 30 studios?\",\n",
       "   'One converted movie studio site, Norman Studios, remains in Arlington; It has been converted to the Jacksonville Silent Film Museum at Norman Studios.'],\n",
       "  ['What voyager said that Mombasa was a great harbour and moored small crafts and great ships?',\n",
       "   'The Swahili built Mombasa into a major port city and established trade links with other nearby city-states, as well as commercial centres in Persia, Arabia, and even India.'],\n",
       "  ['Where is Energiprojekt AB based?',\n",
       "   'Although the reciprocating steam engine is no longer in widespread commercial use, various companies are exploring or exploiting the potential of the engine as an alternative to internal combustion engines.'],\n",
       "  ['Who other than Tesla did Westinghouse consider for the patents?',\n",
       "   \"Westinghouse looked into getting a patent on a similar commutator-less, rotating magnetic field-based induction motor presented in a paper in March 1888 by the Italian physicist Galileo Ferraris, but decided Tesla's patent would probably control the market.\"],\n",
       "  ['What separates the neuroimmune system and peripheral immune system in humans?',\n",
       "   'In humans, the blood–brain barrier, blood–cerebrospinal fluid barrier, and similar fluid–brain barriers separate the peripheral immune system from the neuroimmune system which protects the brain.'],\n",
       "  [\"What did Kublai's government have to balance between?\",\n",
       "   \"Kublai's government after 1262 was a compromise between preserving Mongol interests in China and satisfying the demands of his Chinese subjects.\"],\n",
       "  [\"What did Gasquet's book blame the plague on?\",\n",
       "   'The historian Francis Aidan Gasquet wrote about the \\'Great Pestilence\\' in 1893 and suggested that \"it would appear to be some form of the ordinary Eastern or bubonic plague\".'],\n",
       "  ['Who shared sideline duties with Evan Washburn?',\n",
       "   'In the United States, the game was televised by CBS, as part of a cycle between the three main broadcast television partners of the NFL.'],\n",
       "  ['Who was added to party as Washington went on the way?',\n",
       "   'Washington left with a small party, picking up along the way Jacob Van Braam as an interpreter; Christopher Gist, a company surveyor working in the area; and a few Mingo led by Tanaghrisson.'],\n",
       "  ['What did Queen Elizabeth II open in Newcastle in 1981?',\n",
       "   \"It was opened in five phases between 1980 and 1984, and was Britain's first urban light rail transit system; two extensions were opened in 1991 and 2002.\"],\n",
       "  ['What writing inspired the name Great Yuan?',\n",
       "   'Furthermore, the Yuan is sometimes known as the \"Empire of the Great Khan\" or \"Khanate of the Great Khan\", which particularly appeared on some Yuan maps, since Yuan emperors held the nominal title of Great Khan.'],\n",
       "  ['What happened to the East India Trading Company in 1767?',\n",
       "   'In 1599 the British East India Company was established and was chartered by Queen Elizabeth in the following year.'],\n",
       "  ['The principle of faunal succession was developed 100 years before whose theory of evolution?',\n",
       "   \"Based on principles laid out by William Smith almost a hundred years before the publication of Charles Darwin's theory of evolution, the principles of succession were developed independently of evolutionary thought.\"],\n",
       "  ['How many times did Luther preach in Halle in 1545 and 1546?',\n",
       "   'In 1545 and 1546 Luther preached three times in the Market Church in Halle, staying with his friend Justus Jonas during Christmas.'],\n",
       "  ['What part of the Rhine flows through North Rhine-Westphalia?',\n",
       "   'Here the Rhine flows through the largest conurbation in Germany, the Rhine-Ruhr region.'],\n",
       "  ['What is the most important thing apicoplasts do?',\n",
       "   'The most important apicoplast function is isopentenyl pyrophosphate synthesis—in fact, apicomplexans die when something interferes with this apicoplast function, and when apicomplexans are grown in an isopentenyl pyrophosphate-rich medium, they dump the organelle.'],\n",
       "  [\"When did ABC begin airing Dick Clark's New Year's Rockin' Eve?\",\n",
       "   \"Since 1974, ABC has generally aired Dick Clark's New Year's Rockin' Eve on New Year's Eve (hosted first by its creator Dick Clark, and later by his successor Ryan Seacrest); the only exception was in 1999, when ABC put it on a one-year hiatus to provide coverage of the international millennium festivities, though Clark's traditional countdown from Times Square was still featured within the coverage.\"],\n",
       "  ['The Kronenberg Palace had been an exceptional example of what type of architecture?',\n",
       "   'Despite that the Warsaw University of Technology building (1899–1902) is the most interesting of the late 19th-century architecture.'],\n",
       "  ['What was the definition of professionals, for this study?',\n",
       "   'It is important to note, however, that the British study referenced above is the only one of its kind and consisted of \"a random ... probability sample of 2,869 young people between the ages of 18 and 24 in a computer-assisted study\" and that the questions referred to \"sexual abuse with a professional,\" not necessarily a teacher.'],\n",
       "  ['bassett focuses on what to illustrate his idea?',\n",
       "   'To better illustrate this idea, Bassett focuses his analysis of the role of nineteenth-century maps during the \"scramble for Africa\".'],\n",
       "  ['Where did Tesla believe his talents came from?',\n",
       "   \"Tesla's mother, Đuka Tesla (née Mandić), whose father was also an Orthodox priest,:10 had a talent for making home craft tools, mechanical appliances, and the ability to memorize Serbian epic poems.\"],\n",
       "  ['Who was given the esteemed status of MVP for Super Bowl 50?',\n",
       "   'Denver linebacker Von Miller was named Super Bowl MVP, recording five solo tackles, 2½ sacks, and two forced fumbles.'],\n",
       "  ['What was the percentage of Black or African-Americans living in the city?',\n",
       "   'Hispanic or Latino of any race were 39.9% of the population.'],\n",
       "  ['What was the result of the 2007 election?',\n",
       "   'With International Criminal Court trial dates in 2013 for both President Kenyatta and Deputy President William Ruto related to the 2007 election aftermath, US President Barack Obama chose not to visit the country during his mid-2013 African trip.'],\n",
       "  ['What equation currently decribes the physics of force.',\n",
       "   'The notion \"force\" keeps its meaning in quantum mechanics, though one is now dealing with operators instead of classical variables and though the physics is now described by the Schrödinger equation instead of Newtonian equations.'],\n",
       "  ['What did Iqbal fear would weaken the spiritual foundations of Islam and Muslim society?',\n",
       "   'In his travels to Egypt, Afghanistan, Palestine and Syria, he promoted ideas of greater Islamic political co-operation and unity, calling for the shedding of nationalist differences.'],\n",
       "  ['In what meeting did Shirley lay out plans for 1756?',\n",
       "   'At a meeting in Albany in December 1755, he laid out his plans for 1756.'],\n",
       "  [\"In autoimmune disorders, the immune system doesn't distinguish between what types of cells?\",\n",
       "   'One of the functions of specialized cells (located in the thymus and bone marrow) is to present young lymphocytes with self antigens produced throughout the body and to eliminate those cells that recognize self-antigens, preventing autoimmunity.'],\n",
       "  ['Which husband and wife modern furniture design team are represented in the V&A furniture collection?',\n",
       "   'One of the finest pieces of continental furniture in the collection is the Rococo Augustus Rex Bureau Cabinet dated c1750 from Germany, with especially fine marquetry and ormolu mounts.'],\n",
       "  ['Why did oil start getting priced in terms of gold?',\n",
       "   \"Because oil was priced in dollars, oil producers' real income decreased.\"],\n",
       "  ['Who did Britain exploit in India?',\n",
       "   'Although a substantial number of colonies had been designed to provide economic profit and to ship resources to home ports in the seventeenth and eighteenth centuries, Fieldhouse suggests that in the nineteenth and twentieth centuries in places such as Africa and Asia, this idea is not necessarily valid:'],\n",
       "  ['What popular environmentalist is also a university alumni member?',\n",
       "   'In science, alumni include astronomers Carl Sagan, a prominent contributor to the scientific research of extraterrestrial life, and Edwin Hubble, known for \"Hubble\\'s Law\", NASA astronaut John M. Grunsfeld, geneticist James Watson, best known as one of the co-discoverers of the structure of DNA, experimental physicist Luis Alvarez, popular environmentalist David Suzuki, balloonist Jeannette Piccard, biologists Ernest Everett'],\n",
       "  ['What publication did Philip Howard work for?',\n",
       "   'Responding to the findings of the survey in The Times newspaper, journalist Philip Howard maintained that, \"to compare the violence of Dr Who, sired by a horse-laugh out of a nightmare, with the more realistic violence of other television series, where actors who look like human beings bleed paint that looks like blood, is like comparing Monopoly with the property market in London: both are fantasies, but one is meant to be taken seriously.\"'],\n",
       "  ['If the apparant force of two fermions is attractive, what is the spin function?',\n",
       "   'If two identical fermions (e.g. electrons) have a symmetric spin function (e.g. parallel spins) the spatial variables must be antisymmetric (i.e. they exclude each other from their places much as if there was a repulsive force), and vice versa, i.e. for antiparallel spins the position variables must be symmetric (i.e. the apparent force must be attractive).']],\n",
       " 'targets': [0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'model_out_list': [0.6311678290367126,\n",
       "  0.7619203925132751,\n",
       "  0.7368832230567932,\n",
       "  0.8182130455970764,\n",
       "  0.9198501110076904,\n",
       "  0.8666946887969971,\n",
       "  0.5214384198188782,\n",
       "  0.8973642587661743,\n",
       "  0.8218711018562317,\n",
       "  0.8931249976158142,\n",
       "  0.7466775178909302,\n",
       "  0.3837520182132721,\n",
       "  0.8580110669136047,\n",
       "  0.7189930081367493,\n",
       "  0.9368581175804138,\n",
       "  0.7738507390022278,\n",
       "  0.575401782989502,\n",
       "  0.9446513652801514,\n",
       "  0.8502684831619263,\n",
       "  0.7733870148658752,\n",
       "  0.8900112509727478,\n",
       "  0.13032764196395874,\n",
       "  0.7593749761581421,\n",
       "  0.9370878338813782,\n",
       "  0.8867630362510681,\n",
       "  0.8243213295936584,\n",
       "  0.9457733035087585,\n",
       "  0.7392330169677734,\n",
       "  0.3316514492034912,\n",
       "  0.909346342086792,\n",
       "  0.7328494191169739,\n",
       "  0.7642964720726013,\n",
       "  0.7005867958068848,\n",
       "  0.5980805158615112,\n",
       "  0.42063799500465393,\n",
       "  0.5277463793754578,\n",
       "  0.7914941310882568,\n",
       "  0.9407644867897034,\n",
       "  0.9827529191970825,\n",
       "  0.3425130546092987,\n",
       "  0.23880738019943237,\n",
       "  0.38441193103790283,\n",
       "  0.6875017881393433,\n",
       "  0.8891812562942505,\n",
       "  0.918213963508606,\n",
       "  0.3373945653438568,\n",
       "  0.6999862194061279,\n",
       "  0.31498053669929504,\n",
       "  0.7388923764228821,\n",
       "  0.3203403353691101],\n",
       " 'raw_attr_list': [tensor([[[ 3.7111e-04,  1.0209e-03, -8.1120e-04,  ...,  3.4527e-05,\n",
       "            -2.4959e-05, -6.7916e-04],\n",
       "           [ 2.7085e-04,  1.6873e-04,  5.5883e-04,  ..., -1.5631e-04,\n",
       "             2.5188e-04, -1.9135e-03],\n",
       "           [ 5.2379e-05, -7.0464e-06, -4.5676e-05,  ...,  8.9604e-06,\n",
       "             6.7164e-04, -1.1755e-03],\n",
       "           ...,\n",
       "           [ 3.1041e-04, -1.8801e-03,  7.2879e-04,  ...,  1.1598e-04,\n",
       "             2.0866e-03, -2.7426e-03],\n",
       "           [ 6.2541e-04, -3.2460e-05, -5.9397e-07,  ...,  3.9114e-05,\n",
       "             1.0642e-03,  9.2873e-04],\n",
       "           [-2.4405e-05, -1.7148e-04,  3.5211e-04,  ..., -1.2680e-03,\n",
       "            -4.4239e-04, -1.7889e-04]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[-8.4116e-05, -4.4375e-04, -1.3010e-04,  ...,  1.9275e-05,\n",
       "            -2.2042e-05,  7.6548e-05],\n",
       "           [-1.3156e-03, -6.8335e-04, -7.8256e-04,  ..., -3.4214e-04,\n",
       "            -1.4838e-04, -1.3981e-04],\n",
       "           [-3.0744e-04,  9.1291e-05, -1.3350e-05,  ..., -2.6247e-04,\n",
       "             1.7694e-04,  1.1618e-04],\n",
       "           ...,\n",
       "           [-8.7684e-06,  3.4309e-08,  7.8054e-05,  ...,  5.7149e-05,\n",
       "            -1.4754e-04,  2.7926e-05],\n",
       "           [-1.2748e-04,  1.3408e-04,  2.2059e-05,  ..., -1.4005e-05,\n",
       "             2.1173e-04,  1.3801e-05],\n",
       "           [-1.2051e-04, -2.8798e-05, -2.9328e-05,  ...,  6.8790e-05,\n",
       "            -4.1770e-05,  3.0631e-06]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[-1.7370e-05,  1.5405e-04, -6.1980e-04,  ...,  4.3027e-05,\n",
       "            -7.2454e-05,  1.4175e-04],\n",
       "           [-2.0900e-03, -1.3839e-03, -2.9803e-03,  ..., -2.2030e-03,\n",
       "             1.9122e-04, -2.0847e-03],\n",
       "           [ 1.2362e-04,  7.4326e-04,  1.2510e-04,  ..., -1.8466e-04,\n",
       "            -4.5078e-05, -1.9294e-04],\n",
       "           ...,\n",
       "           [ 1.2891e-03,  1.9187e-04, -4.1077e-04,  ..., -7.6681e-05,\n",
       "             8.2369e-06,  8.8918e-05],\n",
       "           [ 2.0547e-04,  4.1414e-04, -2.9183e-04,  ..., -2.1692e-04,\n",
       "             4.9397e-04,  8.1957e-04],\n",
       "           [-1.0554e-04,  3.0779e-06,  1.6336e-04,  ..., -2.8295e-04,\n",
       "             1.0358e-04, -1.9809e-05]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[ 1.9816e-04,  6.8898e-05,  2.2906e-04,  ...,  7.2713e-06,\n",
       "            -4.7939e-06, -8.5101e-05],\n",
       "           [-4.6919e-06, -7.6608e-04,  6.9839e-04,  ...,  8.1605e-05,\n",
       "            -8.9602e-04,  1.0500e-04],\n",
       "           [ 6.6163e-05, -2.2437e-05,  1.2420e-04,  ...,  1.2064e-04,\n",
       "            -5.1420e-05,  8.9522e-05],\n",
       "           ...,\n",
       "           [ 1.1895e-04, -1.7503e-05,  6.7627e-05,  ...,  6.3767e-06,\n",
       "            -8.3971e-06,  4.4131e-06],\n",
       "           [-5.6788e-07,  5.3491e-05,  5.3954e-06,  ..., -4.3619e-05,\n",
       "             4.9723e-05,  8.3469e-05],\n",
       "           [ 4.5111e-06, -1.8064e-07, -3.6666e-05,  ..., -1.0621e-04,\n",
       "            -2.3628e-08, -1.4550e-05]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[ 1.1383e-05, -6.1972e-05,  7.8051e-05,  ...,  6.6422e-07,\n",
       "            -1.2077e-05,  1.5297e-05],\n",
       "           [ 7.5382e-05, -2.0787e-04, -1.6408e-04,  ..., -1.2575e-04,\n",
       "             5.4742e-05, -5.1155e-04],\n",
       "           [-1.6484e-04,  8.8569e-07,  2.0517e-05,  ..., -6.6881e-05,\n",
       "            -6.6800e-05,  1.0553e-04],\n",
       "           ...,\n",
       "           [ 1.4988e-05, -4.6864e-06, -4.7496e-06,  ...,  2.3297e-06,\n",
       "             4.3467e-05, -4.3286e-06],\n",
       "           [-3.0428e-06, -4.9666e-05, -4.4329e-06,  ...,  5.2397e-06,\n",
       "             6.0617e-05,  1.1186e-05],\n",
       "           [ 4.8227e-06,  1.4820e-05, -5.2242e-07,  ..., -4.3938e-06,\n",
       "             5.2609e-05,  1.0190e-06]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[-2.6473e-05, -1.3030e-04,  1.2169e-05,  ...,  1.0059e-05,\n",
       "            -2.5388e-05, -6.6011e-05],\n",
       "           [-3.3840e-06, -1.8605e-04,  1.1957e-03,  ..., -1.7871e-04,\n",
       "            -1.0487e-04,  1.8996e-05],\n",
       "           [-1.8940e-04, -1.4719e-04,  6.9330e-05,  ...,  1.6012e-04,\n",
       "            -2.0377e-06,  4.2258e-05],\n",
       "           ...,\n",
       "           [ 4.6906e-05, -5.8241e-05, -3.4411e-05,  ..., -7.0958e-05,\n",
       "            -9.6048e-05,  3.7894e-04],\n",
       "           [ 2.2529e-04,  1.8403e-04, -9.1565e-05,  ..., -1.0636e-04,\n",
       "             4.8751e-04,  6.7539e-04],\n",
       "           [ 1.4111e-05, -2.1064e-06,  3.4058e-05,  ..., -1.7980e-04,\n",
       "             4.7218e-05, -8.9516e-06]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[-1.4372e-04, -5.1928e-04, -1.7763e-03,  ..., -7.7984e-05,\n",
       "            -7.7985e-05, -1.8297e-04],\n",
       "           [ 2.8469e-03, -7.4401e-05, -2.5199e-04,  ...,  8.4165e-04,\n",
       "            -8.6307e-06, -9.1785e-04],\n",
       "           [-7.9957e-04, -4.2074e-05,  5.0563e-04,  ...,  2.1435e-04,\n",
       "            -4.4337e-04, -2.8915e-04],\n",
       "           ...,\n",
       "           [ 2.9639e-05, -8.9332e-08,  1.0695e-06,  ...,  1.6025e-04,\n",
       "            -9.9896e-05, -8.2385e-05],\n",
       "           [ 9.8727e-05,  1.0027e-04,  4.4256e-04,  ..., -1.1893e-04,\n",
       "             5.2414e-04,  7.8304e-04],\n",
       "           [-1.1917e-04, -1.5126e-04,  1.7656e-05,  ..., -1.0915e-03,\n",
       "            -5.0796e-06, -1.7514e-05]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[-1.8332e-05, -4.3148e-04,  1.5503e-04,  ...,  7.9453e-06,\n",
       "            -5.9234e-05,  2.5487e-04],\n",
       "           [-4.7999e-05, -4.6761e-05,  1.9035e-04,  ...,  1.3536e-04,\n",
       "            -1.3455e-04, -4.3985e-04],\n",
       "           [-1.0981e-05, -4.9840e-04,  1.9198e-05,  ..., -1.6717e-05,\n",
       "            -2.7079e-05, -2.5331e-04],\n",
       "           ...,\n",
       "           [-3.5485e-05,  3.9765e-05, -1.3437e-05,  ...,  1.2985e-04,\n",
       "             1.0278e-05, -5.7353e-05],\n",
       "           [ 1.2461e-04,  5.5660e-04, -8.7233e-05,  ..., -1.5482e-04,\n",
       "             2.3622e-04,  2.6877e-04],\n",
       "           [ 9.3633e-05,  1.0287e-04,  6.5838e-05,  ...,  9.1714e-05,\n",
       "             6.3884e-05, -9.2029e-05]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[-7.4020e-05, -4.8398e-04,  2.6439e-04,  ...,  1.3974e-05,\n",
       "             4.0145e-05,  1.5620e-05],\n",
       "           [-3.4443e-05, -8.9230e-05,  1.3514e-04,  ..., -2.5151e-05,\n",
       "             1.3900e-04,  6.7901e-05],\n",
       "           [ 8.5891e-05, -9.8053e-05,  6.7246e-05,  ..., -3.1031e-05,\n",
       "             2.6864e-05,  3.0804e-05],\n",
       "           ...,\n",
       "           [ 4.6525e-04, -6.9134e-05, -3.8549e-04,  ...,  1.4965e-08,\n",
       "             1.0127e-04, -3.8455e-04],\n",
       "           [ 7.2270e-05,  2.1795e-04,  1.0709e-04,  ...,  1.6279e-06,\n",
       "             4.8446e-04,  1.9929e-04],\n",
       "           [-4.6916e-05,  1.1275e-04, -2.6223e-05,  ..., -5.3070e-04,\n",
       "             7.5924e-07, -5.3499e-05]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[ 8.7572e-05,  1.6071e-04, -5.6299e-05,  ..., -4.9246e-06,\n",
       "             1.5064e-06, -1.1512e-04],\n",
       "           [-1.7870e-06, -3.4188e-04, -2.5737e-05,  ...,  2.2330e-04,\n",
       "            -1.7252e-05, -9.6327e-05],\n",
       "           [-4.0834e-04, -3.5529e-04,  8.3185e-04,  ..., -1.6511e-04,\n",
       "            -4.0371e-05, -4.8169e-06],\n",
       "           ...,\n",
       "           [ 1.5148e-04,  2.8190e-04, -1.0988e-06,  ...,  5.7992e-06,\n",
       "            -1.3412e-04, -1.5732e-05],\n",
       "           [ 3.2249e-04,  1.9797e-04, -8.7199e-06,  ...,  1.7522e-05,\n",
       "             2.5648e-04,  1.4486e-04],\n",
       "           [ 7.5645e-06,  4.5054e-05, -2.2562e-05,  ...,  1.8199e-05,\n",
       "            -2.4192e-06, -8.3634e-05]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[ 4.3433e-06,  1.5291e-04, -6.4169e-05,  ...,  1.2809e-05,\n",
       "            -7.8093e-05, -1.3344e-04],\n",
       "           [-2.3769e-05, -6.1643e-04,  1.4279e-04,  ..., -6.5083e-04,\n",
       "            -2.2940e-04, -1.0157e-03],\n",
       "           [ 2.1630e-04, -1.0465e-04, -6.9086e-04,  ...,  1.6210e-04,\n",
       "            -9.6561e-06, -1.2824e-04],\n",
       "           ...,\n",
       "           [-1.7641e-04, -3.5857e-04, -1.1205e-05,  ..., -3.5194e-05,\n",
       "            -1.6884e-05, -3.5767e-07],\n",
       "           [-9.4848e-05,  5.8366e-05,  2.2830e-05,  ..., -4.4631e-05,\n",
       "             6.9599e-05,  9.0346e-05],\n",
       "           [-1.0496e-04, -4.2672e-05,  7.9729e-07,  ...,  2.3186e-05,\n",
       "            -2.4279e-05, -1.4295e-05]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[-7.3951e-05, -3.9545e-04, -6.1543e-05,  ..., -4.5366e-05,\n",
       "            -1.8298e-05,  1.2244e-04],\n",
       "           [-1.0088e-03, -1.0015e-03,  1.3412e-04,  ..., -8.4219e-04,\n",
       "             5.4163e-04, -5.3636e-04],\n",
       "           [-6.1281e-04, -2.3248e-05,  8.3095e-04,  ...,  4.1293e-04,\n",
       "             5.5355e-04,  3.2399e-03],\n",
       "           ...,\n",
       "           [ 8.2860e-05,  2.3889e-04,  7.5766e-04,  ..., -1.0285e-04,\n",
       "            -1.6265e-04,  2.7062e-06],\n",
       "           [-4.3859e-05, -2.7222e-04,  7.3110e-05,  ..., -1.2192e-04,\n",
       "             5.9420e-04,  5.9289e-04],\n",
       "           [ 1.4157e-04,  9.2791e-05,  8.5224e-05,  ..., -2.7482e-06,\n",
       "             3.5592e-04,  2.5565e-05]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[-9.4996e-05, -5.4664e-04, -5.0485e-05,  ...,  2.3364e-05,\n",
       "            -1.0472e-04, -4.3891e-05],\n",
       "           [-6.2702e-06,  4.4439e-05, -1.8020e-06,  ...,  4.1655e-05,\n",
       "            -2.4685e-04, -3.2254e-05],\n",
       "           [ 1.4571e-05, -1.3938e-04,  2.1754e-05,  ...,  5.5430e-05,\n",
       "            -2.6884e-05,  1.7792e-05],\n",
       "           ...,\n",
       "           [ 1.3143e-04, -3.7274e-05,  1.3290e-04,  ...,  6.1806e-05,\n",
       "            -2.6645e-05, -1.1421e-04],\n",
       "           [-2.7844e-06,  1.1502e-04, -2.7454e-06,  ..., -1.4175e-04,\n",
       "            -4.3560e-05,  5.8647e-05],\n",
       "           [ 5.7549e-06,  3.5120e-05,  7.5405e-06,  ...,  2.1988e-04,\n",
       "             3.2798e-05, -4.8778e-06]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[-8.3971e-05, -2.7975e-04, -6.7084e-04,  ...,  1.3754e-05,\n",
       "            -1.3083e-05, -8.1274e-05],\n",
       "           [-1.0778e-04,  2.6217e-04, -3.4128e-04,  ..., -5.6263e-05,\n",
       "            -3.8154e-04, -1.5983e-05],\n",
       "           [ 7.8938e-05,  9.8689e-05,  3.6989e-06,  ...,  9.8171e-05,\n",
       "            -1.0993e-04,  2.2808e-04],\n",
       "           ...,\n",
       "           [ 3.0922e-05, -3.0655e-04, -8.2173e-05,  ..., -5.1122e-04,\n",
       "             4.5116e-06, -2.9388e-05],\n",
       "           [-2.8897e-04,  3.1485e-04, -9.7398e-05,  ..., -4.1498e-05,\n",
       "             8.1758e-04,  1.8746e-03],\n",
       "           [-2.4385e-05,  2.8468e-05,  2.7970e-05,  ..., -8.0623e-04,\n",
       "             1.0887e-04, -8.8757e-05]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[-1.0256e-05,  1.7293e-05,  4.6794e-06,  ...,  4.4687e-06,\n",
       "             9.5993e-06,  2.5685e-05],\n",
       "           [-1.8784e-05, -2.8811e-05, -3.6132e-06,  ...,  1.0940e-06,\n",
       "             7.4325e-06, -1.1119e-05],\n",
       "           [-7.9577e-06, -3.0454e-05,  2.1579e-05,  ..., -6.2231e-05,\n",
       "            -1.7293e-05, -3.2166e-05],\n",
       "           ...,\n",
       "           [ 2.8775e-06,  1.2327e-05, -1.0784e-04,  ...,  2.7353e-05,\n",
       "            -2.3823e-06, -2.2419e-05],\n",
       "           [-5.0420e-07, -1.2981e-05,  5.4904e-07,  ..., -1.3817e-05,\n",
       "             5.3420e-05,  1.6904e-06],\n",
       "           [ 4.5191e-06, -5.7483e-06, -1.0673e-06,  ...,  3.4362e-05,\n",
       "             1.0910e-05, -4.9634e-06]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[-6.5296e-05,  4.1384e-05,  1.8435e-04,  ..., -4.9168e-06,\n",
       "            -3.1481e-05, -2.6785e-04],\n",
       "           [-4.4281e-06,  2.4043e-04,  1.3294e-03,  ..., -5.0939e-04,\n",
       "            -2.3551e-04,  1.4787e-04],\n",
       "           [-3.3907e-04,  5.3109e-04, -4.8922e-05,  ..., -5.0303e-04,\n",
       "             3.6609e-04,  3.9345e-04],\n",
       "           ...,\n",
       "           [ 3.3492e-04, -5.7108e-05,  8.2679e-05,  ...,  1.5753e-04,\n",
       "            -8.8515e-05,  1.7692e-05],\n",
       "           [ 2.1443e-05,  2.1345e-04, -9.7304e-06,  ..., -4.4229e-05,\n",
       "             4.2264e-05,  2.4825e-06],\n",
       "           [-1.4581e-04, -3.9956e-05,  3.2863e-05,  ...,  4.5484e-05,\n",
       "             3.4951e-05, -3.1669e-05]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[-1.9109e-04, -1.1583e-04, -2.2696e-04,  ..., -8.3098e-05,\n",
       "            -1.9469e-04, -3.6973e-04],\n",
       "           [-5.1355e-04, -2.3905e-03, -2.9211e-04,  ..., -1.2571e-03,\n",
       "            -2.8283e-04, -2.3993e-03],\n",
       "           [-5.0454e-04,  2.0827e-03,  2.8460e-04,  ..., -3.5945e-04,\n",
       "             1.4384e-05, -1.8905e-03],\n",
       "           ...,\n",
       "           [-1.9014e-04,  4.3700e-04,  7.5484e-05,  ...,  6.2927e-05,\n",
       "            -1.3959e-03, -1.9033e-04],\n",
       "           [ 9.3324e-04,  2.5601e-03, -3.1958e-04,  ..., -7.3494e-04,\n",
       "             2.3412e-03,  4.0073e-03],\n",
       "           [-6.8080e-04, -1.3040e-05,  1.6743e-04,  ..., -1.9759e-04,\n",
       "             1.9179e-04, -1.8790e-04]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[-6.4248e-06, -9.7322e-05,  1.1347e-05,  ..., -6.8478e-06,\n",
       "            -1.9955e-05,  9.3235e-05],\n",
       "           [ 1.5341e-04, -2.3621e-04, -8.6706e-04,  ...,  9.2522e-05,\n",
       "            -1.5068e-04, -2.1267e-03],\n",
       "           [-3.0499e-04, -8.5371e-04, -1.8435e-04,  ..., -3.7793e-05,\n",
       "             5.9660e-05,  1.9639e-04],\n",
       "           ...,\n",
       "           [ 4.1280e-05, -2.2320e-06,  9.8512e-06,  ..., -5.5759e-05,\n",
       "            -2.1105e-04,  1.9880e-05],\n",
       "           [ 7.5158e-06, -4.3823e-07, -4.0652e-06,  ...,  2.4464e-06,\n",
       "             7.3937e-05,  3.9367e-05],\n",
       "           [ 6.7162e-06,  8.2683e-06, -2.3159e-05,  ..., -8.5843e-05,\n",
       "             6.1341e-06, -5.5159e-06]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[ 1.4451e-04, -4.5728e-04,  1.0173e-05,  ...,  5.2813e-06,\n",
       "            -6.1377e-05, -1.5509e-04],\n",
       "           [-7.8660e-04, -1.5658e-04,  6.8598e-05,  ..., -4.7604e-04,\n",
       "            -6.2580e-04,  7.2951e-04],\n",
       "           [ 7.9702e-05,  1.1356e-05,  2.9487e-05,  ..., -1.4054e-05,\n",
       "             1.0388e-04,  1.9725e-05],\n",
       "           ...,\n",
       "           [-2.0950e-05, -2.7199e-04,  1.0740e-04,  ..., -1.3543e-05,\n",
       "             2.5653e-06, -1.2437e-05],\n",
       "           [-1.5052e-05,  1.9303e-05, -2.0013e-04,  ...,  3.5204e-05,\n",
       "             2.7131e-04,  1.0766e-04],\n",
       "           [-5.2470e-07,  6.3354e-05, -3.7374e-06,  ...,  9.3414e-05,\n",
       "             8.4636e-05, -2.5366e-06]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[-5.4520e-06,  7.2011e-05, -8.5413e-05,  ...,  2.1443e-05,\n",
       "            -3.9905e-05, -1.7344e-04],\n",
       "           [ 2.0257e-05, -1.7548e-04, -6.6252e-05,  ..., -3.4878e-05,\n",
       "             4.4093e-05,  1.2662e-04],\n",
       "           [-4.5029e-04,  2.4575e-05, -6.4789e-05,  ...,  5.6432e-05,\n",
       "             4.8028e-05,  1.2984e-04],\n",
       "           ...,\n",
       "           [ 1.9216e-04,  9.0688e-07, -6.7308e-05,  ..., -1.4754e-04,\n",
       "             1.3718e-04,  1.1569e-07],\n",
       "           [ 1.0617e-06,  6.3256e-06, -5.8263e-07,  ..., -2.9081e-06,\n",
       "             1.1025e-05, -9.4614e-05],\n",
       "           [-2.2086e-05, -2.1538e-07,  6.5199e-05,  ..., -3.1106e-05,\n",
       "            -3.6140e-05, -2.0955e-05]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[-5.5046e-06, -4.0915e-06,  1.2054e-04,  ..., -1.1020e-05,\n",
       "             1.4748e-05, -1.1803e-04],\n",
       "           [ 1.8932e-04, -1.8227e-04,  5.3109e-05,  ..., -1.5833e-04,\n",
       "             4.0942e-05,  2.8583e-06],\n",
       "           [-5.2856e-05,  1.9300e-04,  1.4904e-04,  ...,  8.6369e-05,\n",
       "             1.5708e-03,  1.4849e-05],\n",
       "           ...,\n",
       "           [ 6.4924e-06,  2.7175e-06,  2.2501e-05,  ...,  6.4865e-05,\n",
       "             6.7658e-05,  2.1356e-04],\n",
       "           [ 2.5542e-05, -6.9762e-07,  1.6672e-05,  ...,  6.1696e-06,\n",
       "             6.0237e-06, -1.3675e-05],\n",
       "           [ 2.3034e-05, -5.4308e-05,  2.7237e-05,  ...,  2.1625e-04,\n",
       "            -5.1118e-05,  4.1893e-06]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[-4.3571e-05,  2.1920e-04, -6.5280e-05,  ..., -3.0183e-06,\n",
       "             1.5149e-06, -1.2056e-04],\n",
       "           [ 1.0809e-04,  9.1985e-06, -2.6193e-06,  ...,  2.3582e-05,\n",
       "             1.8980e-05, -5.0750e-04],\n",
       "           [-9.5516e-05, -3.0275e-05, -6.2644e-05,  ...,  3.3219e-05,\n",
       "             2.1640e-05, -5.1888e-06],\n",
       "           ...,\n",
       "           [-2.9426e-05, -2.4100e-04,  5.7069e-05,  ..., -7.4546e-06,\n",
       "             6.7367e-05, -1.9079e-05],\n",
       "           [ 5.0378e-05,  1.7734e-05,  5.2479e-05,  ..., -2.8414e-05,\n",
       "             1.1937e-04, -1.4845e-04],\n",
       "           [ 5.5408e-06, -2.7799e-05,  1.6227e-05,  ..., -6.9186e-05,\n",
       "            -1.7366e-06,  4.4072e-06]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[ 7.9373e-06,  6.7209e-05, -8.1711e-05,  ...,  8.5304e-06,\n",
       "            -2.0839e-05, -1.2042e-04],\n",
       "           [ 1.8376e-04, -2.0137e-04, -4.0385e-05,  ..., -1.0950e-04,\n",
       "             5.4248e-05, -5.7435e-04],\n",
       "           [ 1.7697e-04,  9.4386e-05, -6.4297e-05,  ...,  3.0270e-05,\n",
       "             6.8710e-05, -2.3850e-05],\n",
       "           ...,\n",
       "           [ 3.4255e-05, -2.2610e-05, -5.2764e-05,  ...,  2.0859e-05,\n",
       "             3.8024e-05,  3.3088e-05],\n",
       "           [ 2.7457e-05,  3.9928e-05, -1.6967e-07,  ..., -5.6450e-05,\n",
       "             1.7785e-04,  2.1446e-04],\n",
       "           [-5.6999e-05,  3.0021e-05,  9.8032e-08,  ..., -2.0393e-04,\n",
       "             1.0401e-05, -4.2516e-06]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[-1.7957e-05, -1.8729e-04,  9.7607e-05,  ...,  3.7287e-06,\n",
       "             5.9926e-06, -8.2177e-05],\n",
       "           [-7.4096e-06, -8.2413e-05,  8.2803e-05,  ...,  6.7202e-05,\n",
       "             1.9902e-05,  6.5959e-05],\n",
       "           [-3.2033e-04,  5.9740e-05, -9.8999e-07,  ...,  8.6494e-07,\n",
       "             3.8705e-05, -2.1009e-06],\n",
       "           ...,\n",
       "           [-2.0287e-05, -3.8342e-06, -2.5015e-05,  ..., -2.1604e-04,\n",
       "            -1.0498e-04,  1.4849e-05],\n",
       "           [ 2.5576e-05,  9.0470e-05, -2.8575e-06,  ..., -2.8023e-05,\n",
       "             2.2522e-04,  4.6974e-05],\n",
       "           [-8.9100e-06,  4.6866e-06, -4.2913e-07,  ..., -2.5774e-05,\n",
       "             3.5308e-05,  5.2138e-07]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[-1.0773e-04,  4.1440e-05, -4.5233e-05,  ...,  9.1304e-06,\n",
       "             4.8207e-06,  3.5003e-05],\n",
       "           [-2.3957e-05, -1.3826e-04,  6.0364e-05,  ...,  1.0730e-05,\n",
       "            -3.0622e-05, -5.8367e-05],\n",
       "           [-7.1673e-05,  1.4823e-04,  5.4170e-05,  ..., -1.5489e-05,\n",
       "            -3.9802e-06, -4.8775e-05],\n",
       "           ...,\n",
       "           [-4.6695e-05, -1.5958e-04,  8.6209e-05,  ...,  3.6989e-05,\n",
       "             9.6260e-06,  1.4891e-04],\n",
       "           [-3.5440e-05,  8.5683e-05,  5.8728e-05,  ...,  2.4536e-05,\n",
       "             4.5303e-05,  5.7299e-05],\n",
       "           [-1.0855e-04,  8.4254e-05, -9.3118e-05,  ..., -8.1348e-05,\n",
       "             2.1628e-06,  7.0810e-06]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[ 1.5359e-04, -6.5901e-04,  2.6727e-04,  ..., -1.2382e-05,\n",
       "            -2.7678e-05, -2.5251e-04],\n",
       "           [ 8.6054e-04, -4.1003e-04, -2.2347e-04,  ..., -4.7129e-04,\n",
       "             1.2529e-04, -1.6742e-03],\n",
       "           [ 2.6524e-04,  4.1852e-04,  7.0567e-04,  ...,  3.2368e-04,\n",
       "             1.1352e-04,  1.5058e-04],\n",
       "           ...,\n",
       "           [-6.5546e-04, -5.1372e-05, -2.1991e-06,  ...,  3.3010e-05,\n",
       "            -7.1767e-05,  1.8849e-05],\n",
       "           [ 2.0862e-04,  6.0199e-04,  4.6357e-05,  ..., -2.3486e-04,\n",
       "             9.0583e-04,  1.3402e-03],\n",
       "           [ 1.3839e-05,  6.7610e-06, -3.0127e-05,  ...,  2.6957e-04,\n",
       "             3.1027e-04, -3.0652e-05]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[ 1.6148e-05, -8.7989e-05,  3.0549e-05,  ..., -1.7647e-06,\n",
       "            -3.3247e-06, -2.6737e-05],\n",
       "           [ 2.6516e-05, -2.6532e-05, -1.2792e-04,  ..., -9.0465e-07,\n",
       "            -1.9378e-05, -3.0749e-04],\n",
       "           [-3.4085e-05,  1.2681e-04, -1.7856e-04,  ..., -5.2246e-04,\n",
       "             4.6088e-04, -8.9472e-08],\n",
       "           ...,\n",
       "           [ 1.2854e-04,  1.7201e-04,  9.9850e-07,  ..., -1.3391e-05,\n",
       "             1.0115e-04,  1.0276e-06],\n",
       "           [ 5.3862e-06,  5.1378e-05,  8.3848e-06,  ..., -3.4915e-06,\n",
       "             2.0196e-05,  1.3292e-05],\n",
       "           [-1.1853e-05,  1.0693e-06, -1.1847e-05,  ..., -1.0330e-05,\n",
       "             7.8275e-06,  1.7556e-06]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[-5.9931e-05, -8.6843e-05, -6.0872e-04,  ..., -2.8999e-05,\n",
       "            -1.1758e-05, -1.9912e-04],\n",
       "           [ 3.7210e-04, -4.4567e-04,  6.9667e-04,  ...,  2.7562e-04,\n",
       "             2.5443e-04, -1.6305e-04],\n",
       "           [-5.1746e-05, -4.2570e-05,  1.7527e-04,  ...,  5.7874e-05,\n",
       "            -5.7098e-04,  6.2618e-05],\n",
       "           ...,\n",
       "           [-2.8942e-04,  2.3450e-05, -1.0132e-04,  ...,  3.5453e-05,\n",
       "             2.7603e-04, -3.7417e-04],\n",
       "           [ 2.2716e-05,  3.1771e-05,  1.8516e-05,  ...,  9.1412e-06,\n",
       "             9.9824e-05,  6.4250e-04],\n",
       "           [-4.4294e-05,  6.9160e-05,  1.2991e-05,  ..., -4.7191e-04,\n",
       "             6.1202e-05, -1.4118e-04]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[-2.7179e-04,  5.9307e-04, -4.9201e-04,  ..., -1.3178e-05,\n",
       "             1.0038e-04, -3.6360e-04],\n",
       "           [ 3.3009e-05, -9.8724e-05, -1.8928e-05,  ...,  1.0075e-05,\n",
       "            -3.3135e-04,  2.5174e-04],\n",
       "           [-2.9557e-04, -1.9512e-04,  1.8742e-03,  ...,  1.5958e-06,\n",
       "            -2.5312e-04,  9.8836e-06],\n",
       "           ...,\n",
       "           [-9.5947e-06, -4.5259e-04, -5.1025e-04,  ..., -7.7265e-05,\n",
       "            -4.1816e-05,  1.6170e-04],\n",
       "           [-5.6459e-05,  8.1634e-06,  1.6284e-07,  ..., -1.0846e-05,\n",
       "            -5.8358e-05, -3.2014e-04],\n",
       "           [-9.3445e-05,  3.1712e-05, -1.8038e-07,  ...,  2.4858e-04,\n",
       "             3.8996e-06,  1.2570e-05]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[ 4.6084e-05, -5.7887e-05, -1.0171e-04,  ..., -4.6200e-06,\n",
       "             9.0065e-09, -2.6014e-05],\n",
       "           [-8.6560e-07,  8.9659e-05,  7.1588e-04,  ...,  1.4154e-04,\n",
       "            -1.5627e-04,  1.6726e-04],\n",
       "           [-1.4902e-04, -7.8464e-05,  3.4974e-05,  ..., -1.1453e-05,\n",
       "            -3.6509e-05, -2.4205e-04],\n",
       "           ...,\n",
       "           [ 4.8432e-05, -3.5210e-05, -7.3470e-05,  ...,  2.8677e-04,\n",
       "            -3.5544e-05,  4.1384e-05],\n",
       "           [ 3.1528e-05,  1.4005e-04,  5.1934e-05,  ...,  8.1200e-05,\n",
       "             8.7560e-06,  1.2829e-04],\n",
       "           [ 7.9899e-05,  3.5223e-05,  1.1250e-05,  ..., -6.4568e-05,\n",
       "             5.5420e-05, -2.3790e-05]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[ 1.5167e-05, -3.4664e-05,  1.3575e-05,  ..., -3.2372e-05,\n",
       "            -1.0101e-04, -6.0922e-04],\n",
       "           [-6.4189e-04, -2.0562e-04,  1.5696e-04,  ...,  1.0148e-04,\n",
       "            -1.2060e-04, -3.2319e-03],\n",
       "           [ 7.4157e-04,  6.2668e-04,  1.0037e-03,  ...,  7.7267e-05,\n",
       "             5.4471e-04, -9.4858e-04],\n",
       "           ...,\n",
       "           [-1.1799e-04,  6.7220e-05,  3.3084e-05,  ..., -2.1771e-04,\n",
       "            -2.9672e-04, -1.4195e-04],\n",
       "           [ 3.5750e-05,  3.6901e-04,  2.8249e-05,  ...,  7.8748e-06,\n",
       "             1.0730e-03,  5.2660e-04],\n",
       "           [-9.1741e-05, -1.5547e-04, -5.7539e-05,  ..., -5.8031e-04,\n",
       "             3.6381e-04,  7.2100e-05]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[-3.5859e-05,  4.9973e-04, -3.7756e-04,  ..., -6.3146e-06,\n",
       "             3.1260e-06, -6.5533e-05],\n",
       "           [ 5.7231e-04, -3.8691e-05, -1.5600e-04,  ..., -3.7814e-05,\n",
       "            -4.1651e-05, -5.1788e-04],\n",
       "           [-9.8540e-05,  1.0148e-05,  2.8573e-05,  ...,  2.4655e-05,\n",
       "             7.5364e-05,  3.3330e-05],\n",
       "           ...,\n",
       "           [-1.4873e-04,  7.4009e-05,  2.0840e-04,  ...,  3.1042e-06,\n",
       "             4.6862e-04,  3.5422e-05],\n",
       "           [-1.7314e-05,  8.5379e-05,  4.2628e-05,  ...,  2.8124e-05,\n",
       "             1.8799e-04,  1.0955e-04],\n",
       "           [-4.6955e-05,  2.9169e-05,  4.3235e-05,  ..., -2.0426e-05,\n",
       "            -2.8890e-05, -2.9627e-05]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[ 9.1790e-05,  2.1785e-03, -5.9112e-04,  ...,  6.0792e-06,\n",
       "            -2.1292e-04, -6.9017e-04],\n",
       "           [-8.1292e-04,  1.5790e-03, -1.3359e-04,  ...,  1.3321e-04,\n",
       "             1.2497e-03, -1.3775e-04],\n",
       "           [ 2.4211e-04,  3.0169e-04, -7.0033e-04,  ..., -1.0030e-04,\n",
       "            -1.4164e-04, -9.1720e-04],\n",
       "           ...,\n",
       "           [-1.2274e-03,  8.7449e-05,  6.4276e-04,  ...,  1.7518e-04,\n",
       "            -4.6977e-04, -1.0060e-03],\n",
       "           [-1.8863e-04, -2.8940e-04,  1.2731e-05,  ..., -3.6309e-06,\n",
       "             6.1238e-04, -7.3114e-04],\n",
       "           [ 9.9637e-05, -1.2241e-04,  2.8504e-04,  ...,  2.1395e-04,\n",
       "            -1.1623e-05, -2.6015e-04]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[ 1.1219e-04,  8.3059e-04, -1.1491e-03,  ...,  5.2012e-05,\n",
       "            -1.1908e-04, -8.7963e-04],\n",
       "           [-4.2612e-04, -2.1494e-03,  7.5071e-05,  ..., -2.9226e-05,\n",
       "            -7.6930e-04,  2.1131e-03],\n",
       "           [-7.2929e-05,  2.6096e-04,  7.3663e-06,  ...,  4.9780e-05,\n",
       "             5.0675e-05, -2.6757e-04],\n",
       "           ...,\n",
       "           [ 3.6296e-04, -1.1707e-03, -4.7614e-04,  ...,  4.3267e-04,\n",
       "             7.7949e-04, -6.2902e-05],\n",
       "           [ 1.6548e-06,  5.7792e-04,  2.1512e-04,  ..., -2.8883e-04,\n",
       "             3.8459e-04,  1.3171e-03],\n",
       "           [-1.0727e-04,  1.8462e-04,  1.7233e-04,  ...,  1.2205e-04,\n",
       "            -3.8382e-04, -1.4584e-04]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[-8.3231e-05,  6.3288e-05, -2.2703e-04,  ..., -8.5361e-07,\n",
       "            -1.1388e-05, -1.2106e-04],\n",
       "           [ 2.3561e-04, -3.5640e-05, -1.0985e-04,  ..., -1.8960e-07,\n",
       "            -2.6384e-05, -1.0905e-04],\n",
       "           [-5.0496e-05, -2.8597e-04, -7.2921e-05,  ..., -1.4026e-05,\n",
       "            -3.4655e-05,  4.7775e-05],\n",
       "           ...,\n",
       "           [-1.4270e-04,  2.6888e-05,  1.3883e-04,  ...,  3.0981e-04,\n",
       "            -1.8041e-04,  9.4237e-05],\n",
       "           [ 3.4937e-05, -6.2040e-05,  3.4436e-06,  ..., -2.0275e-05,\n",
       "            -3.8946e-05,  3.6969e-06],\n",
       "           [ 1.4499e-04,  3.2921e-06, -3.7026e-05,  ..., -1.6440e-05,\n",
       "             8.1304e-06, -5.0419e-05]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[ 9.1735e-04,  1.8359e-05, -4.4420e-04,  ...,  8.9583e-06,\n",
       "            -6.2074e-05, -5.7936e-04],\n",
       "           [-3.7226e-04,  5.1796e-04,  1.4162e-03,  ..., -3.1182e-03,\n",
       "            -1.7131e-05,  7.1804e-04],\n",
       "           [-8.2692e-05,  7.4403e-05,  1.6730e-04,  ..., -2.4487e-05,\n",
       "            -3.2634e-03, -1.1970e-03],\n",
       "           ...,\n",
       "           [ 3.6002e-04, -1.3509e-04,  2.3216e-04,  ...,  2.2811e-05,\n",
       "            -7.9177e-05, -3.7091e-06],\n",
       "           [-1.2690e-04,  1.5860e-04, -1.6082e-05,  ...,  1.0717e-05,\n",
       "             8.3152e-04,  9.3419e-05],\n",
       "           [-2.2931e-04,  1.9603e-05,  5.3650e-05,  ..., -2.2611e-04,\n",
       "             2.1092e-04,  3.1832e-05]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[-4.1635e-05, -1.0009e-04, -1.8552e-04,  ..., -2.3184e-07,\n",
       "            -6.2860e-05, -1.9312e-04],\n",
       "           [-5.4684e-04,  2.7895e-04, -1.6721e-04,  ..., -1.1662e-04,\n",
       "            -5.7065e-04, -1.6322e-04],\n",
       "           [-7.4106e-05, -1.6104e-04, -4.5866e-06,  ..., -1.9077e-05,\n",
       "             3.7557e-05, -1.0472e-04],\n",
       "           ...,\n",
       "           [ 1.1135e-04, -2.6183e-05, -9.0575e-05,  ...,  2.0498e-04,\n",
       "            -1.3812e-04, -2.0298e-04],\n",
       "           [ 3.0876e-05,  9.2183e-05,  1.1722e-05,  ...,  1.2324e-05,\n",
       "             3.3505e-05, -1.7409e-04],\n",
       "           [ 7.2763e-05, -2.8244e-05, -8.1136e-07,  ...,  1.0155e-04,\n",
       "            -7.9862e-05, -2.7313e-05]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[ 9.5827e-05, -3.5063e-05, -1.1819e-04,  ..., -2.7366e-06,\n",
       "             1.3408e-05,  7.0581e-05],\n",
       "           [-3.2968e-05, -1.1392e-04, -9.9738e-05,  ...,  5.7815e-05,\n",
       "             7.3426e-05, -1.6887e-05],\n",
       "           [-2.9038e-05,  1.6165e-04,  1.8284e-05,  ...,  1.2011e-05,\n",
       "            -2.1344e-06,  5.8937e-06],\n",
       "           ...,\n",
       "           [-2.2761e-05, -2.6622e-07,  2.0702e-06,  ...,  7.3909e-07,\n",
       "             6.7905e-07,  1.8601e-05],\n",
       "           [ 1.3651e-05,  9.3666e-05, -2.0449e-05,  ..., -2.4838e-05,\n",
       "             2.7607e-04,  9.5027e-05],\n",
       "           [-2.3850e-05,  7.0774e-05,  5.0947e-05,  ...,  1.9967e-05,\n",
       "             3.4313e-05, -2.3160e-06]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[-1.3877e-05, -6.9294e-05,  4.9871e-05,  ...,  1.5410e-06,\n",
       "            -8.8577e-06,  2.3863e-05],\n",
       "           [-8.7533e-05, -1.4409e-05,  3.8449e-05,  ..., -1.1486e-05,\n",
       "             5.2847e-06, -1.3241e-04],\n",
       "           [ 2.9804e-06,  2.8423e-06, -9.2145e-06,  ..., -5.7649e-06,\n",
       "             1.8265e-06,  1.2190e-05],\n",
       "           ...,\n",
       "           [-4.2047e-06,  5.0673e-05, -2.0219e-05,  ..., -5.3307e-06,\n",
       "             3.5770e-05,  3.3062e-05],\n",
       "           [ 6.4550e-06,  3.9336e-08,  9.9279e-06,  ..., -6.0337e-07,\n",
       "             3.0125e-05,  3.8902e-06],\n",
       "           [-5.6866e-06, -6.8221e-06,  2.1149e-06,  ...,  2.0536e-05,\n",
       "            -6.5442e-07, -8.2503e-06]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[-1.0131e-04, -1.2236e-04, -2.2374e-04,  ..., -6.3059e-06,\n",
       "            -9.8671e-06, -1.5579e-04],\n",
       "           [-3.0920e-05, -2.4868e-04,  5.9441e-04,  ...,  3.4648e-04,\n",
       "             8.8461e-05, -1.3073e-03],\n",
       "           [-3.1743e-04, -3.0952e-04,  1.6648e-04,  ..., -1.0117e-04,\n",
       "             4.4788e-06,  6.9140e-05],\n",
       "           ...,\n",
       "           [-1.2823e-05, -2.1040e-05,  3.4693e-06,  ..., -3.9387e-05,\n",
       "             8.5348e-05,  7.8360e-05],\n",
       "           [-2.8847e-05, -5.0634e-05, -3.0223e-05,  ...,  2.4846e-06,\n",
       "            -6.2092e-05, -6.9107e-05],\n",
       "           [-1.1197e-04, -5.0469e-05,  7.8575e-05,  ..., -1.7356e-04,\n",
       "            -5.0570e-05,  5.0152e-05]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[-3.1614e-04,  2.2616e-05,  1.2516e-04,  ...,  5.0029e-05,\n",
       "            -9.1257e-05, -1.6144e-04],\n",
       "           [-7.5957e-04,  1.1259e-03,  2.0338e-03,  ..., -8.0695e-04,\n",
       "             2.0812e-05,  2.1573e-03],\n",
       "           [ 8.9305e-05,  1.7144e-04,  7.0806e-04,  ..., -2.7730e-04,\n",
       "            -2.3721e-03, -2.4807e-05],\n",
       "           ...,\n",
       "           [-3.6820e-04, -3.8014e-04,  9.5046e-05,  ...,  3.4670e-05,\n",
       "            -1.2608e-03,  3.6171e-04],\n",
       "           [-5.4668e-05,  4.1296e-04, -6.4806e-05,  ...,  3.4153e-05,\n",
       "             8.0381e-05, -1.8908e-04],\n",
       "           [-9.9226e-05,  3.8761e-07, -8.1504e-05,  ..., -4.2876e-04,\n",
       "            -7.4678e-06,  4.9907e-05]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[-1.8755e-04, -5.5376e-04, -6.7897e-04,  ...,  1.0538e-05,\n",
       "            -5.0776e-05, -8.6700e-04],\n",
       "           [-4.6067e-05, -8.7355e-06,  1.4376e-04,  ..., -8.9491e-05,\n",
       "             1.2395e-04, -9.6691e-04],\n",
       "           [ 3.7267e-04,  2.8151e-04, -1.1236e-03,  ...,  4.4225e-04,\n",
       "            -4.8555e-05,  2.1246e-04],\n",
       "           ...,\n",
       "           [ 2.0230e-04,  1.4583e-03, -4.6190e-06,  ..., -8.2245e-05,\n",
       "             2.4184e-04,  1.9888e-05],\n",
       "           [-9.2636e-05,  2.9406e-04, -9.2690e-05,  ..., -1.1705e-04,\n",
       "             2.1448e-04,  2.1268e-04],\n",
       "           [ 2.8502e-05,  1.3325e-05, -7.2178e-05,  ...,  2.1827e-04,\n",
       "             2.5556e-07,  1.0159e-05]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[ 2.1053e-05,  3.8471e-04, -1.2732e-03,  ...,  1.0821e-04,\n",
       "            -1.4497e-04, -4.0759e-04],\n",
       "           [ 1.5515e-04, -2.1071e-04, -3.5816e-04,  ..., -3.0416e-04,\n",
       "             2.9476e-04,  4.0065e-04],\n",
       "           [ 4.0004e-03, -1.7524e-03, -1.2003e-03,  ..., -2.7831e-03,\n",
       "             3.7036e-04, -3.0950e-03],\n",
       "           ...,\n",
       "           [-5.8987e-03,  6.2322e-04,  6.4548e-03,  ...,  1.6495e-03,\n",
       "             1.6359e-03,  4.0240e-03],\n",
       "           [-2.2945e-03,  1.6518e-03,  2.5744e-04,  ..., -8.9063e-04,\n",
       "            -5.8314e-04, -4.5580e-04],\n",
       "           [-1.5113e-03, -3.2580e-04,  4.0478e-04,  ..., -3.8075e-03,\n",
       "            -3.5706e-05,  1.0125e-03]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[ 6.6039e-05,  8.7157e-05, -3.8462e-05,  ..., -8.9199e-07,\n",
       "             1.3357e-05,  1.1811e-05],\n",
       "           [ 1.9804e-05, -9.3256e-06,  4.4463e-06,  ..., -6.2325e-05,\n",
       "             1.0487e-05, -4.2896e-05],\n",
       "           [-2.0718e-04, -7.4462e-05,  2.3137e-04,  ..., -7.1264e-05,\n",
       "             1.1569e-04, -4.7052e-06],\n",
       "           ...,\n",
       "           [ 1.8259e-05, -1.4776e-05,  5.0114e-05,  ...,  2.1705e-04,\n",
       "             7.2566e-08, -9.2798e-06],\n",
       "           [ 1.5216e-05,  3.0671e-05,  1.3605e-05,  ..., -3.8677e-05,\n",
       "             8.4805e-05,  5.3366e-05],\n",
       "           [-1.0772e-05,  5.9073e-08,  2.5167e-06,  ...,  1.9910e-05,\n",
       "            -1.9152e-05, -2.9429e-06]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[ 3.5767e-05, -7.1298e-05,  2.1372e-05,  ...,  5.5441e-06,\n",
       "            -1.3589e-06,  4.7859e-05],\n",
       "           [ 3.4556e-05, -2.4373e-04, -4.5272e-05,  ..., -1.7044e-05,\n",
       "             1.8560e-05, -5.2396e-06],\n",
       "           [ 2.4576e-05, -2.7349e-04, -4.4830e-05,  ...,  5.4168e-06,\n",
       "            -9.8905e-04,  1.6443e-04],\n",
       "           ...,\n",
       "           [ 1.3463e-04, -8.5718e-05,  1.2076e-04,  ..., -1.5024e-05,\n",
       "            -9.1866e-07, -1.0286e-05],\n",
       "           [-1.1295e-05,  1.0691e-05,  2.1141e-06,  ...,  7.3183e-06,\n",
       "             3.5547e-05, -2.4254e-06],\n",
       "           [-2.9008e-05, -1.2287e-05,  9.4206e-06,  ..., -3.6426e-05,\n",
       "             9.3236e-07, -8.8764e-07]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[-3.3556e-04,  1.4117e-04, -2.6200e-04,  ...,  2.1575e-07,\n",
       "            -5.6988e-05, -3.8241e-04],\n",
       "           [ 2.9716e-04,  8.7813e-04,  4.7740e-04,  ...,  1.1028e-04,\n",
       "            -1.2086e-03, -5.1830e-04],\n",
       "           [-7.6285e-05,  1.2557e-04, -2.2036e-04,  ..., -1.2267e-04,\n",
       "             2.7517e-06,  1.0742e-04],\n",
       "           ...,\n",
       "           [ 9.4403e-05, -1.8119e-04, -3.7148e-05,  ...,  4.4315e-04,\n",
       "             6.8592e-04, -2.2032e-04],\n",
       "           [-2.4955e-06,  4.0255e-04,  1.7666e-05,  ..., -1.7061e-07,\n",
       "             4.2228e-05,  9.1364e-05],\n",
       "           [-3.6070e-05,  1.8586e-05, -4.0444e-05,  ..., -1.9719e-04,\n",
       "            -7.1065e-07, -6.7198e-05]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[ 2.9054e-04,  6.8970e-04, -9.0626e-04,  ...,  3.5886e-06,\n",
       "            -6.5589e-05, -1.8258e-04],\n",
       "           [-5.1970e-06,  3.2733e-04,  4.0018e-04,  ..., -5.5709e-05,\n",
       "            -5.2880e-04, -4.5984e-04],\n",
       "           [ 4.2613e-04,  2.9413e-04,  1.3403e-04,  ...,  1.1812e-04,\n",
       "             3.2215e-04,  9.3756e-05],\n",
       "           ...,\n",
       "           [ 9.4079e-04, -8.8920e-04,  4.4736e-04,  ...,  1.3508e-03,\n",
       "             7.3814e-04, -1.5864e-03],\n",
       "           [ 6.5411e-04, -7.0287e-05,  4.6522e-04,  ...,  1.6832e-05,\n",
       "             3.6457e-04,  1.3212e-03],\n",
       "           [ 7.9197e-05, -2.2989e-04,  1.9549e-04,  ..., -1.1493e-03,\n",
       "             1.1002e-04, -9.3252e-05]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[-5.1981e-04,  7.8103e-04, -8.5597e-04,  ..., -4.5114e-06,\n",
       "             4.0858e-05, -7.0963e-05],\n",
       "           [ 2.8499e-04,  6.6031e-04,  1.7640e-05,  ..., -3.5931e-04,\n",
       "             1.7184e-04,  1.2542e-04],\n",
       "           [-2.3722e-03, -2.9965e-05, -4.7735e-05,  ...,  8.5633e-04,\n",
       "             1.2139e-03,  2.1889e-04],\n",
       "           ...,\n",
       "           [ 3.1601e-03,  1.9584e-05, -2.5399e-04,  ..., -6.4595e-05,\n",
       "             5.2379e-04,  9.1112e-05],\n",
       "           [-4.9606e-04, -1.6743e-04,  4.7833e-04,  ...,  1.0296e-03,\n",
       "             8.4106e-04,  8.1118e-04],\n",
       "           [ 6.6595e-04, -9.7245e-05, -4.3043e-04,  ...,  1.0047e-03,\n",
       "             9.6755e-04, -3.9737e-04]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[-8.8361e-05, -1.1244e-05,  1.5065e-04,  ..., -8.2372e-06,\n",
       "             2.6470e-05, -3.4520e-05],\n",
       "           [ 1.0871e-03, -1.2791e-04,  2.1743e-04,  ...,  8.9562e-05,\n",
       "            -5.6599e-05, -6.8872e-04],\n",
       "           [ 1.8081e-04, -8.2855e-05,  7.2792e-05,  ...,  2.2124e-05,\n",
       "            -3.6405e-06, -9.9405e-04],\n",
       "           ...,\n",
       "           [ 1.2454e-06,  1.6257e-05,  9.2511e-05,  ...,  6.9302e-06,\n",
       "             3.6857e-04, -1.1952e-05],\n",
       "           [-7.5812e-06,  1.0915e-04, -2.7970e-05,  ..., -5.9900e-06,\n",
       "            -1.5355e-05,  4.6659e-06],\n",
       "           [-1.2273e-05,  4.3281e-06, -1.0678e-04,  ...,  1.6113e-04,\n",
       "            -6.0345e-06, -7.4565e-06]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[ 1.6757e-04,  2.1411e-04, -4.7520e-04,  ...,  1.3203e-06,\n",
       "            -9.5080e-07, -2.8824e-04],\n",
       "           [-1.3986e-04, -4.4877e-04, -1.1942e-04,  ..., -4.7750e-05,\n",
       "            -5.3677e-05,  1.8457e-05],\n",
       "           [-1.0410e-04,  1.2449e-06,  1.0228e-05,  ...,  4.8347e-05,\n",
       "             3.7885e-05, -1.4637e-04],\n",
       "           ...,\n",
       "           [-6.8509e-05,  7.3169e-05,  7.3842e-05,  ..., -1.0060e-04,\n",
       "             6.1913e-04, -1.2775e-04],\n",
       "           [-7.3554e-05, -5.4280e-05, -9.3567e-05,  ...,  6.7114e-08,\n",
       "             7.4182e-05, -5.4414e-05],\n",
       "           [ 1.9428e-04,  5.7221e-05, -3.9992e-05,  ..., -6.1452e-05,\n",
       "             4.1228e-06, -2.3563e-05]]], device='cuda:0', grad_fn=<MulBackward0>)],\n",
       " 'conti_attr_list': [tensor([-2.4683e-03, -3.1340e-02, -2.3063e-02,  8.5846e-02, -1.3606e-01,\n",
       "          -5.6050e-02,  1.7835e-02, -1.2950e-01, -2.3075e-02,  2.8824e-02,\n",
       "           7.9517e-02, -2.4911e-01,  1.3514e-01,  2.0214e-01, -8.6794e-02,\n",
       "          -6.6704e-02, -4.3959e-02, -7.5047e-03, -1.7923e-01, -5.6481e-05,\n",
       "          -8.5562e-02,  1.7122e-01,  4.3536e-02, -2.9848e-01,  9.6469e-02,\n",
       "          -8.5471e-03, -6.3962e-02,  2.2039e-02, -1.4393e-01,  3.8258e-02,\n",
       "          -2.7458e-02,  4.7850e-02,  4.7579e-02,  6.4932e-03, -1.4074e-01,\n",
       "           3.7176e-02,  1.5523e-01,  1.5875e-02, -5.0587e-02,  4.2823e-02,\n",
       "           1.5195e-01,  1.2051e-01,  1.1640e-01,  4.2975e-02,  7.2501e-03,\n",
       "           8.9933e-02,  5.1321e-02,  3.9967e-02,  1.8308e-01,  7.9316e-02,\n",
       "           1.2671e-01, -5.2389e-01]),\n",
       "  tensor([-0.1706, -0.2738,  0.1249,  0.0618,  0.0514, -0.5345, -0.0057,  0.0450,\n",
       "           0.2284,  0.0107, -0.0972, -0.0303, -0.0478,  0.0146,  0.0253, -0.0234,\n",
       "           0.0111,  0.0390,  0.0717, -0.0270,  0.0283, -0.0597,  0.0109,  0.0459,\n",
       "          -0.0352,  0.0408, -0.0292,  0.0304, -0.0144,  0.1062, -0.0324, -0.0050,\n",
       "           0.0406, -0.0139,  0.0369,  0.0039, -0.0341,  0.0040, -0.0275, -0.0282,\n",
       "           0.0663,  0.0431, -0.0451,  0.0135, -0.0047,  0.0047,  0.0356, -0.0195,\n",
       "          -0.0116, -0.0307,  0.0231, -0.0246,  0.1120,  0.0118,  0.0682,  0.0495,\n",
       "           0.0543,  0.0288, -0.0157,  0.0299, -0.0153,  0.0036, -0.0721,  0.0408,\n",
       "           0.0366, -0.0094,  0.0653,  0.0283, -0.1519]),\n",
       "  tensor([-0.2020, -0.2829,  0.0656, -0.1091,  0.0100, -0.1244, -0.0514,  0.1761,\n",
       "           0.0338, -0.1339,  0.0546, -0.0461, -0.0038, -0.0270,  0.2178,  0.4261,\n",
       "          -0.1660, -0.0360,  0.2790,  0.0203, -0.0676, -0.0232,  0.1329,  0.0023,\n",
       "           0.0173, -0.0405,  0.0845, -0.0151,  0.1170, -0.0334, -0.0406, -0.0190,\n",
       "          -0.0215, -0.0108,  0.0083,  0.0238,  0.0175,  0.0066,  0.0165,  0.2138,\n",
       "          -0.0781,  0.2325, -0.0060, -0.0011,  0.1609, -0.0341]),\n",
       "  tensor([-1.9108e-01, -1.7691e-01,  8.3361e-02,  4.7193e-02, -7.7874e-02,\n",
       "          -2.2740e-01,  6.2765e-02,  1.6235e-01,  2.0815e-02, -1.2046e-01,\n",
       "          -6.3765e-02, -1.3366e-01, -4.5890e-01,  5.2475e-01,  7.2280e-02,\n",
       "           5.2501e-03, -1.3569e-01,  7.3141e-03, -1.1589e-02,  1.1378e-02,\n",
       "           3.4431e-02,  4.6928e-02,  3.9236e-02,  8.7281e-02,  1.7245e-04,\n",
       "           5.6957e-02,  1.5352e-01,  8.5024e-03,  6.9581e-02, -2.0457e-01,\n",
       "           1.3358e-02, -2.1178e-02,  2.4663e-02, -1.6678e-01,  6.0795e-02,\n",
       "           2.5372e-01, -6.2432e-02,  3.3829e-02,  5.0872e-02, -1.1545e-02,\n",
       "           1.7290e-02, -1.8756e-02,  4.9894e-02, -8.8414e-02]),\n",
       "  tensor([ 0.0126, -0.3132, -0.0695, -0.0810,  0.0227, -0.0198,  0.0934,  0.0447,\n",
       "           0.2868,  0.1358, -0.0951,  0.2214,  0.2305,  0.0199,  0.1554,  0.0117,\n",
       "           0.0164, -0.1320,  0.0468,  0.1543, -0.2606, -0.3230,  0.1233, -0.1689,\n",
       "          -0.2971,  0.0040,  0.0560,  0.0109,  0.0253,  0.0285,  0.1939,  0.2393,\n",
       "          -0.0639,  0.0497,  0.0972]),\n",
       "  tensor([-2.5832e-01, -1.5068e-01,  1.1032e-01,  1.3527e-01,  2.4947e-02,\n",
       "           9.5896e-03,  2.0076e-02, -8.6494e-02,  1.6788e-01, -1.6568e-02,\n",
       "           1.9814e-02,  5.3567e-02, -2.4550e-01,  1.9672e-01,  5.6277e-02,\n",
       "          -2.1089e-02,  3.8273e-02, -5.5775e-02,  7.4081e-02,  1.6816e-04,\n",
       "          -4.5149e-02,  6.5820e-02, -4.2931e-02,  1.1991e-01,  1.9004e-01,\n",
       "           9.6079e-02, -3.7457e-02,  9.2541e-03,  1.4128e-02, -8.5200e-02,\n",
       "           2.4155e-02,  9.2141e-02,  5.9571e-03, -2.6466e-02, -4.2269e-02,\n",
       "           1.0241e-02,  1.0915e-03,  2.6983e-02,  2.4373e-01, -4.5965e-02,\n",
       "          -8.1717e-02, -5.7566e-02,  2.8113e-01, -2.5344e-01]),\n",
       "  tensor([-0.2071, -0.1002,  0.0036,  0.0449, -0.1208,  0.1000,  0.1032, -0.4616,\n",
       "          -0.4102,  0.0451,  0.0368,  0.1644, -0.0117, -0.1638,  0.0111, -0.0035,\n",
       "           0.1680,  0.0937,  0.2332, -0.0813, -0.1377,  0.0395,  0.0169, -0.0027,\n",
       "           0.0242,  0.0477,  0.4380]),\n",
       "  tensor([-0.1014,  0.0435,  0.0941, -0.2531, -0.0376,  0.1163,  0.0994, -0.0107,\n",
       "          -0.1060, -0.2074,  0.0266,  0.1678,  0.4352, -0.4707, -0.2275,  0.0232,\n",
       "          -0.0858,  0.0396,  0.1636,  0.1626,  0.1267]),\n",
       "  tensor([ 0.0313, -0.1337,  0.0106,  0.1186, -0.0821, -0.0325,  0.0649,  0.1145,\n",
       "          -0.0307, -0.0508, -0.3202, -0.0553, -0.1918,  0.1969, -0.0288, -0.1914,\n",
       "           0.1802,  0.1891,  0.0307,  0.0585,  0.0936,  0.2202,  0.2019,  0.1645,\n",
       "           0.0914, -0.2133,  0.0983, -0.2174]),\n",
       "  tensor([-0.0617, -0.1926, -0.0285,  0.0939, -0.0175, -0.2734, -0.2656,  0.2991,\n",
       "           0.3894, -0.1564, -0.2127,  0.0882,  0.1633, -0.0122,  0.0925, -0.1932,\n",
       "           0.2046,  0.1697,  0.2116,  0.0389,  0.0160,  0.2719, -0.1148,  0.0347,\n",
       "           0.1544, -0.1490]),\n",
       "  tensor([-2.5755e-02,  3.2622e-01, -3.8716e-02,  6.3340e-02, -2.5531e-01,\n",
       "           4.3367e-02,  7.6064e-02,  1.2304e-01,  5.2284e-02, -1.8713e-01,\n",
       "          -7.8955e-02, -1.3848e-01, -2.3202e-01, -3.8529e-01,  1.9792e-02,\n",
       "          -1.1228e-01, -1.5378e-01, -1.0520e-01,  3.5301e-04,  2.4123e-02,\n",
       "           2.8695e-02,  3.8878e-02,  1.5767e-02, -4.4685e-02, -3.7915e-02,\n",
       "           1.2672e-01,  9.8564e-02, -5.8684e-02,  5.1315e-03,  3.7934e-02,\n",
       "          -7.3597e-03,  8.2763e-02,  1.3563e-01,  1.1014e-01,  9.8901e-02,\n",
       "           1.6225e-01,  8.5160e-03,  1.9723e-03,  1.7913e-01,  6.2831e-02,\n",
       "           2.0605e-02,  1.2325e-02, -5.9660e-02,  3.4215e-02,  3.3041e-03,\n",
       "           1.8205e-02,  1.5090e-02,  4.3685e-02, -3.2399e-01]),\n",
       "  tensor([ 0.0387, -0.0802,  0.1854, -0.3586,  0.0312,  0.0567, -0.0168, -0.0379,\n",
       "           0.0798,  0.0102,  0.0012, -0.0033, -0.0075,  0.0073, -0.0523,  0.0696,\n",
       "           0.0283, -0.0014, -0.0024,  0.0243,  0.0388, -0.0722,  0.0255, -0.0099,\n",
       "           0.0357, -0.0090, -0.0472, -0.0357,  0.0069,  0.0289, -0.0322,  0.0316,\n",
       "           0.0356,  0.0205, -0.1500,  0.5311,  0.1437, -0.1683, -0.1064,  0.1052,\n",
       "           0.2142, -0.0329, -0.1222,  0.0097, -0.0165, -0.0075,  0.0798, -0.0116,\n",
       "           0.1215, -0.0302,  0.0686, -0.0356,  0.0691, -0.0410,  0.0644,  0.0522,\n",
       "          -0.0334, -0.0382,  0.0308, -0.0277,  0.0067, -0.0024,  0.1413, -0.0113,\n",
       "           0.0407,  0.0093, -0.2208]),\n",
       "  tensor([-0.2896, -0.0136,  0.0047, -0.0195, -0.0300, -0.0880, -0.0900,  0.3402,\n",
       "          -0.2099, -0.2277, -0.1847,  0.2592,  0.0443,  0.0569, -0.0398, -0.0032,\n",
       "           0.0763, -0.0276, -0.0689,  0.0671, -0.0261, -0.0312,  0.0406, -0.1040,\n",
       "           0.0886, -0.0805,  0.0564,  0.0134, -0.1873, -0.1271,  0.0862,  0.0440,\n",
       "           0.1611, -0.1018,  0.1091, -0.0083, -0.0499,  0.0260, -0.0218, -0.0646,\n",
       "          -0.0186, -0.0531,  0.0521, -0.0797,  0.1083]),\n",
       "  tensor([-0.4044,  0.0530, -0.0280,  0.0735,  0.0136,  0.0656, -0.0911, -0.0109,\n",
       "           0.1219, -0.0829, -0.0927,  0.3016,  0.2014, -0.0226,  0.0105, -0.0641,\n",
       "          -0.0257,  0.0259, -0.0086, -0.1475, -0.0009, -0.0699, -0.0606, -0.0240,\n",
       "           0.0520, -0.0417, -0.0807,  0.0146,  0.1715, -0.0711,  0.0077,  0.0384,\n",
       "          -0.0467, -0.0239,  0.0754,  0.0295,  0.2510, -0.2129]),\n",
       "  tensor([ 4.0482e-02,  2.4496e-02, -1.2520e-01, -2.0385e-02,  3.1552e-02,\n",
       "          -2.2738e-02, -6.1131e-02,  3.1683e-02, -9.3330e-02, -1.2109e-02,\n",
       "           6.5192e-02, -4.2892e-01, -4.2839e-01, -1.3092e-01,  1.2054e-01,\n",
       "          -1.0664e-01, -1.7005e-01,  4.2882e-02,  1.1409e-01,  1.3522e-01,\n",
       "          -1.5796e-02, -1.2409e-01,  1.1029e-01, -1.1853e-01,  1.7805e-01,\n",
       "          -2.8064e-02,  2.6949e-03, -1.1208e-01,  2.7810e-02,  8.1568e-02,\n",
       "           5.0874e-02, -5.3832e-02,  4.1611e-04,  7.6822e-03,  5.5728e-02,\n",
       "          -1.6403e-02,  1.7754e-02,  1.0852e-01, -9.1003e-02,  2.3774e-02,\n",
       "           2.4367e-02,  1.8284e-02,  5.8879e-02,  4.2280e-03,  1.8749e-02,\n",
       "           2.4283e-02, -1.0458e-02, -4.2612e-03,  2.7068e-02,  2.4495e-02,\n",
       "          -1.9339e-04,  4.8774e-04,  5.5823e-02, -1.7715e-01]),\n",
       "  tensor([ 0.0299, -0.3328,  0.0691,  0.1034, -0.0108,  0.1668,  0.1352, -0.0191,\n",
       "          -0.0573, -0.0119,  0.0373,  0.1477, -0.1479,  0.0715, -0.2198, -0.2093,\n",
       "          -0.1708,  0.0250,  0.1780, -0.2169, -0.0254, -0.0028, -0.1823,  0.0068,\n",
       "           0.0744,  0.0262,  0.0278, -0.0981,  0.0992,  0.0344,  0.1261, -0.0789,\n",
       "           0.0645,  0.0433, -0.1195, -0.1217,  0.0127, -0.2425, -0.0210,  0.1309,\n",
       "           0.0375,  0.0797, -0.0055,  0.0838,  0.0162,  0.1696, -0.0509, -0.0086,\n",
       "          -0.0454,  0.0919, -0.3739]),\n",
       "  tensor([ 0.1948, -0.0802, -0.0798, -0.0995,  0.1926, -0.1284, -0.1382, -0.1024,\n",
       "           0.0878, -0.2075,  0.1836, -0.0872, -0.0822, -0.0127,  0.0279, -0.1481,\n",
       "          -0.0233, -0.1369, -0.1757, -0.0284,  0.0105,  0.1027,  0.0907, -0.1585,\n",
       "          -0.2203,  0.0550,  0.1089,  0.0961, -0.1122,  0.1731, -0.0158, -0.1724,\n",
       "          -0.1012,  0.0373, -0.1535,  0.3300, -0.1040]),\n",
       "  tensor([-0.1972,  0.0052,  0.0505, -0.4023, -0.0634,  0.0040,  0.0420,  0.0212,\n",
       "           0.1325, -0.1286, -0.0498, -0.1119,  0.2079, -0.0455, -0.0162,  0.3851,\n",
       "           0.0009,  0.0358,  0.0839,  0.0105,  0.0935, -0.0339,  0.0276,  0.0029,\n",
       "           0.0728,  0.0565, -0.1963,  0.0521, -0.0300,  0.1409, -0.0049, -0.0803,\n",
       "           0.0219,  0.0268,  0.0268, -0.0439,  0.0050,  0.0600, -0.0004, -0.1389,\n",
       "          -0.0361,  0.0481,  0.0659, -0.0522,  0.0751,  0.1129, -0.1256,  0.1191]),\n",
       "  tensor([ 0.0023, -0.0891, -0.1578, -0.0598, -0.0550,  0.1400,  0.1896,  0.3732,\n",
       "          -0.1848, -0.1619, -0.0931,  0.0951, -0.1275,  0.0751, -0.0301, -0.0802,\n",
       "          -0.1649,  0.0582, -0.0062, -0.1051, -0.1651,  0.1379,  0.1634,  0.2528,\n",
       "          -0.0143, -0.0389, -0.0521,  0.0581,  0.0325, -0.0813, -0.1101, -0.0603,\n",
       "          -0.0441,  0.2446,  0.0542,  0.1566,  0.1413,  0.1480,  0.1929]),\n",
       "  tensor([-0.3732,  0.0348,  0.2304, -0.0427, -0.0352,  0.3873, -0.1130, -0.1973,\n",
       "           0.0147,  0.1074, -0.0868,  0.1549,  0.0320, -0.1259, -0.0852,  0.0977,\n",
       "          -0.0554,  0.0268,  0.1009, -0.0431,  0.0305, -0.0042,  0.0288,  0.0540,\n",
       "           0.1060, -0.0104,  0.0040, -0.0263, -0.0219,  0.0026, -0.1039,  0.0282,\n",
       "           0.0432, -0.0882, -0.1067,  0.0396,  0.0975, -0.0373,  0.1815,  0.3063,\n",
       "           0.0787,  0.0138,  0.0273,  0.0928,  0.2068, -0.0590, -0.0582, -0.0045,\n",
       "           0.0385, -0.0239, -0.2329]),\n",
       "  tensor([ 0.0447, -0.2248,  0.0582,  0.1224, -0.0121,  0.0551, -0.0451, -0.0017,\n",
       "           0.0542,  0.0239,  0.0914, -0.0760,  0.0250,  0.1194, -0.0013,  0.0950,\n",
       "           0.0342, -0.1335,  0.3107, -0.0622, -0.0797, -0.0538,  0.0632,  0.2116,\n",
       "           0.0442,  0.1339,  0.0206, -0.0574,  0.0929, -0.0355,  0.0889, -0.0533,\n",
       "          -0.0176, -0.0221,  0.0103,  0.0278,  0.0274,  0.0904,  0.0727, -0.1666]),\n",
       "  tensor([ 0.1286,  0.0367,  0.0289, -0.0312, -0.0955, -0.0777, -0.1689,  0.3612,\n",
       "           0.1399, -0.1406, -0.3089, -0.0610, -0.0266, -0.0561, -0.0179,  0.1014,\n",
       "          -0.0389,  0.2052,  0.3916,  0.0007, -0.0260, -0.1369, -0.0726, -0.0317,\n",
       "           0.1366, -0.1400,  0.2232, -0.0281, -0.0989,  0.0912, -0.0646, -0.0637,\n",
       "          -0.3397]),\n",
       "  tensor([ 0.0704, -0.0772, -0.1814,  0.0044, -0.0885,  0.2175,  0.1309,  0.3099,\n",
       "           0.1083, -0.3491, -0.3816, -0.0964, -0.0461, -0.0208,  0.0297,  0.0458,\n",
       "           0.1157, -0.0715, -0.0147, -0.0808,  0.0243, -0.1579, -0.0635, -0.0285,\n",
       "           0.2211, -0.0026,  0.0639, -0.1394,  0.0816,  0.0197,  0.0702,  0.0353,\n",
       "           0.0699,  0.0266,  0.0172, -0.1357, -0.2035,  0.1362,  0.0347,  0.2138,\n",
       "           0.1361]),\n",
       "  tensor([-2.4679e-01,  3.0539e-02, -7.6253e-04,  8.7770e-02, -3.9642e-02,\n",
       "          -1.5022e-03,  7.1946e-02, -8.0410e-02,  1.0548e-01,  2.4530e-01,\n",
       "           9.6338e-02,  4.8007e-02, -6.1826e-01,  3.8865e-02,  5.1297e-02,\n",
       "          -3.9808e-02,  1.9296e-01, -7.8887e-02, -1.9337e-02,  1.4976e-01,\n",
       "          -2.9602e-02,  5.5690e-02, -3.9709e-02, -2.3146e-02,  3.3205e-02,\n",
       "           1.2785e-01,  2.5333e-03,  1.2079e-03, -1.8718e-02,  9.2810e-02,\n",
       "           8.1311e-02,  6.6002e-02,  8.9550e-03, -5.9939e-02,  1.7593e-01,\n",
       "           1.8209e-06]),\n",
       "  tensor([-1.4564e-01,  3.0722e-02, -2.4900e-02,  4.7872e-02, -5.7249e-03,\n",
       "           1.4348e-01,  3.3142e-02,  8.5666e-03,  1.0608e-02, -4.7759e-03,\n",
       "           4.7360e-05, -1.4331e-01, -4.4730e-01, -2.3973e-01,  1.3905e-01,\n",
       "           3.0961e-02, -6.8741e-03,  5.1501e-02, -4.6229e-02,  1.4316e-01,\n",
       "           3.0205e-02, -1.5341e-02,  4.9237e-02, -9.9976e-02,  1.0068e-01,\n",
       "          -5.8617e-02,  2.2561e-02,  9.8211e-02, -8.7377e-02, -7.3516e-03,\n",
       "          -8.0336e-02,  1.3831e-01,  3.8794e-02, -5.4148e-04,  9.1417e-02,\n",
       "          -3.6207e-01, -9.4159e-03,  4.2486e-02, -8.7413e-03,  3.8982e-02,\n",
       "           2.3417e-01, -5.7121e-02,  3.2625e-02, -1.3388e-02,  1.0608e-01,\n",
       "           1.6356e-01,  1.7544e-02,  7.5147e-02]),\n",
       "  tensor([-0.1429, -0.1179,  0.0050,  0.3993,  0.0308, -0.0607,  0.0352,  0.1857,\n",
       "          -0.1090,  0.0548,  0.0180, -0.0031, -0.0023, -0.0876, -0.0645,  0.0562,\n",
       "          -0.1431,  0.1176,  0.2090,  0.0055, -0.2195, -0.0151,  0.0059,  0.0007,\n",
       "           0.0285,  0.0244,  0.1004, -0.1489,  0.0236, -0.0762, -0.1399,  0.0665,\n",
       "          -0.1827, -0.0271, -0.0204, -0.0614,  0.0636, -0.0104,  0.1145,  0.2135,\n",
       "          -0.3556]),\n",
       "  tensor([-0.0515,  0.2624,  0.0360,  0.4559,  0.1164, -0.0040, -0.0226, -0.0231,\n",
       "          -0.1958, -0.2457, -0.0024,  0.1546,  0.0290, -0.0286,  0.1462, -0.0950,\n",
       "          -0.0032,  0.0161,  0.1114,  0.0296,  0.0097, -0.0179, -0.0493,  0.1409,\n",
       "           0.0247,  0.0239, -0.0123, -0.0866, -0.0540,  0.0384,  0.0825,  0.0079,\n",
       "          -0.0505,  0.0243,  0.2850,  0.0720,  0.0187,  0.2537,  0.0526,  0.0093,\n",
       "           0.0330, -0.0662,  0.3096,  0.0093, -0.0997, -0.0579, -0.0024]),\n",
       "  tensor([ 0.0744,  0.0650,  0.0835,  0.0096,  0.0193, -0.1900,  0.0896,  0.2474,\n",
       "           0.2669, -0.3222, -0.2034, -0.0752, -0.1325,  0.6041, -0.1215, -0.0504,\n",
       "          -0.0660, -0.1489,  0.0529,  0.1132, -0.0419,  0.0646, -0.0329, -0.0129,\n",
       "           0.0703,  0.0371, -0.0115,  0.1166,  0.0502, -0.0416,  0.0094,  0.0202,\n",
       "           0.1705]),\n",
       "  tensor([ 0.3175, -0.1711, -0.0305, -0.0865,  0.0028, -0.0181, -0.0656,  0.0537,\n",
       "          -0.0153, -0.0781,  0.1700, -0.1341, -0.1746,  0.0501, -0.0131, -0.1329,\n",
       "          -0.3224,  0.0180,  0.1586, -0.0553,  0.0170,  0.1311,  0.0745,  0.0025,\n",
       "          -0.0300, -0.0335, -0.0051,  0.0646,  0.0806, -0.0345,  0.1329, -0.1218,\n",
       "           0.0398, -0.2245,  0.1631, -0.3007, -0.0467, -0.0900,  0.0611, -0.0854,\n",
       "          -0.1520,  0.0324, -0.0558,  0.0735, -0.0127, -0.2163, -0.0579, -0.0629,\n",
       "          -0.3061]),\n",
       "  tensor([ 0.2357, -0.0856,  0.1613,  0.0221,  0.1189, -0.2768,  0.0202,  0.1749,\n",
       "           0.0873,  0.1590, -0.1200,  0.0907, -0.2359,  0.0728,  0.1113,  0.2282,\n",
       "          -0.0781,  0.0972, -0.1135, -0.0089, -0.1188, -0.0090,  0.2151,  0.0801,\n",
       "          -0.0151,  0.1260, -0.1436,  0.1963, -0.0616, -0.1292, -0.0091, -0.0094,\n",
       "          -0.1964,  0.0557, -0.0685,  0.0800,  0.0826,  0.0826]),\n",
       "  tensor([-0.2017,  0.0393, -0.1332, -0.0104,  0.0294, -0.0394, -0.0785, -0.0418,\n",
       "          -0.1237,  0.0605,  0.0762,  0.5360, -0.4220, -0.2415,  0.0874,  0.0435,\n",
       "          -0.0954, -0.0807,  0.1345,  0.2051,  0.0151, -0.1805,  0.1200,  0.0464,\n",
       "          -0.0216,  0.1088]),\n",
       "  tensor([ 0.2367, -0.1620,  0.0035,  0.0259,  0.0378, -0.0033, -0.2418,  0.0494,\n",
       "          -0.0975,  0.0578, -0.1904, -0.0983,  0.1489, -0.0896, -0.0128, -0.1970,\n",
       "           0.0025,  0.0020, -0.1707, -0.0571, -0.0373,  0.0209,  0.0642,  0.0409,\n",
       "           0.1186,  0.0907,  0.0252,  0.0064, -0.0442, -0.0143, -0.0093, -0.0576,\n",
       "          -0.0516,  0.0292, -0.0622, -0.0212,  0.0301, -0.0182, -0.0143,  0.0065,\n",
       "           0.3005,  0.0717,  0.0826, -0.0050,  0.0276]),\n",
       "  tensor([ 0.1482,  0.0488,  0.0354, -0.1185, -0.0493, -0.0528,  0.0010,  0.0012,\n",
       "           0.0112, -0.0170, -0.0123,  0.0311, -0.3009, -0.2616, -0.0254,  0.0289,\n",
       "          -0.1308, -0.0478,  0.0408,  0.0696, -0.0534, -0.0264,  0.0044,  0.0004,\n",
       "           0.0108,  0.0293, -0.0388,  0.0108,  0.0058,  0.0822, -0.0691,  0.0529,\n",
       "          -0.0175,  0.0450,  0.0137,  0.0172, -0.0229,  0.0186, -0.0107, -0.1228,\n",
       "           0.0366,  0.0266, -0.0541, -0.0966, -0.1007,  0.1406, -0.2600,  0.2206,\n",
       "           0.2528, -0.1168,  0.0779,  0.0376,  0.0862,  0.0553, -0.0438,  0.0538,\n",
       "           0.0146,  0.0780,  0.0107,  0.0080, -0.0812, -0.0141,  0.0071,  0.0051,\n",
       "           0.0059, -0.0284,  0.0503,  0.0037,  0.2641, -0.0749,  0.0701, -0.0642,\n",
       "           0.0317, -0.0106,  0.0495, -0.1249,  0.0344,  0.0926, -0.1170, -0.0386]),\n",
       "  tensor([ 0.3058, -0.0731, -0.0087,  0.0939, -0.0377,  0.0396, -0.1091, -0.1941,\n",
       "          -0.0475, -0.1220,  0.1548,  0.1257, -0.0355,  0.0900, -0.1434, -0.4570,\n",
       "           0.3473, -0.1111, -0.0424,  0.1035,  0.0140, -0.2954,  0.1938,  0.2364,\n",
       "           0.0305, -0.0520, -0.0717, -0.1991, -0.0410, -0.2263, -0.0748,  0.1271,\n",
       "           0.0139,  0.0837,  0.1037]),\n",
       "  tensor([ 0.0678, -0.0111, -0.1101,  0.1280, -0.0680, -0.0261, -0.1062, -0.1056,\n",
       "          -0.0216,  0.0132,  0.1129,  0.0426,  0.0291, -0.1225,  0.0244, -0.0659,\n",
       "          -0.0293, -0.0906, -0.1454, -0.0252,  0.0155,  0.1403,  0.0654, -0.0554,\n",
       "          -0.1770, -0.0327,  0.0186,  0.0054,  0.0082,  0.0394, -0.0996, -0.0258,\n",
       "           0.0458, -0.0427, -0.0164, -0.0549, -0.0855, -0.1220, -0.0083,  0.0402,\n",
       "          -0.0607,  0.0589, -0.0451, -0.1536,  0.0603, -0.0310, -0.0326,  0.0551,\n",
       "          -0.0079,  0.0464, -0.0235,  0.0081,  0.0561,  0.0630,  0.0825, -0.0718,\n",
       "           0.0636, -0.4186,  0.0501,  0.3751,  0.0368, -0.1474,  0.0194,  0.0551,\n",
       "           0.0757,  0.1217, -0.1330,  0.3388,  0.0014, -0.0323]),\n",
       "  tensor([ 0.0604,  0.0489, -0.2172, -0.1365, -0.3883, -0.0989,  0.2456, -0.1741,\n",
       "          -0.2298,  0.1061,  0.0955,  0.0769,  0.0226, -0.0113,  0.0154, -0.1417,\n",
       "           0.0835, -0.2817,  0.0648,  0.0466, -0.0116,  0.1072,  0.2018,  0.0760,\n",
       "           0.1411,  0.1207,  0.0692, -0.1314,  0.1258,  0.1130, -0.0618, -0.1652]),\n",
       "  tensor([ 0.0878,  0.0848, -0.1026,  0.0207, -0.0632, -0.0038, -0.0589, -0.1917,\n",
       "          -0.0254, -0.1337, -0.0420, -0.0393, -0.1415,  0.0140,  0.0708, -0.0527,\n",
       "           0.0900, -0.1818, -0.2664,  0.0839,  0.1563, -0.1751,  0.1317,  0.1734,\n",
       "           0.2307,  0.0798,  0.0447, -0.0039, -0.0071, -0.0639,  0.1507,  0.0763,\n",
       "           0.0940,  0.0949,  0.0628, -0.0387,  0.0854,  0.0147, -0.0543, -0.0725,\n",
       "          -0.1813, -0.1455, -0.0239]),\n",
       "  tensor([ 2.0476e-01,  1.0954e-02, -1.2488e-02, -6.4944e-02,  5.4619e-02,\n",
       "          -4.7149e-02, -1.8565e-03, -9.2744e-03, -4.1930e-02,  5.8074e-02,\n",
       "          -8.6415e-02, -1.0395e-03,  1.0458e-01, -1.5156e-01, -7.2392e-01,\n",
       "           8.7740e-02,  2.1759e-01,  3.3761e-01,  5.1764e-02, -1.5253e-01,\n",
       "           2.0756e-02, -1.1131e-01, -4.6366e-02,  1.9433e-02,  2.5053e-02,\n",
       "           3.8635e-02, -2.4628e-04,  2.5409e-02, -1.1859e-02, -6.0165e-02,\n",
       "          -4.5610e-02,  2.8359e-02,  6.3386e-02,  8.8071e-02,  1.7015e-01]),\n",
       "  tensor([-0.0831,  0.1107,  0.1672,  0.3297, -0.1759, -0.0547,  0.0629,  0.0677,\n",
       "          -0.0387, -0.0748, -0.0452,  0.1237,  0.1429, -0.2058, -0.4453, -0.0161,\n",
       "          -0.0121,  0.2670,  0.1759, -0.2846,  0.0086,  0.0202,  0.2418,  0.0950,\n",
       "           0.0489,  0.1455, -0.1219]),\n",
       "  tensor([ 0.0550,  0.3968, -0.3173,  0.0047,  0.0374, -0.0361, -0.0187,  0.2652,\n",
       "           0.3287, -0.1167,  0.0670, -0.1791,  0.0122,  0.0701, -0.1218, -0.0039,\n",
       "           0.0691, -0.1188,  0.0195,  0.0401,  0.0366, -0.0752,  0.0757,  0.0077,\n",
       "          -0.0973, -0.0340,  0.1248, -0.0641,  0.0961,  0.0147,  0.0655, -0.2629,\n",
       "          -0.1229,  0.0074,  0.0416,  0.0512, -0.1229, -0.1562,  0.0515,  0.0587,\n",
       "          -0.1585, -0.0169, -0.0146,  0.0096,  0.0495,  0.0603, -0.1043, -0.0137,\n",
       "           0.0699,  0.1017]),\n",
       "  tensor([-0.0276, -0.0724, -0.1979,  0.0113,  0.0451, -0.0349, -0.0766,  0.0949,\n",
       "          -0.0646,  0.0961,  0.0257, -0.1071, -0.0039, -0.0512,  0.0996, -0.1210,\n",
       "          -0.0033,  0.0259, -0.0362,  0.0654,  0.0157, -0.0461, -0.0422, -0.0016,\n",
       "          -0.0161, -0.0419, -0.0427, -0.0166,  0.0681, -0.0634, -0.1145,  0.0050,\n",
       "           0.0361,  0.0391, -0.0639,  0.1934,  0.4349, -0.0869, -0.0066,  0.2020,\n",
       "          -0.0156, -0.0322,  0.2282,  0.0897, -0.0950, -0.0121, -0.5349]),\n",
       "  tensor([-0.0989,  0.0917, -0.1992, -0.1109, -0.0734, -0.0923, -0.1603,  0.1448,\n",
       "           0.1389,  0.0864,  0.0781,  0.1653, -0.0557,  0.0722,  0.2102, -0.2239,\n",
       "           0.1126, -0.0186, -0.0033, -0.2765, -0.0435, -0.1785, -0.0273,  0.1127,\n",
       "          -0.1604, -0.0835,  0.1590, -0.1860,  0.1920,  0.0292, -0.1159,  0.0978,\n",
       "          -0.0232, -0.0820, -0.0040, -0.0705,  0.1772, -0.0741,  0.0449,  0.0992,\n",
       "           0.0097,  0.0982,  0.1308, -0.1318]),\n",
       "  tensor([-0.4957,  0.2288, -0.2925,  0.0115, -0.0321, -0.1189,  0.1418, -0.0988,\n",
       "          -0.0965,  0.1266,  0.1538, -0.1723, -0.1002,  0.0381, -0.2102,  0.1685,\n",
       "           0.1481, -0.0447,  0.1762,  0.0334,  0.0177,  0.0638,  0.1897,  0.0953,\n",
       "           0.0168,  0.2384,  0.1807,  0.0167, -0.2990]),\n",
       "  tensor([ 1.0039e-01,  3.8116e-03,  1.2386e-02,  2.5609e-02, -1.6813e-02,\n",
       "           6.4608e-02,  6.3432e-02, -7.5156e-02, -1.5924e-01, -1.7890e-01,\n",
       "           1.4090e-01,  2.0202e-01, -1.6266e-01,  2.7211e-01, -2.1307e-01,\n",
       "          -3.6138e-01,  1.2375e-02, -2.0793e-02,  2.4650e-01, -6.0585e-02,\n",
       "           1.3399e-02,  3.3099e-02,  5.6555e-02,  2.0145e-02, -6.0894e-02,\n",
       "           1.0830e-01, -7.6589e-02,  8.4387e-06,  1.0147e-01, -8.0902e-02,\n",
       "          -2.8426e-02,  7.6458e-02, -7.5437e-02, -1.5380e-02, -3.7936e-02,\n",
       "          -6.1650e-04, -1.9136e-01,  2.0414e-02,  1.1645e-01,  6.0707e-02,\n",
       "          -1.5394e-02,  8.9370e-02,  2.9557e-02,  6.9047e-03, -3.6744e-02,\n",
       "          -9.0568e-02,  2.1464e-02, -1.0980e-01,  6.2058e-02, -1.2993e-02,\n",
       "           4.7295e-02, -1.6490e-02, -1.7031e-01]),\n",
       "  tensor([-1.1308e-01,  2.3274e-02, -5.0867e-01, -7.2099e-02, -3.0861e-01,\n",
       "           9.2733e-05,  4.0648e-02,  2.0463e-01,  2.3129e-01, -1.3377e-01,\n",
       "           5.2293e-02,  1.0014e-01,  6.0770e-02, -2.7576e-02, -1.7190e-01,\n",
       "           1.6849e-01,  1.4714e-01,  5.7469e-02, -1.5405e-01, -6.3870e-02,\n",
       "          -6.5857e-02,  5.1358e-02, -5.1459e-02, -9.6139e-02,  3.2604e-01,\n",
       "           1.0769e-01, -1.6144e-01, -5.4788e-02, -9.3239e-02, -7.8780e-03,\n",
       "          -9.5093e-02,  8.5967e-02, -9.7645e-02,  7.1133e-02,  6.7008e-02,\n",
       "          -1.4523e-02,  6.4484e-02,  7.6498e-02, -2.8814e-02,  1.1924e-02,\n",
       "           1.0904e-02, -1.2456e-02,  3.6180e-02, -2.5475e-02,  1.4729e-02,\n",
       "           8.9451e-03,  6.3960e-02, -1.1575e-01]),\n",
       "  tensor([ 0.2537,  0.2003,  0.0231, -0.1810,  0.0376, -0.0620, -0.0995, -0.0400,\n",
       "           0.0424, -0.1011,  0.1132, -0.2235, -0.4741,  0.1017,  0.1737,  0.0647,\n",
       "          -0.0459,  0.1950, -0.3137, -0.1048, -0.0291,  0.1737, -0.0315, -0.1414,\n",
       "          -0.1301]),\n",
       "  tensor([-3.6541e-02, -1.7885e-02, -8.5177e-02, -4.4000e-03, -1.2685e-02,\n",
       "          -2.6675e-02, -2.6806e-01,  3.4683e-01,  3.5934e-01, -1.0337e-01,\n",
       "          -7.0243e-02,  3.0363e-03, -4.0789e-02, -2.5609e-02,  4.5579e-02,\n",
       "          -2.2030e-02,  9.5143e-05, -3.9767e-02, -3.9843e-03, -3.9355e-02,\n",
       "           9.6562e-02, -2.4047e-02, -2.8292e-03,  2.4544e-02,  3.1649e-02,\n",
       "          -2.9933e-02, -7.7694e-03, -3.1601e-02, -4.4408e-02,  4.7799e-02,\n",
       "          -5.0609e-02,  2.6368e-02,  1.0798e-01,  1.8693e-02, -3.6321e-02,\n",
       "          -3.5343e-02,  9.9172e-02, -1.9845e-02, -4.7971e-02, -1.2303e-01,\n",
       "           8.9119e-02, -5.5805e-02, -1.4792e-01,  7.6249e-02,  1.1787e-01,\n",
       "           5.3959e-02, -4.3757e-02, -1.5316e-02,  1.4608e-01, -4.2158e-03,\n",
       "           1.2297e-01, -3.0750e-02,  2.4768e-02, -5.9011e-02,  1.0215e-01,\n",
       "           1.1414e-01,  1.7007e-01, -4.9137e-01]),\n",
       "  tensor([ 0.0657, -0.0958,  0.0485,  0.0585,  0.0301, -0.0571,  0.0166,  0.0190,\n",
       "           0.1208, -0.1614,  0.1129,  0.1966, -0.0511, -0.0300,  0.2298,  0.0602,\n",
       "          -0.0824, -0.0843, -0.0427, -0.0505,  0.0344,  0.0935, -0.0148, -0.0266,\n",
       "          -0.0050,  0.0094, -0.0232,  0.0008, -0.0198, -0.0190, -0.0181,  0.0147,\n",
       "          -0.0033, -0.0188, -0.0096, -0.0334,  0.1761,  0.1328, -0.1001, -0.0667,\n",
       "          -0.0031,  0.0130,  0.0024, -0.0310,  0.0762, -0.0089, -0.0214,  0.0132,\n",
       "           0.0065, -0.0491,  0.0032, -0.0245, -0.0234, -0.0685,  0.0090,  0.0441,\n",
       "           0.0391, -0.0656, -0.0727, -0.0259,  0.2285,  0.1331, -0.0168, -0.1151,\n",
       "          -0.1433,  0.0490, -0.0794, -0.0278, -0.2758, -0.1380,  0.0806]),\n",
       "  tensor([-0.1491, -0.1364, -0.0582,  0.0584, -0.1525,  0.1899, -0.0835, -0.0721,\n",
       "           0.2560,  0.2106, -0.0625, -0.0102,  0.0391, -0.2448,  0.0287,  0.0024,\n",
       "          -0.0760,  0.3384, -0.1034,  0.2044,  0.2064,  0.0172, -0.1430,  0.1527,\n",
       "          -0.0713,  0.0213,  0.0269, -0.0155,  0.0549, -0.0270,  0.0808,  0.0201,\n",
       "           0.0026, -0.1277,  0.0109, -0.0241,  0.0167,  0.0270,  0.0032, -0.0187,\n",
       "           0.0273, -0.0048,  0.0086,  0.0750, -0.0301, -0.0591,  0.0537,  0.0663,\n",
       "           0.0376,  0.0189,  0.0734,  0.0914, -0.0205,  0.0441,  0.0204,  0.0022,\n",
       "           0.0054, -0.1141,  0.0171,  0.0109,  0.0062, -0.0299,  0.0100,  0.0047,\n",
       "          -0.0875,  0.1341, -0.1934, -0.0235, -0.0995,  0.1302,  0.0114, -0.0437,\n",
       "           0.1066, -0.0313, -0.0263,  0.0984,  0.0362,  0.0244, -0.0182, -0.0358,\n",
       "           0.0734,  0.0405,  0.0200,  0.0722, -0.0149]),\n",
       "  tensor([ 1.8835e-01, -7.3944e-02, -2.9347e-02, -4.0125e-02,  3.1911e-02,\n",
       "          -7.9235e-02, -1.8376e-02,  1.4295e-02,  1.5829e-01, -2.9306e-02,\n",
       "          -2.1238e-01,  5.9499e-02, -2.4640e-02, -2.4201e-02, -1.7248e-02,\n",
       "           2.1887e-01,  1.8123e-01, -9.6763e-02, -1.0319e-01, -7.6532e-02,\n",
       "           8.9539e-03,  1.7385e-02, -3.3624e-02, -2.8968e-02,  9.7295e-02,\n",
       "           6.2120e-02,  1.1241e-01,  8.5893e-02, -5.6617e-02,  7.9637e-03,\n",
       "          -2.3409e-02,  3.9153e-02,  5.6091e-02,  4.5954e-02,  1.3333e-02,\n",
       "           2.7899e-02, -7.3038e-03,  4.1311e-02, -1.8467e-02, -5.1923e-02,\n",
       "          -5.7712e-02,  1.6917e-04,  2.3141e-02,  1.9768e-02, -1.4122e-02,\n",
       "           1.8827e-02,  1.1689e-02, -3.5878e-02,  2.7607e-02,  1.1693e-02,\n",
       "          -6.2373e-02,  4.1890e-03, -2.1903e-02, -4.2460e-02,  3.4025e-02,\n",
       "          -2.0302e-03, -2.7318e-03, -1.9393e-02,  1.4396e-02, -4.9383e-02,\n",
       "           1.2853e-01, -3.4279e-02, -7.1245e-02, -1.7492e-01,  2.4581e-01,\n",
       "           1.3666e-01, -2.1852e-01,  1.6358e-01,  1.8123e-01,  5.5454e-02,\n",
       "          -1.6566e-01,  1.7935e-01, -2.5865e-02,  4.2505e-02])],\n",
       " 'raw_input_list': [['[CLS]',\n",
       "   'what',\n",
       "   'would',\n",
       "   'a',\n",
       "   'teacher',\n",
       "   'assess',\n",
       "   'the',\n",
       "   'levels',\n",
       "   'of',\n",
       "   'a',\n",
       "   'student',\n",
       "   'on?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'for',\n",
       "   'example,',\n",
       "   'an',\n",
       "   'experienced',\n",
       "   'teacher',\n",
       "   'and',\n",
       "   'parent',\n",
       "   'described',\n",
       "   'the',\n",
       "   'place',\n",
       "   'of',\n",
       "   'a',\n",
       "   'teacher',\n",
       "   'in',\n",
       "   'learning',\n",
       "   'as',\n",
       "   'follows:',\n",
       "   '\"the',\n",
       "   'real',\n",
       "   'bulk',\n",
       "   'of',\n",
       "   'learning',\n",
       "   'takes',\n",
       "   'place',\n",
       "   'in',\n",
       "   'self-study',\n",
       "   'and',\n",
       "   'problem',\n",
       "   'solving',\n",
       "   'with',\n",
       "   'a',\n",
       "   'lot',\n",
       "   'of',\n",
       "   'feedback',\n",
       "   'around',\n",
       "   'that',\n",
       "   'loop.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'what',\n",
       "   'company',\n",
       "   'created',\n",
       "   'doctor',\n",
       "   'who?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'who',\n",
       "   'character',\n",
       "   'by',\n",
       "   'bbc',\n",
       "   'television',\n",
       "   'in',\n",
       "   'the',\n",
       "   'early',\n",
       "   '1960s,',\n",
       "   'a',\n",
       "   'myriad',\n",
       "   'of',\n",
       "   'stories',\n",
       "   'have',\n",
       "   'been',\n",
       "   'published',\n",
       "   'about',\n",
       "   'doctor',\n",
       "   'who,',\n",
       "   'in',\n",
       "   'different',\n",
       "   'media:',\n",
       "   'apart',\n",
       "   'from',\n",
       "   'the',\n",
       "   'actual',\n",
       "   'television',\n",
       "   'episodes',\n",
       "   'that',\n",
       "   'continue',\n",
       "   'to',\n",
       "   'be',\n",
       "   'produced',\n",
       "   'by',\n",
       "   'the',\n",
       "   'bbc,',\n",
       "   'there',\n",
       "   'have',\n",
       "   'also',\n",
       "   'been',\n",
       "   'novels,',\n",
       "   'comics,',\n",
       "   'short',\n",
       "   'stories,',\n",
       "   'audio',\n",
       "   'books,',\n",
       "   'radio',\n",
       "   'plays,',\n",
       "   'interactive',\n",
       "   'video',\n",
       "   'games,',\n",
       "   'game',\n",
       "   'books,',\n",
       "   'webcasts,',\n",
       "   'dvd',\n",
       "   'extras,',\n",
       "   'and',\n",
       "   'even',\n",
       "   'stage',\n",
       "   'performances.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'what',\n",
       "   'was',\n",
       "   'the',\n",
       "   'name',\n",
       "   'of',\n",
       "   'the',\n",
       "   'media',\n",
       "   'day',\n",
       "   'event',\n",
       "   'for',\n",
       "   'super',\n",
       "   'bowl',\n",
       "   '50?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'the',\n",
       "   \"game's\",\n",
       "   'media',\n",
       "   'day,',\n",
       "   'which',\n",
       "   'was',\n",
       "   'typically',\n",
       "   'held',\n",
       "   'on',\n",
       "   'the',\n",
       "   'tuesday',\n",
       "   'afternoon',\n",
       "   'prior',\n",
       "   'to',\n",
       "   'the',\n",
       "   'game,',\n",
       "   'was',\n",
       "   'moved',\n",
       "   'to',\n",
       "   'the',\n",
       "   'monday',\n",
       "   'evening',\n",
       "   'and',\n",
       "   're-branded',\n",
       "   'as',\n",
       "   'super',\n",
       "   'bowl',\n",
       "   'opening',\n",
       "   'night.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'how',\n",
       "   'many',\n",
       "   'doctor',\n",
       "   'who',\n",
       "   'soundtracks',\n",
       "   'have',\n",
       "   'been',\n",
       "   'released',\n",
       "   'since',\n",
       "   '2005?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'the',\n",
       "   'fourth',\n",
       "   'was',\n",
       "   'released',\n",
       "   'on',\n",
       "   '4',\n",
       "   'october',\n",
       "   '2010',\n",
       "   'as',\n",
       "   'a',\n",
       "   'two',\n",
       "   'disc',\n",
       "   'special',\n",
       "   'edition',\n",
       "   'and',\n",
       "   'contained',\n",
       "   'music',\n",
       "   'from',\n",
       "   'the',\n",
       "   '2008–2010',\n",
       "   'specials',\n",
       "   '(the',\n",
       "   'next',\n",
       "   'doctor',\n",
       "   'to',\n",
       "   'end',\n",
       "   'of',\n",
       "   'time',\n",
       "   'part',\n",
       "   '2).',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'what',\n",
       "   'is',\n",
       "   'the',\n",
       "   'name',\n",
       "   'of',\n",
       "   'the',\n",
       "   \"country's\",\n",
       "   'longest',\n",
       "   'continuously',\n",
       "   'running',\n",
       "   'student',\n",
       "   'film',\n",
       "   'society?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'students',\n",
       "   'at',\n",
       "   'the',\n",
       "   'university',\n",
       "   'of',\n",
       "   'chicago',\n",
       "   'run',\n",
       "   'over',\n",
       "   '400',\n",
       "   'clubs',\n",
       "   'and',\n",
       "   'organizations',\n",
       "   'known',\n",
       "   'as',\n",
       "   'recognized',\n",
       "   'student',\n",
       "   'organizations',\n",
       "   '(rsos).',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'how',\n",
       "   'many',\n",
       "   'times',\n",
       "   'has',\n",
       "   'the',\n",
       "   'south',\n",
       "   'florida/miami',\n",
       "   'area',\n",
       "   'hosted',\n",
       "   'the',\n",
       "   'super',\n",
       "   'bowl?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'the',\n",
       "   'south',\n",
       "   'florida/miami',\n",
       "   'area',\n",
       "   'has',\n",
       "   'previously',\n",
       "   'hosted',\n",
       "   'the',\n",
       "   'event',\n",
       "   '10',\n",
       "   'times',\n",
       "   '(tied',\n",
       "   'for',\n",
       "   'most',\n",
       "   'with',\n",
       "   'new',\n",
       "   'orleans),',\n",
       "   'with',\n",
       "   'the',\n",
       "   'most',\n",
       "   'recent',\n",
       "   'one',\n",
       "   'being',\n",
       "   'super',\n",
       "   'bowl',\n",
       "   'xliv',\n",
       "   'in',\n",
       "   '2010.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'what',\n",
       "   'is',\n",
       "   'different',\n",
       "   'about',\n",
       "   'paulinella',\n",
       "   'chromatophora?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'it',\n",
       "   'is',\n",
       "   'not',\n",
       "   'clear',\n",
       "   'whether',\n",
       "   'that',\n",
       "   'symbiont',\n",
       "   'is',\n",
       "   'closely',\n",
       "   'related',\n",
       "   'to',\n",
       "   'the',\n",
       "   'ancestral',\n",
       "   'chloroplast',\n",
       "   'of',\n",
       "   'other',\n",
       "   'eukaryotes.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'who',\n",
       "   'played',\n",
       "   'doctor',\n",
       "   'who',\n",
       "   'on',\n",
       "   'stage',\n",
       "   'in',\n",
       "   'the',\n",
       "   \"70's?\",\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'doctor',\n",
       "   'who',\n",
       "   'has',\n",
       "   'appeared',\n",
       "   'on',\n",
       "   'stage',\n",
       "   'numerous',\n",
       "   'times.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'who',\n",
       "   'do',\n",
       "   'clinical',\n",
       "   'pharmacists',\n",
       "   'work',\n",
       "   'with',\n",
       "   'much',\n",
       "   'of',\n",
       "   'the',\n",
       "   'time?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'clinical',\n",
       "   'pharmacists',\n",
       "   'often',\n",
       "   'collaborate',\n",
       "   'with',\n",
       "   'physicians',\n",
       "   'and',\n",
       "   'other',\n",
       "   'healthcare',\n",
       "   'professionals',\n",
       "   'to',\n",
       "   'improve',\n",
       "   'pharmaceutical',\n",
       "   'care.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'in',\n",
       "   'which',\n",
       "   'county',\n",
       "   'does',\n",
       "   'jacksonville',\n",
       "   'reside?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'it',\n",
       "   'is',\n",
       "   'the',\n",
       "   'county',\n",
       "   'seat',\n",
       "   'of',\n",
       "   'duval',\n",
       "   'county,',\n",
       "   'with',\n",
       "   'which',\n",
       "   'the',\n",
       "   'city',\n",
       "   'government',\n",
       "   'consolidated',\n",
       "   'in',\n",
       "   '1968.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'who',\n",
       "   'did',\n",
       "   'genghis',\n",
       "   'khan',\n",
       "   'charge',\n",
       "   'with',\n",
       "   'finding',\n",
       "   'and',\n",
       "   'punishing',\n",
       "   'the',\n",
       "   'shah?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'genghis',\n",
       "   'khan',\n",
       "   'ordered',\n",
       "   'the',\n",
       "   'wholesale',\n",
       "   'massacre',\n",
       "   'of',\n",
       "   'many',\n",
       "   'of',\n",
       "   'the',\n",
       "   'civilians,',\n",
       "   'enslaved',\n",
       "   'the',\n",
       "   'rest',\n",
       "   'of',\n",
       "   'the',\n",
       "   'population',\n",
       "   'and',\n",
       "   'executed',\n",
       "   'inalchuq',\n",
       "   'by',\n",
       "   'pouring',\n",
       "   'molten',\n",
       "   'silver',\n",
       "   'into',\n",
       "   'his',\n",
       "   'ears',\n",
       "   'and',\n",
       "   'eyes,',\n",
       "   'as',\n",
       "   'retribution',\n",
       "   'for',\n",
       "   'his',\n",
       "   'actions.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'what',\n",
       "   'entity',\n",
       "   'enforces',\n",
       "   'the',\n",
       "   'charter',\n",
       "   'of',\n",
       "   'fundamental',\n",
       "   'rights',\n",
       "   'of',\n",
       "   'the',\n",
       "   'european',\n",
       "   'union?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'in',\n",
       "   'effect,',\n",
       "   'after',\n",
       "   'the',\n",
       "   'lisbon',\n",
       "   'treaty,',\n",
       "   'the',\n",
       "   'charter',\n",
       "   'and',\n",
       "   'the',\n",
       "   'convention',\n",
       "   'now',\n",
       "   'co-exist',\n",
       "   'under',\n",
       "   'european',\n",
       "   'union',\n",
       "   'law,',\n",
       "   'though',\n",
       "   'the',\n",
       "   'former',\n",
       "   'is',\n",
       "   'enforced',\n",
       "   'by',\n",
       "   'the',\n",
       "   'european',\n",
       "   'court',\n",
       "   'of',\n",
       "   'justice',\n",
       "   'in',\n",
       "   'relation',\n",
       "   'to',\n",
       "   'european',\n",
       "   'union',\n",
       "   'measures,',\n",
       "   'and',\n",
       "   'the',\n",
       "   'latter',\n",
       "   'by',\n",
       "   'the',\n",
       "   'european',\n",
       "   'court',\n",
       "   'of',\n",
       "   'human',\n",
       "   'rights',\n",
       "   'in',\n",
       "   'relation',\n",
       "   'to',\n",
       "   'measures',\n",
       "   'by',\n",
       "   'member',\n",
       "   'states.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'most',\n",
       "   'of',\n",
       "   'the',\n",
       "   \"museum's\",\n",
       "   'collection',\n",
       "   'had',\n",
       "   'been',\n",
       "   'returned',\n",
       "   'by',\n",
       "   'which',\n",
       "   'year?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'before',\n",
       "   'the',\n",
       "   'return',\n",
       "   'of',\n",
       "   'the',\n",
       "   'collections',\n",
       "   'after',\n",
       "   'the',\n",
       "   'war,',\n",
       "   'the',\n",
       "   'britain',\n",
       "   'can',\n",
       "   'make',\n",
       "   'it',\n",
       "   'exhibition',\n",
       "   'was',\n",
       "   'held',\n",
       "   'between',\n",
       "   'september',\n",
       "   'and',\n",
       "   'november',\n",
       "   '1946,',\n",
       "   'attracting',\n",
       "   'nearly',\n",
       "   'a',\n",
       "   'million',\n",
       "   'and',\n",
       "   'a',\n",
       "   'half',\n",
       "   'visitors.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'within',\n",
       "   'the',\n",
       "   '30',\n",
       "   'days',\n",
       "   'how',\n",
       "   'many',\n",
       "   'digiboxes',\n",
       "   'had',\n",
       "   'been',\n",
       "   'sold?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'within',\n",
       "   '30',\n",
       "   'days,',\n",
       "   'over',\n",
       "   '100,000',\n",
       "   'digiboxes',\n",
       "   'had',\n",
       "   'been',\n",
       "   'sold,',\n",
       "   'which',\n",
       "   'help',\n",
       "   'bolstered',\n",
       "   \"bskyb's\",\n",
       "   'decision',\n",
       "   'to',\n",
       "   'give',\n",
       "   'away',\n",
       "   'free',\n",
       "   'digiboxes',\n",
       "   'and',\n",
       "   'minidishes',\n",
       "   'from',\n",
       "   'may',\n",
       "   '1999.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'the',\n",
       "   'receptors',\n",
       "   'on',\n",
       "   'a',\n",
       "   'killer',\n",
       "   't',\n",
       "   'cell',\n",
       "   'must',\n",
       "   'bind',\n",
       "   'to',\n",
       "   'how',\n",
       "   'many',\n",
       "   'mhc:',\n",
       "   'antigen',\n",
       "   'complexes',\n",
       "   'in',\n",
       "   'order',\n",
       "   'to',\n",
       "   'activate',\n",
       "   'the',\n",
       "   'cell?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'the',\n",
       "   'mhc:antigen',\n",
       "   'complex',\n",
       "   'is',\n",
       "   'also',\n",
       "   'recognized',\n",
       "   'by',\n",
       "   'the',\n",
       "   'helper',\n",
       "   \"cell's\",\n",
       "   'cd4',\n",
       "   'co-receptor,',\n",
       "   'which',\n",
       "   'recruits',\n",
       "   'molecules',\n",
       "   'inside',\n",
       "   'the',\n",
       "   't',\n",
       "   'cell',\n",
       "   '(e.g.,',\n",
       "   'lck)',\n",
       "   'that',\n",
       "   'are',\n",
       "   'responsible',\n",
       "   'for',\n",
       "   'the',\n",
       "   't',\n",
       "   \"cell's\",\n",
       "   'activation.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'how',\n",
       "   'much',\n",
       "   'did',\n",
       "   'westinghouse',\n",
       "   'pay',\n",
       "   'for',\n",
       "   \"tesla's\",\n",
       "   'designs?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'in',\n",
       "   'july',\n",
       "   '1888,',\n",
       "   'brown',\n",
       "   'and',\n",
       "   'peck',\n",
       "   'negotiated',\n",
       "   'a',\n",
       "   'licensing',\n",
       "   'deal',\n",
       "   'with',\n",
       "   'george',\n",
       "   'westinghouse',\n",
       "   'for',\n",
       "   \"tesla's\",\n",
       "   'polyphase',\n",
       "   'induction',\n",
       "   'motor',\n",
       "   'and',\n",
       "   'transformer',\n",
       "   'designs',\n",
       "   'for',\n",
       "   '$60,000',\n",
       "   'in',\n",
       "   'cash',\n",
       "   'and',\n",
       "   'stock',\n",
       "   'and',\n",
       "   'a',\n",
       "   'royalty',\n",
       "   'of',\n",
       "   '$2.50',\n",
       "   'per',\n",
       "   'ac',\n",
       "   'horsepower',\n",
       "   'produced',\n",
       "   'by',\n",
       "   'each',\n",
       "   'motor.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'what',\n",
       "   'type',\n",
       "   'of',\n",
       "   'movies',\n",
       "   'were',\n",
       "   'produced',\n",
       "   'in',\n",
       "   \"jacksonville's\",\n",
       "   '30',\n",
       "   'studios?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'one',\n",
       "   'converted',\n",
       "   'movie',\n",
       "   'studio',\n",
       "   'site,',\n",
       "   'norman',\n",
       "   'studios,',\n",
       "   'remains',\n",
       "   'in',\n",
       "   'arlington;',\n",
       "   'it',\n",
       "   'has',\n",
       "   'been',\n",
       "   'converted',\n",
       "   'to',\n",
       "   'the',\n",
       "   'jacksonville',\n",
       "   'silent',\n",
       "   'film',\n",
       "   'museum',\n",
       "   'at',\n",
       "   'norman',\n",
       "   'studios.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'what',\n",
       "   'voyager',\n",
       "   'said',\n",
       "   'that',\n",
       "   'mombasa',\n",
       "   'was',\n",
       "   'a',\n",
       "   'great',\n",
       "   'harbour',\n",
       "   'and',\n",
       "   'moored',\n",
       "   'small',\n",
       "   'crafts',\n",
       "   'and',\n",
       "   'great',\n",
       "   'ships?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'the',\n",
       "   'swahili',\n",
       "   'built',\n",
       "   'mombasa',\n",
       "   'into',\n",
       "   'a',\n",
       "   'major',\n",
       "   'port',\n",
       "   'city',\n",
       "   'and',\n",
       "   'established',\n",
       "   'trade',\n",
       "   'links',\n",
       "   'with',\n",
       "   'other',\n",
       "   'nearby',\n",
       "   'city-states,',\n",
       "   'as',\n",
       "   'well',\n",
       "   'as',\n",
       "   'commercial',\n",
       "   'centres',\n",
       "   'in',\n",
       "   'persia,',\n",
       "   'arabia,',\n",
       "   'and',\n",
       "   'even',\n",
       "   'india.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'where',\n",
       "   'is',\n",
       "   'energiprojekt',\n",
       "   'ab',\n",
       "   'based?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'although',\n",
       "   'the',\n",
       "   'reciprocating',\n",
       "   'steam',\n",
       "   'engine',\n",
       "   'is',\n",
       "   'no',\n",
       "   'longer',\n",
       "   'in',\n",
       "   'widespread',\n",
       "   'commercial',\n",
       "   'use,',\n",
       "   'various',\n",
       "   'companies',\n",
       "   'are',\n",
       "   'exploring',\n",
       "   'or',\n",
       "   'exploiting',\n",
       "   'the',\n",
       "   'potential',\n",
       "   'of',\n",
       "   'the',\n",
       "   'engine',\n",
       "   'as',\n",
       "   'an',\n",
       "   'alternative',\n",
       "   'to',\n",
       "   'internal',\n",
       "   'combustion',\n",
       "   'engines.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'who',\n",
       "   'other',\n",
       "   'than',\n",
       "   'tesla',\n",
       "   'did',\n",
       "   'westinghouse',\n",
       "   'consider',\n",
       "   'for',\n",
       "   'the',\n",
       "   'patents?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'westinghouse',\n",
       "   'looked',\n",
       "   'into',\n",
       "   'getting',\n",
       "   'a',\n",
       "   'patent',\n",
       "   'on',\n",
       "   'a',\n",
       "   'similar',\n",
       "   'commutator-less,',\n",
       "   'rotating',\n",
       "   'magnetic',\n",
       "   'field-based',\n",
       "   'induction',\n",
       "   'motor',\n",
       "   'presented',\n",
       "   'in',\n",
       "   'a',\n",
       "   'paper',\n",
       "   'in',\n",
       "   'march',\n",
       "   '1888',\n",
       "   'by',\n",
       "   'the',\n",
       "   'italian',\n",
       "   'physicist',\n",
       "   'galileo',\n",
       "   'ferraris,',\n",
       "   'but',\n",
       "   'decided',\n",
       "   \"tesla's\",\n",
       "   'patent',\n",
       "   'would',\n",
       "   'probably',\n",
       "   'control',\n",
       "   'the',\n",
       "   'market.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'what',\n",
       "   'separates',\n",
       "   'the',\n",
       "   'neuroimmune',\n",
       "   'system',\n",
       "   'and',\n",
       "   'peripheral',\n",
       "   'immune',\n",
       "   'system',\n",
       "   'in',\n",
       "   'humans?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'in',\n",
       "   'humans,',\n",
       "   'the',\n",
       "   'blood–brain',\n",
       "   'barrier,',\n",
       "   'blood–cerebrospinal',\n",
       "   'fluid',\n",
       "   'barrier,',\n",
       "   'and',\n",
       "   'similar',\n",
       "   'fluid–brain',\n",
       "   'barriers',\n",
       "   'separate',\n",
       "   'the',\n",
       "   'peripheral',\n",
       "   'immune',\n",
       "   'system',\n",
       "   'from',\n",
       "   'the',\n",
       "   'neuroimmune',\n",
       "   'system',\n",
       "   'which',\n",
       "   'protects',\n",
       "   'the',\n",
       "   'brain.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'what',\n",
       "   'did',\n",
       "   \"kublai's\",\n",
       "   'government',\n",
       "   'have',\n",
       "   'to',\n",
       "   'balance',\n",
       "   'between?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   \"kublai's\",\n",
       "   'government',\n",
       "   'after',\n",
       "   '1262',\n",
       "   'was',\n",
       "   'a',\n",
       "   'compromise',\n",
       "   'between',\n",
       "   'preserving',\n",
       "   'mongol',\n",
       "   'interests',\n",
       "   'in',\n",
       "   'china',\n",
       "   'and',\n",
       "   'satisfying',\n",
       "   'the',\n",
       "   'demands',\n",
       "   'of',\n",
       "   'his',\n",
       "   'chinese',\n",
       "   'subjects.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'what',\n",
       "   'did',\n",
       "   \"gasquet's\",\n",
       "   'book',\n",
       "   'blame',\n",
       "   'the',\n",
       "   'plague',\n",
       "   'on?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'the',\n",
       "   'historian',\n",
       "   'francis',\n",
       "   'aidan',\n",
       "   'gasquet',\n",
       "   'wrote',\n",
       "   'about',\n",
       "   'the',\n",
       "   \"'great\",\n",
       "   \"pestilence'\",\n",
       "   'in',\n",
       "   '1893',\n",
       "   'and',\n",
       "   'suggested',\n",
       "   'that',\n",
       "   '\"it',\n",
       "   'would',\n",
       "   'appear',\n",
       "   'to',\n",
       "   'be',\n",
       "   'some',\n",
       "   'form',\n",
       "   'of',\n",
       "   'the',\n",
       "   'ordinary',\n",
       "   'eastern',\n",
       "   'or',\n",
       "   'bubonic',\n",
       "   'plague\".',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'who',\n",
       "   'shared',\n",
       "   'sideline',\n",
       "   'duties',\n",
       "   'with',\n",
       "   'evan',\n",
       "   'washburn?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'in',\n",
       "   'the',\n",
       "   'united',\n",
       "   'states,',\n",
       "   'the',\n",
       "   'game',\n",
       "   'was',\n",
       "   'televised',\n",
       "   'by',\n",
       "   'cbs,',\n",
       "   'as',\n",
       "   'part',\n",
       "   'of',\n",
       "   'a',\n",
       "   'cycle',\n",
       "   'between',\n",
       "   'the',\n",
       "   'three',\n",
       "   'main',\n",
       "   'broadcast',\n",
       "   'television',\n",
       "   'partners',\n",
       "   'of',\n",
       "   'the',\n",
       "   'nfl.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'who',\n",
       "   'was',\n",
       "   'added',\n",
       "   'to',\n",
       "   'party',\n",
       "   'as',\n",
       "   'washington',\n",
       "   'went',\n",
       "   'on',\n",
       "   'the',\n",
       "   'way?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'washington',\n",
       "   'left',\n",
       "   'with',\n",
       "   'a',\n",
       "   'small',\n",
       "   'party,',\n",
       "   'picking',\n",
       "   'up',\n",
       "   'along',\n",
       "   'the',\n",
       "   'way',\n",
       "   'jacob',\n",
       "   'van',\n",
       "   'braam',\n",
       "   'as',\n",
       "   'an',\n",
       "   'interpreter;',\n",
       "   'christopher',\n",
       "   'gist,',\n",
       "   'a',\n",
       "   'company',\n",
       "   'surveyor',\n",
       "   'working',\n",
       "   'in',\n",
       "   'the',\n",
       "   'area;',\n",
       "   'and',\n",
       "   'a',\n",
       "   'few',\n",
       "   'mingo',\n",
       "   'led',\n",
       "   'by',\n",
       "   'tanaghrisson.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'what',\n",
       "   'did',\n",
       "   'queen',\n",
       "   'elizabeth',\n",
       "   'ii',\n",
       "   'open',\n",
       "   'in',\n",
       "   'newcastle',\n",
       "   'in',\n",
       "   '1981?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'it',\n",
       "   'was',\n",
       "   'opened',\n",
       "   'in',\n",
       "   'five',\n",
       "   'phases',\n",
       "   'between',\n",
       "   '1980',\n",
       "   'and',\n",
       "   '1984,',\n",
       "   'and',\n",
       "   'was',\n",
       "   \"britain's\",\n",
       "   'first',\n",
       "   'urban',\n",
       "   'light',\n",
       "   'rail',\n",
       "   'transit',\n",
       "   'system;',\n",
       "   'two',\n",
       "   'extensions',\n",
       "   'were',\n",
       "   'opened',\n",
       "   'in',\n",
       "   '1991',\n",
       "   'and',\n",
       "   '2002.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'what',\n",
       "   'writing',\n",
       "   'inspired',\n",
       "   'the',\n",
       "   'name',\n",
       "   'great',\n",
       "   'yuan?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'furthermore,',\n",
       "   'the',\n",
       "   'yuan',\n",
       "   'is',\n",
       "   'sometimes',\n",
       "   'known',\n",
       "   'as',\n",
       "   'the',\n",
       "   '\"empire',\n",
       "   'of',\n",
       "   'the',\n",
       "   'great',\n",
       "   'khan\"',\n",
       "   'or',\n",
       "   '\"khanate',\n",
       "   'of',\n",
       "   'the',\n",
       "   'great',\n",
       "   'khan\",',\n",
       "   'which',\n",
       "   'particularly',\n",
       "   'appeared',\n",
       "   'on',\n",
       "   'some',\n",
       "   'yuan',\n",
       "   'maps,',\n",
       "   'since',\n",
       "   'yuan',\n",
       "   'emperors',\n",
       "   'held',\n",
       "   'the',\n",
       "   'nominal',\n",
       "   'title',\n",
       "   'of',\n",
       "   'great',\n",
       "   'khan.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'what',\n",
       "   'happened',\n",
       "   'to',\n",
       "   'the',\n",
       "   'east',\n",
       "   'india',\n",
       "   'trading',\n",
       "   'company',\n",
       "   'in',\n",
       "   '1767?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'in',\n",
       "   '1599',\n",
       "   'the',\n",
       "   'british',\n",
       "   'east',\n",
       "   'india',\n",
       "   'company',\n",
       "   'was',\n",
       "   'established',\n",
       "   'and',\n",
       "   'was',\n",
       "   'chartered',\n",
       "   'by',\n",
       "   'queen',\n",
       "   'elizabeth',\n",
       "   'in',\n",
       "   'the',\n",
       "   'following',\n",
       "   'year.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'the',\n",
       "   'principle',\n",
       "   'of',\n",
       "   'faunal',\n",
       "   'succession',\n",
       "   'was',\n",
       "   'developed',\n",
       "   '100',\n",
       "   'years',\n",
       "   'before',\n",
       "   'whose',\n",
       "   'theory',\n",
       "   'of',\n",
       "   'evolution?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'based',\n",
       "   'on',\n",
       "   'principles',\n",
       "   'laid',\n",
       "   'out',\n",
       "   'by',\n",
       "   'william',\n",
       "   'smith',\n",
       "   'almost',\n",
       "   'a',\n",
       "   'hundred',\n",
       "   'years',\n",
       "   'before',\n",
       "   'the',\n",
       "   'publication',\n",
       "   'of',\n",
       "   'charles',\n",
       "   \"darwin's\",\n",
       "   'theory',\n",
       "   'of',\n",
       "   'evolution,',\n",
       "   'the',\n",
       "   'principles',\n",
       "   'of',\n",
       "   'succession',\n",
       "   'were',\n",
       "   'developed',\n",
       "   'independently',\n",
       "   'of',\n",
       "   'evolutionary',\n",
       "   'thought.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'how',\n",
       "   'many',\n",
       "   'times',\n",
       "   'did',\n",
       "   'luther',\n",
       "   'preach',\n",
       "   'in',\n",
       "   'halle',\n",
       "   'in',\n",
       "   '1545',\n",
       "   'and',\n",
       "   '1546?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'in',\n",
       "   '1545',\n",
       "   'and',\n",
       "   '1546',\n",
       "   'luther',\n",
       "   'preached',\n",
       "   'three',\n",
       "   'times',\n",
       "   'in',\n",
       "   'the',\n",
       "   'market',\n",
       "   'church',\n",
       "   'in',\n",
       "   'halle,',\n",
       "   'staying',\n",
       "   'with',\n",
       "   'his',\n",
       "   'friend',\n",
       "   'justus',\n",
       "   'jonas',\n",
       "   'during',\n",
       "   'christmas.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'what',\n",
       "   'part',\n",
       "   'of',\n",
       "   'the',\n",
       "   'rhine',\n",
       "   'flows',\n",
       "   'through',\n",
       "   'north',\n",
       "   'rhine-westphalia?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'here',\n",
       "   'the',\n",
       "   'rhine',\n",
       "   'flows',\n",
       "   'through',\n",
       "   'the',\n",
       "   'largest',\n",
       "   'conurbation',\n",
       "   'in',\n",
       "   'germany,',\n",
       "   'the',\n",
       "   'rhine-ruhr',\n",
       "   'region.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'what',\n",
       "   'is',\n",
       "   'the',\n",
       "   'most',\n",
       "   'important',\n",
       "   'thing',\n",
       "   'apicoplasts',\n",
       "   'do?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'the',\n",
       "   'most',\n",
       "   'important',\n",
       "   'apicoplast',\n",
       "   'function',\n",
       "   'is',\n",
       "   'isopentenyl',\n",
       "   'pyrophosphate',\n",
       "   'synthesis—in',\n",
       "   'fact,',\n",
       "   'apicomplexans',\n",
       "   'die',\n",
       "   'when',\n",
       "   'something',\n",
       "   'interferes',\n",
       "   'with',\n",
       "   'this',\n",
       "   'apicoplast',\n",
       "   'function,',\n",
       "   'and',\n",
       "   'when',\n",
       "   'apicomplexans',\n",
       "   'are',\n",
       "   'grown',\n",
       "   'in',\n",
       "   'an',\n",
       "   'isopentenyl',\n",
       "   'pyrophosphate-rich',\n",
       "   'medium,',\n",
       "   'they',\n",
       "   'dump',\n",
       "   'the',\n",
       "   'organelle.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'when',\n",
       "   'did',\n",
       "   'abc',\n",
       "   'begin',\n",
       "   'airing',\n",
       "   'dick',\n",
       "   \"clark's\",\n",
       "   'new',\n",
       "   \"year's\",\n",
       "   \"rockin'\",\n",
       "   'eve?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'since',\n",
       "   '1974,',\n",
       "   'abc',\n",
       "   'has',\n",
       "   'generally',\n",
       "   'aired',\n",
       "   'dick',\n",
       "   \"clark's\",\n",
       "   'new',\n",
       "   \"year's\",\n",
       "   \"rockin'\",\n",
       "   'eve',\n",
       "   'on',\n",
       "   'new',\n",
       "   \"year's\",\n",
       "   'eve',\n",
       "   '(hosted',\n",
       "   'first',\n",
       "   'by',\n",
       "   'its',\n",
       "   'creator',\n",
       "   'dick',\n",
       "   'clark,',\n",
       "   'and',\n",
       "   'later',\n",
       "   'by',\n",
       "   'his',\n",
       "   'successor',\n",
       "   'ryan',\n",
       "   'seacrest);',\n",
       "   'the',\n",
       "   'only',\n",
       "   'exception',\n",
       "   'was',\n",
       "   'in',\n",
       "   '1999,',\n",
       "   'when',\n",
       "   'abc',\n",
       "   'put',\n",
       "   'it',\n",
       "   'on',\n",
       "   'a',\n",
       "   'one-year',\n",
       "   'hiatus',\n",
       "   'to',\n",
       "   'provide',\n",
       "   'coverage',\n",
       "   'of',\n",
       "   'the',\n",
       "   'international',\n",
       "   'millennium',\n",
       "   'festivities,',\n",
       "   'though',\n",
       "   \"clark's\",\n",
       "   'traditional',\n",
       "   'countdown',\n",
       "   'from',\n",
       "   'times',\n",
       "   'square',\n",
       "   'was',\n",
       "   'still',\n",
       "   'featured',\n",
       "   'within',\n",
       "   'the',\n",
       "   'coverage.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'the',\n",
       "   'kronenberg',\n",
       "   'palace',\n",
       "   'had',\n",
       "   'been',\n",
       "   'an',\n",
       "   'exceptional',\n",
       "   'example',\n",
       "   'of',\n",
       "   'what',\n",
       "   'type',\n",
       "   'of',\n",
       "   'architecture?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'despite',\n",
       "   'that',\n",
       "   'the',\n",
       "   'warsaw',\n",
       "   'university',\n",
       "   'of',\n",
       "   'technology',\n",
       "   'building',\n",
       "   '(1899–1902)',\n",
       "   'is',\n",
       "   'the',\n",
       "   'most',\n",
       "   'interesting',\n",
       "   'of',\n",
       "   'the',\n",
       "   'late',\n",
       "   '19th-century',\n",
       "   'architecture.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'what',\n",
       "   'was',\n",
       "   'the',\n",
       "   'definition',\n",
       "   'of',\n",
       "   'professionals,',\n",
       "   'for',\n",
       "   'this',\n",
       "   'study?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'it',\n",
       "   'is',\n",
       "   'important',\n",
       "   'to',\n",
       "   'note,',\n",
       "   'however,',\n",
       "   'that',\n",
       "   'the',\n",
       "   'british',\n",
       "   'study',\n",
       "   'referenced',\n",
       "   'above',\n",
       "   'is',\n",
       "   'the',\n",
       "   'only',\n",
       "   'one',\n",
       "   'of',\n",
       "   'its',\n",
       "   'kind',\n",
       "   'and',\n",
       "   'consisted',\n",
       "   'of',\n",
       "   '\"a',\n",
       "   'random',\n",
       "   '...',\n",
       "   'probability',\n",
       "   'sample',\n",
       "   'of',\n",
       "   '2,869',\n",
       "   'young',\n",
       "   'people',\n",
       "   'between',\n",
       "   'the',\n",
       "   'ages',\n",
       "   'of',\n",
       "   '18',\n",
       "   'and',\n",
       "   '24',\n",
       "   'in',\n",
       "   'a',\n",
       "   'computer-assisted',\n",
       "   'study\"',\n",
       "   'and',\n",
       "   'that',\n",
       "   'the',\n",
       "   'questions',\n",
       "   'referred',\n",
       "   'to',\n",
       "   '\"sexual',\n",
       "   'abuse',\n",
       "   'with',\n",
       "   'a',\n",
       "   'professional,\"',\n",
       "   'not',\n",
       "   'necessarily',\n",
       "   'a',\n",
       "   'teacher.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'bassett',\n",
       "   'focuses',\n",
       "   'on',\n",
       "   'what',\n",
       "   'to',\n",
       "   'illustrate',\n",
       "   'his',\n",
       "   'idea?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'to',\n",
       "   'better',\n",
       "   'illustrate',\n",
       "   'this',\n",
       "   'idea,',\n",
       "   'bassett',\n",
       "   'focuses',\n",
       "   'his',\n",
       "   'analysis',\n",
       "   'of',\n",
       "   'the',\n",
       "   'role',\n",
       "   'of',\n",
       "   'nineteenth-century',\n",
       "   'maps',\n",
       "   'during',\n",
       "   'the',\n",
       "   '\"scramble',\n",
       "   'for',\n",
       "   'africa\".',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'where',\n",
       "   'did',\n",
       "   'tesla',\n",
       "   'believe',\n",
       "   'his',\n",
       "   'talents',\n",
       "   'came',\n",
       "   'from?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   \"tesla's\",\n",
       "   'mother,',\n",
       "   'đuka',\n",
       "   'tesla',\n",
       "   '(nee',\n",
       "   'mandic),',\n",
       "   'whose',\n",
       "   'father',\n",
       "   'was',\n",
       "   'also',\n",
       "   'an',\n",
       "   'orthodox',\n",
       "   'priest,:10',\n",
       "   'had',\n",
       "   'a',\n",
       "   'talent',\n",
       "   'for',\n",
       "   'making',\n",
       "   'home',\n",
       "   'craft',\n",
       "   'tools,',\n",
       "   'mechanical',\n",
       "   'appliances,',\n",
       "   'and',\n",
       "   'the',\n",
       "   'ability',\n",
       "   'to',\n",
       "   'memorize',\n",
       "   'serbian',\n",
       "   'epic',\n",
       "   'poems.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'who',\n",
       "   'was',\n",
       "   'given',\n",
       "   'the',\n",
       "   'esteemed',\n",
       "   'status',\n",
       "   'of',\n",
       "   'mvp',\n",
       "   'for',\n",
       "   'super',\n",
       "   'bowl',\n",
       "   '50?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'denver',\n",
       "   'linebacker',\n",
       "   'von',\n",
       "   'miller',\n",
       "   'was',\n",
       "   'named',\n",
       "   'super',\n",
       "   'bowl',\n",
       "   'mvp,',\n",
       "   'recording',\n",
       "   'five',\n",
       "   'solo',\n",
       "   'tackles,',\n",
       "   '2½',\n",
       "   'sacks,',\n",
       "   'and',\n",
       "   'two',\n",
       "   'forced',\n",
       "   'fumbles.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'what',\n",
       "   'was',\n",
       "   'the',\n",
       "   'percentage',\n",
       "   'of',\n",
       "   'black',\n",
       "   'or',\n",
       "   'african-americans',\n",
       "   'living',\n",
       "   'in',\n",
       "   'the',\n",
       "   'city?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'hispanic',\n",
       "   'or',\n",
       "   'latino',\n",
       "   'of',\n",
       "   'any',\n",
       "   'race',\n",
       "   'were',\n",
       "   '39.9%',\n",
       "   'of',\n",
       "   'the',\n",
       "   'population.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'what',\n",
       "   'was',\n",
       "   'the',\n",
       "   'result',\n",
       "   'of',\n",
       "   'the',\n",
       "   '2007',\n",
       "   'election?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'with',\n",
       "   'international',\n",
       "   'criminal',\n",
       "   'court',\n",
       "   'trial',\n",
       "   'dates',\n",
       "   'in',\n",
       "   '2013',\n",
       "   'for',\n",
       "   'both',\n",
       "   'president',\n",
       "   'kenyatta',\n",
       "   'and',\n",
       "   'deputy',\n",
       "   'president',\n",
       "   'william',\n",
       "   'ruto',\n",
       "   'related',\n",
       "   'to',\n",
       "   'the',\n",
       "   '2007',\n",
       "   'election',\n",
       "   'aftermath,',\n",
       "   'us',\n",
       "   'president',\n",
       "   'barack',\n",
       "   'obama',\n",
       "   'chose',\n",
       "   'not',\n",
       "   'to',\n",
       "   'visit',\n",
       "   'the',\n",
       "   'country',\n",
       "   'during',\n",
       "   'his',\n",
       "   'mid-2013',\n",
       "   'african',\n",
       "   'trip.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'what',\n",
       "   'equation',\n",
       "   'currently',\n",
       "   'decribes',\n",
       "   'the',\n",
       "   'physics',\n",
       "   'of',\n",
       "   'force.',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'the',\n",
       "   'notion',\n",
       "   '\"force\"',\n",
       "   'keeps',\n",
       "   'its',\n",
       "   'meaning',\n",
       "   'in',\n",
       "   'quantum',\n",
       "   'mechanics,',\n",
       "   'though',\n",
       "   'one',\n",
       "   'is',\n",
       "   'now',\n",
       "   'dealing',\n",
       "   'with',\n",
       "   'operators',\n",
       "   'instead',\n",
       "   'of',\n",
       "   'classical',\n",
       "   'variables',\n",
       "   'and',\n",
       "   'though',\n",
       "   'the',\n",
       "   'physics',\n",
       "   'is',\n",
       "   'now',\n",
       "   'described',\n",
       "   'by',\n",
       "   'the',\n",
       "   'schrodinger',\n",
       "   'equation',\n",
       "   'instead',\n",
       "   'of',\n",
       "   'newtonian',\n",
       "   'equations.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'what',\n",
       "   'did',\n",
       "   'iqbal',\n",
       "   'fear',\n",
       "   'would',\n",
       "   'weaken',\n",
       "   'the',\n",
       "   'spiritual',\n",
       "   'foundations',\n",
       "   'of',\n",
       "   'islam',\n",
       "   'and',\n",
       "   'muslim',\n",
       "   'society?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'in',\n",
       "   'his',\n",
       "   'travels',\n",
       "   'to',\n",
       "   'egypt,',\n",
       "   'afghanistan,',\n",
       "   'palestine',\n",
       "   'and',\n",
       "   'syria,',\n",
       "   'he',\n",
       "   'promoted',\n",
       "   'ideas',\n",
       "   'of',\n",
       "   'greater',\n",
       "   'islamic',\n",
       "   'political',\n",
       "   'co-operation',\n",
       "   'and',\n",
       "   'unity,',\n",
       "   'calling',\n",
       "   'for',\n",
       "   'the',\n",
       "   'shedding',\n",
       "   'of',\n",
       "   'nationalist',\n",
       "   'differences.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'in',\n",
       "   'what',\n",
       "   'meeting',\n",
       "   'did',\n",
       "   'shirley',\n",
       "   'lay',\n",
       "   'out',\n",
       "   'plans',\n",
       "   'for',\n",
       "   '1756?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'at',\n",
       "   'a',\n",
       "   'meeting',\n",
       "   'in',\n",
       "   'albany',\n",
       "   'in',\n",
       "   'december',\n",
       "   '1755,',\n",
       "   'he',\n",
       "   'laid',\n",
       "   'out',\n",
       "   'his',\n",
       "   'plans',\n",
       "   'for',\n",
       "   '1756.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'in',\n",
       "   'autoimmune',\n",
       "   'disorders,',\n",
       "   'the',\n",
       "   'immune',\n",
       "   'system',\n",
       "   \"doesn't\",\n",
       "   'distinguish',\n",
       "   'between',\n",
       "   'what',\n",
       "   'types',\n",
       "   'of',\n",
       "   'cells?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'one',\n",
       "   'of',\n",
       "   'the',\n",
       "   'functions',\n",
       "   'of',\n",
       "   'specialized',\n",
       "   'cells',\n",
       "   '(located',\n",
       "   'in',\n",
       "   'the',\n",
       "   'thymus',\n",
       "   'and',\n",
       "   'bone',\n",
       "   'marrow)',\n",
       "   'is',\n",
       "   'to',\n",
       "   'present',\n",
       "   'young',\n",
       "   'lymphocytes',\n",
       "   'with',\n",
       "   'self',\n",
       "   'antigens',\n",
       "   'produced',\n",
       "   'throughout',\n",
       "   'the',\n",
       "   'body',\n",
       "   'and',\n",
       "   'to',\n",
       "   'eliminate',\n",
       "   'those',\n",
       "   'cells',\n",
       "   'that',\n",
       "   'recognize',\n",
       "   'self-antigens,',\n",
       "   'preventing',\n",
       "   'autoimmunity.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'which',\n",
       "   'husband',\n",
       "   'and',\n",
       "   'wife',\n",
       "   'modern',\n",
       "   'furniture',\n",
       "   'design',\n",
       "   'team',\n",
       "   'are',\n",
       "   'represented',\n",
       "   'in',\n",
       "   'the',\n",
       "   'v&a',\n",
       "   'furniture',\n",
       "   'collection?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'one',\n",
       "   'of',\n",
       "   'the',\n",
       "   'finest',\n",
       "   'pieces',\n",
       "   'of',\n",
       "   'continental',\n",
       "   'furniture',\n",
       "   'in',\n",
       "   'the',\n",
       "   'collection',\n",
       "   'is',\n",
       "   'the',\n",
       "   'rococo',\n",
       "   'augustus',\n",
       "   'rex',\n",
       "   'bureau',\n",
       "   'cabinet',\n",
       "   'dated',\n",
       "   'c1750',\n",
       "   'from',\n",
       "   'germany,',\n",
       "   'with',\n",
       "   'especially',\n",
       "   'fine',\n",
       "   'marquetry',\n",
       "   'and',\n",
       "   'ormolu',\n",
       "   'mounts.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'why',\n",
       "   'did',\n",
       "   'oil',\n",
       "   'start',\n",
       "   'getting',\n",
       "   'priced',\n",
       "   'in',\n",
       "   'terms',\n",
       "   'of',\n",
       "   'gold?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'because',\n",
       "   'oil',\n",
       "   'was',\n",
       "   'priced',\n",
       "   'in',\n",
       "   'dollars,',\n",
       "   'oil',\n",
       "   \"producers'\",\n",
       "   'real',\n",
       "   'income',\n",
       "   'decreased.',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'who',\n",
       "   'did',\n",
       "   'britain',\n",
       "   'exploit',\n",
       "   'in',\n",
       "   'india?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'although',\n",
       "   'a',\n",
       "   'substantial',\n",
       "   'number',\n",
       "   'of',\n",
       "   'colonies',\n",
       "   'had',\n",
       "   'been',\n",
       "   'designed',\n",
       "   'to',\n",
       "   'provide',\n",
       "   'economic',\n",
       "   'profit',\n",
       "   'and',\n",
       "   'to',\n",
       "   'ship',\n",
       "   'resources',\n",
       "   'to',\n",
       "   'home',\n",
       "   'ports',\n",
       "   'in',\n",
       "   'the',\n",
       "   'seventeenth',\n",
       "   'and',\n",
       "   'eighteenth',\n",
       "   'centuries,',\n",
       "   'fieldhouse',\n",
       "   'suggests',\n",
       "   'that',\n",
       "   'in',\n",
       "   'the',\n",
       "   'nineteenth',\n",
       "   'and',\n",
       "   'twentieth',\n",
       "   'centuries',\n",
       "   'in',\n",
       "   'places',\n",
       "   'such',\n",
       "   'as',\n",
       "   'africa',\n",
       "   'and',\n",
       "   'asia,',\n",
       "   'this',\n",
       "   'idea',\n",
       "   'is',\n",
       "   'not',\n",
       "   'necessarily',\n",
       "   'valid:',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'what',\n",
       "   'popular',\n",
       "   'environmentalist',\n",
       "   'is',\n",
       "   'also',\n",
       "   'a',\n",
       "   'university',\n",
       "   'alumni',\n",
       "   'member?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'in',\n",
       "   'science,',\n",
       "   'alumni',\n",
       "   'include',\n",
       "   'astronomers',\n",
       "   'carl',\n",
       "   'sagan,',\n",
       "   'a',\n",
       "   'prominent',\n",
       "   'contributor',\n",
       "   'to',\n",
       "   'the',\n",
       "   'scientific',\n",
       "   'research',\n",
       "   'of',\n",
       "   'extraterrestrial',\n",
       "   'life,',\n",
       "   'and',\n",
       "   'edwin',\n",
       "   'hubble,',\n",
       "   'known',\n",
       "   'for',\n",
       "   '\"hubble\\'s',\n",
       "   'law\",',\n",
       "   'nasa',\n",
       "   'astronaut',\n",
       "   'john',\n",
       "   'm.',\n",
       "   'grunsfeld,',\n",
       "   'geneticist',\n",
       "   'james',\n",
       "   'watson,',\n",
       "   'best',\n",
       "   'known',\n",
       "   'as',\n",
       "   'one',\n",
       "   'of',\n",
       "   'the',\n",
       "   'co-discoverers',\n",
       "   'of',\n",
       "   'the',\n",
       "   'structure',\n",
       "   'of',\n",
       "   'dna,',\n",
       "   'experimental',\n",
       "   'physicist',\n",
       "   'luis',\n",
       "   'alvarez,',\n",
       "   'popular',\n",
       "   'environmentalist',\n",
       "   'david',\n",
       "   'suzuki,',\n",
       "   'balloonist',\n",
       "   'jeannette',\n",
       "   'piccard,',\n",
       "   'biologists',\n",
       "   'ernest',\n",
       "   'everett',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'what',\n",
       "   'publication',\n",
       "   'did',\n",
       "   'philip',\n",
       "   'howard',\n",
       "   'work',\n",
       "   'for?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'responding',\n",
       "   'to',\n",
       "   'the',\n",
       "   'findings',\n",
       "   'of',\n",
       "   'the',\n",
       "   'survey',\n",
       "   'in',\n",
       "   'the',\n",
       "   'times',\n",
       "   'newspaper,',\n",
       "   'journalist',\n",
       "   'philip',\n",
       "   'howard',\n",
       "   'maintained',\n",
       "   'that,',\n",
       "   '\"to',\n",
       "   'compare',\n",
       "   'the',\n",
       "   'violence',\n",
       "   'of',\n",
       "   'dr',\n",
       "   'who,',\n",
       "   'sired',\n",
       "   'by',\n",
       "   'a',\n",
       "   'horse-laugh',\n",
       "   'out',\n",
       "   'of',\n",
       "   'a',\n",
       "   'nightmare,',\n",
       "   'with',\n",
       "   'the',\n",
       "   'more',\n",
       "   'realistic',\n",
       "   'violence',\n",
       "   'of',\n",
       "   'other',\n",
       "   'television',\n",
       "   'series,',\n",
       "   'where',\n",
       "   'actors',\n",
       "   'who',\n",
       "   'look',\n",
       "   'like',\n",
       "   'human',\n",
       "   'beings',\n",
       "   'bleed',\n",
       "   'paint',\n",
       "   'that',\n",
       "   'looks',\n",
       "   'like',\n",
       "   'blood,',\n",
       "   'is',\n",
       "   'like',\n",
       "   'comparing',\n",
       "   'monopoly',\n",
       "   'with',\n",
       "   'the',\n",
       "   'property',\n",
       "   'market',\n",
       "   'in',\n",
       "   'london:',\n",
       "   'both',\n",
       "   'are',\n",
       "   'fantasies,',\n",
       "   'but',\n",
       "   'one',\n",
       "   'is',\n",
       "   'meant',\n",
       "   'to',\n",
       "   'be',\n",
       "   'taken',\n",
       "   'seriously.\"',\n",
       "   '[SEP]'],\n",
       "  ['[CLS]',\n",
       "   'if',\n",
       "   'the',\n",
       "   'apparant',\n",
       "   'force',\n",
       "   'of',\n",
       "   'two',\n",
       "   'fermions',\n",
       "   'is',\n",
       "   'attractive,',\n",
       "   'what',\n",
       "   'is',\n",
       "   'the',\n",
       "   'spin',\n",
       "   'function?',\n",
       "   '[SEP]',\n",
       "   '[SEP]',\n",
       "   'if',\n",
       "   'two',\n",
       "   'identical',\n",
       "   'fermions',\n",
       "   '(e.g.',\n",
       "   'electrons)',\n",
       "   'have',\n",
       "   'a',\n",
       "   'symmetric',\n",
       "   'spin',\n",
       "   'function',\n",
       "   '(e.g.',\n",
       "   'parallel',\n",
       "   'spins)',\n",
       "   'the',\n",
       "   'spatial',\n",
       "   'variables',\n",
       "   'must',\n",
       "   'be',\n",
       "   'antisymmetric',\n",
       "   '(i.e.',\n",
       "   'they',\n",
       "   'exclude',\n",
       "   'each',\n",
       "   'other',\n",
       "   'from',\n",
       "   'their',\n",
       "   'places',\n",
       "   'much',\n",
       "   'as',\n",
       "   'if',\n",
       "   'there',\n",
       "   'was',\n",
       "   'a',\n",
       "   'repulsive',\n",
       "   'force),',\n",
       "   'and',\n",
       "   'vice',\n",
       "   'versa,',\n",
       "   'i.e.',\n",
       "   'for',\n",
       "   'antiparallel',\n",
       "   'spins',\n",
       "   'the',\n",
       "   'position',\n",
       "   'variables',\n",
       "   'must',\n",
       "   'be',\n",
       "   'symmetric',\n",
       "   '(i.e.',\n",
       "   'the',\n",
       "   'apparent',\n",
       "   'force',\n",
       "   'must',\n",
       "   'be',\n",
       "   'attractive).',\n",
       "   '[SEP]']]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_info(idxs, qnli_data_raw, targets, model_out_list, raw_attr_list, conti_attr_list, raw_input_list, \n",
    "          fname=f'../MethodOutputs/{file_name_base}_out.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db9de1f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_notebook()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "download_HTML(cur_file_name=f'{file_name_base}_QNLI_BERT.ipynb',\n",
    "              out_file_name=f'{file_name_base}_QNLI_BERT.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
