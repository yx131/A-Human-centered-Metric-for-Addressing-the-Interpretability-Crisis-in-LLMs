{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52a49c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from nltk.metrics.agreement import AnnotationTask\n",
    "import analysis_constants as ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a86b2605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_out_and_results_files(frame_name):\n",
    "    frame_out_name = f'{frame_name}_out.pkl'\n",
    "    frame_res_name =  f'{frame_name}_results.csv'\n",
    "    frame_out = {}\n",
    "    with open(f'{frame_out_name}', 'rb') as f:\n",
    "        frame_out = pickle.load(f)\n",
    "    frame_res = pd.read_csv(f'{frame_res_name}')\n",
    "#     print(f'{frame_res.columns}')\n",
    "    return frame_out, frame_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b5bc3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#process frame_out's information to be used by calc score\n",
    "def get_organized_frame_out(frame_out):\n",
    "    #get features (words)\n",
    "    organized = {'feats_pos': [], 'feats_neg': [], 'N_Chunks': []}\n",
    "    for i, (ri, ca) in enumerate(zip(frame_out['raw_input_list'], frame_out['conti_attr_list'])):\n",
    "        #subout beginnining <s> and end </s> tokens for ['BEGIN'] and ['END']\n",
    "        raw_input_i = ['[BEGIN]'if f == '<s>' else '[END]' if f == '</s>' else f for f in ri]\n",
    "        attr_appearance_cutoff = 5e-2\n",
    "        ca = ca.to(torch.float32)\n",
    "        \n",
    "        #filtering out by zeroing non-appearing features\n",
    "        ca_i = torch.where(torch.abs(ca) < attr_appearance_cutoff, torch.zeros(1), ca) \n",
    "        \n",
    "        #get positive and negative features\n",
    "        ca_i_pos = torch.where(ca_i > 0, ca_i, torch.zeros(1))\n",
    "        ca_i_neg = torch.where(ca_i < 0, ca_i, torch.zeros(1))\n",
    "        \n",
    "        try:\n",
    "            #get idx of pos/neg identified feature\n",
    "            ca_i_pos_idx = torch.nonzero(ca_i_pos).squeeze().numpy()\n",
    "            ca_i_neg_idx = torch.nonzero(ca_i_neg).squeeze().numpy() \n",
    "            #don't account for empty ''s or empty arrays\n",
    "            features_pos = [raw_input_i[idx] for idx in ca_i_pos_idx if ri[idx] != ''] \n",
    "            features_neg = [raw_input_i[idx] for idx in ca_i_neg_idx if ri[idx] != ''] \n",
    "        except TypeError: #TypeError: iteration over a 0-d array\n",
    "            #         print(f'i: {i}')\n",
    "            #         print(f'{ri}')\n",
    "            #         print(f'i: {raw_input_i}')\n",
    "            #         print(f'{ca}')\n",
    "            #         print(f'{ca_i}')\n",
    "            #         print(f'{ca_i_idx}')\n",
    "            #         print(f'features frame {features_frame}')\n",
    "            #         print(f'N_Chunks {N_Chunks}')\n",
    "            #         print(organized)\n",
    "            features_pos = []\n",
    "            features_neg = []\n",
    "            \n",
    "\n",
    "        \n",
    "            \n",
    "        organized['feats_pos'].append(features_pos)\n",
    "        organized['feats_neg'].append(features_neg)\n",
    "        \n",
    "        N_cs = len(features_pos) + len(features_neg)\n",
    "        organized['N_Chunks'].append(N_cs)\n",
    "        \n",
    "#      \n",
    "    frame_out.update(organized)\n",
    "    return frame_out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2151e294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process frame_res to be used by calc_score\n",
    "def get_organized_frame_res(frame_res, yhs_func, task_name):\n",
    "    organized = {'yh': [], 'non_neg': [], 'non_pos': [], 'should_neg': [], 'should_pos': [], 'trust_numbers': []}\n",
    "    for x in frame_res.groupby(f'Input.{task_name}_number'):  # edit this groupby thing for different tasks\n",
    "        task_answers = x[1]['Answer.taskAnswers']\n",
    "        yhs, trusts = [], []\n",
    "        non_red_ins, non_green_ins, fiat_red_ins, fiat_green_ins = [], [], [], []\n",
    "        for answer_string in task_answers:  # edit this portion below to adapt\n",
    "            json_obj = json.loads(answer_string)[0]\n",
    "#             print(f'json obj {json_obj}')\n",
    "            yh = yhs_func(json_obj)\n",
    "            yhs.append(yh)\n",
    "            trust = json_obj['trust_number'] if 'trust_number' in json_obj else 0         \n",
    "            trusts.append(trust)\n",
    "            \n",
    "            if 'non_red_in' in json_obj.keys():\n",
    "                non_red_ins.append([k.strip() for k in json_obj['non_red_in'].split(',')])\n",
    "            else:\n",
    "                non_red_ins.append([])\n",
    "\n",
    "            if 'non_green_in' in json_obj.keys():\n",
    "                non_green_ins.append([k.strip() for k in json_obj['non_green_in'].split(',')])\n",
    "            else:\n",
    "                non_green_ins.append([])\n",
    "\n",
    "            if 'fiat_red_in' in json_obj.keys():\n",
    "                fiat_red_ins.append([k.strip() for k in json_obj['fiat_red_in'].split(',')])\n",
    "            else:\n",
    "                fiat_red_ins.append([])\n",
    "\n",
    "            if 'fiat_green_in' in json_obj.keys():\n",
    "                fiat_green_ins.append([k.strip() for k in json_obj['fiat_green_in'].split(',')])\n",
    "            else:\n",
    "                fiat_green_ins.append([])\n",
    "\n",
    "        organized['yh'].append(yhs)\n",
    "        organized['non_neg'].append(non_red_ins)\n",
    "        organized['non_pos'].append(non_green_ins)\n",
    "        organized['should_neg'].append(fiat_red_ins)\n",
    "        organized['should_pos'].append(fiat_green_ins)\n",
    "        organized['trust_numbers'].append(trusts)\n",
    "        \n",
    "    # see agreement rate of turks:\n",
    "    # assume 3 annotators\n",
    "        \n",
    "    annotation_triples = []\n",
    "    for i, y_res in enumerate(organized['yh'], start=1):\n",
    "        if len(y_res) != 3:\n",
    "            print(f'i:{i}, don\\'t have 3 answers')\n",
    "            continue\n",
    "        a1 = ('a1', str(i), y_res[0])\n",
    "        a2 = ('a2', str(i), y_res[1])\n",
    "        a3 = ('a3', str(i), y_res[2])\n",
    "        annotation_triples.append(a1)\n",
    "        annotation_triples.append(a2)\n",
    "        annotation_triples.append(a3)      \n",
    "    annotation_task = AnnotationTask(annotation_triples)\n",
    "    average_ao = annotation_task.avg_Ao()\n",
    "    return organized, average_ao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "814d4df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions to parse out the annotator's result from the json object for each task\n",
    "def sst2_sentiment_function(json_obj):\n",
    "    sentiment = 1 if json_obj['sentiment_radio']['1'] else 0\n",
    "    return sentiment\n",
    "\n",
    "def stsb_similarity_function(json_obj):\n",
    "    similarity = json_obj['similarity'] if 'similarity' in json_obj else 2.5\n",
    "    similarity = 1 if float(similarity) > 2.5 else 0\n",
    "    return similarity\n",
    "\n",
    "def qnli_entailment_function(json_obj):\n",
    "    entailment = 1 if json_obj['entailment_radio']['1'] else 0\n",
    "    return entailment\n",
    "\n",
    "yhs_function_list = [sst2_sentiment_function, stsb_similarity_function, qnli_entailment_function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5f8af15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_frame_out_and_res(task_name,  \n",
    "                          yhs_func,\n",
    "    frame_names=['deeplift', 'guided_backprop', 'input_x_gradients', 'integrated_gradients', 'kernel_shap', 'lime']):\n",
    "    \n",
    "    path_to_task_files = ac.path_to_task_files(task_name)\n",
    "    avg_aos = []\n",
    "    for frame_name in frame_names:\n",
    "        print(f'current task: {task_name}, current framework: {frame_name}')\n",
    "        path_to_frame=f'{path_to_task_files}/{frame_name}'\n",
    "        frame_out, frame_results = load_out_and_results_files(path_to_frame)\n",
    "        org_frame_results, avg_ao = get_organized_frame_res(frame_results, yhs_func, task_name)\n",
    "        avg_aos.append(avg_ao)\n",
    "        org_frame_out = get_organized_frame_out(frame_out)    \n",
    "        \n",
    "        with open(f'{path_to_task_files}/{frame_name}_out{ac.process_suffix}.pkl', 'wb') as f:\n",
    "            pickle.dump(org_frame_out, f)\n",
    "        with open(f'{path_to_task_files}/{frame_name}_results{ac.process_suffix}.pkl', 'wb') as f:\n",
    "            pickle.dump(org_frame_results, f)\n",
    "            \n",
    "    print(f'average average agreement {np.mean(avg_aos):.2f}')\n",
    "    return frame_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86de99a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_frame_process_wrapper(tasks_names, yhs_function_list):\n",
    "        for (task_name, yhs_function) in zip(tasks_names, yhs_function_list):\n",
    "            proc_frame_out_and_res(task_name, yhs_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e548b045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current task: sst2, current framework: deeplift\n",
      "current task: sst2, current framework: guided_backprop\n",
      "current task: sst2, current framework: input_x_gradients\n",
      "current task: sst2, current framework: integrated_gradients\n",
      "current task: sst2, current framework: kernel_shap\n",
      "current task: sst2, current framework: lime\n",
      "average average agreement 0.65\n",
      "current task: stsb, current framework: deeplift\n",
      "current task: stsb, current framework: guided_backprop\n",
      "current task: stsb, current framework: input_x_gradients\n",
      "current task: stsb, current framework: integrated_gradients\n",
      "current task: stsb, current framework: kernel_shap\n",
      "current task: stsb, current framework: lime\n",
      "average average agreement 0.83\n",
      "current task: qnli, current framework: deeplift\n",
      "current task: qnli, current framework: guided_backprop\n",
      "current task: qnli, current framework: input_x_gradients\n",
      "current task: qnli, current framework: integrated_gradients\n",
      "current task: qnli, current framework: kernel_shap\n",
      "current task: qnli, current framework: lime\n",
      "average average agreement 0.65\n"
     ]
    }
   ],
   "source": [
    "task_frame_process_wrapper(ac.task_names, yhs_function_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6076bab3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
