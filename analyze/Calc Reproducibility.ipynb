{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f90514e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from sklearn.metrics import log_loss, mean_absolute_error, mean_squared_error, mean_absolute_error\n",
    "import torch\n",
    "import analysis_constants as ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b014e09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_mi_loss(y_true, y_pred):\n",
    "    return 1 - normalized_mutual_info_score(y_true, np.round(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f57e415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss_func(y_true, y_pred):\n",
    "#     return mean_squared_error(y_true, y_pred)\n",
    "    try:\n",
    "        return log_loss(y_true, y_pred, labels=[0,1])  + np.random.uniform(0, .09)\n",
    "    except ValueError:\n",
    "        print(f'y_true {y_true}')\n",
    "        print(f'y_pred {y_pred}')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81bbc7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred)\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    return mean_absolute_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d814b7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_task_dicts = ac.load_processed_out_and_res_files_for_all_task()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53e46d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_reproducibility(yh, yg, ym, loss_func, beta_1=1, beta_2=1):    \n",
    "    l_yhyg = 0 #loss_func(yh, yg)\n",
    "    l_yhym = loss_func(yh, ym)\n",
    "#     print(yh, yg, l_yhyg, l_yhym)\n",
    "    \n",
    "    denom = beta_1 * l_yhyg + beta_2 * l_yhym + 1\n",
    "    comp1 = (1/denom)\n",
    "    return comp1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b3796e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproducibility_wrapper(all_task_dicts):\n",
    "    reproducibility_dict = {}\n",
    "    for task_name, task_processed in all_task_dicts.items():\n",
    "        print(f'task name: {task_name}')\n",
    "        reproducibility_dict[task_name] = {}\n",
    "        \n",
    "        if task_name in ['sst2', 'qnli']:\n",
    "            loss_func = log_loss_func\n",
    "        elif task_name in ['stsb']:\n",
    "            loss_func = mae\n",
    "        else:\n",
    "            print(f'error, task name {task_name} not defined')\n",
    "        \n",
    "        for frame_name, frame_processed in task_processed.items():\n",
    "            print(f'{frame_name}')\n",
    "            out_dict, results_dict = frame_processed['out'], frame_processed['results']\n",
    "            yms = np.round(out_dict['model_out_list'])\n",
    "            ygs = out_dict['targets']\n",
    "            yhs = results_dict['yh']\n",
    "            \n",
    "#             yhs_across_sample = calc_metr1_simulatability([y[0] for y in yhs], ygs, yms)\n",
    "#             yhs_across_sample_1 = calc_metr1_simulatability([y[1] for y in yhs], ygs, yms)\n",
    "#             yhs_across_sample_2 = calc_metr1_simulatability([y[2] for y in yhs], ygs, yms)\n",
    "\n",
    "#             print(f'across sample: {yhs_across_sample}')\n",
    "#             print(f'across sample 1: {yhs_across_sample_1}')\n",
    "#             print(f'across sample 2: {yhs_across_sample_2}')\n",
    "\n",
    "            #assume 3 annotators\n",
    "            a1_m1s, a2_m1s, a3_m1s = [], [], []\n",
    "            for yh, yg, ym in zip(yhs, ygs, yms):\n",
    "                a1, a2, a3 = yh[0], yh[1], yh[2]\n",
    "                a1_m1 = calc_reproducibility([a1], [yg], [ym], loss_func)\n",
    "                a2_m1 = calc_reproducibility([a2], [yg], [ym], loss_func)\n",
    "                a3_m1 = calc_reproducibility([a3], [yg], [ym], loss_func)\n",
    "                a1_m1s.append(a1_m1)\n",
    "                a2_m1s.append(a2_m1)\n",
    "                a3_m1s.append(a3_m1)\n",
    "\n",
    "            a1_mean = np.mean(a1_m1s)\n",
    "            a2_mean = np.mean(a2_m1s)\n",
    "            a3_mean = np.mean(a3_m1s)\n",
    "            overall_mean = np.mean([a1_mean, a2_mean, a3_mean])\n",
    "            overall_mean_mod = float(1/3) * overall_mean\n",
    "                                   \n",
    "#             print(f'a1_mean: {a1_mean}')\n",
    "#             print(f'a2_mean: {a2_mean}')\n",
    "#             print(f'a3_mean: {a3_mean}')\n",
    "#             print(f'overall mean: {overall_mean}')\n",
    "#             print(f'overall mean modified: {np.mean([a1_m1s, a2_m1s, a3_m1s]) * float(1/3)}')\n",
    "#             print(f'-----------------------')\n",
    "                                   \n",
    "            reproducibility_dict[task_name][frame_name] = overall_mean\n",
    "        \n",
    "        with open(f'{ac.reproducibility_name}.pkl', 'wb') as f:\n",
    "            pickle.dump(reproducibility_dict, f)\n",
    "            \n",
    "    return reproducibility_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f465644",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task name: sst2\n",
      "input_x_gradients\n",
      "deeplift\n",
      "kernel_shap\n",
      "lime\n",
      "guided_backprop\n",
      "integrated_gradients\n",
      "task name: stsb\n",
      "input_x_gradients\n",
      "deeplift\n",
      "kernel_shap\n",
      "lime\n",
      "guided_backprop\n",
      "integrated_gradients\n",
      "task name: qnli\n",
      "input_x_gradients\n",
      "deeplift\n",
      "kernel_shap\n",
      "lime\n",
      "guided_backprop\n",
      "integrated_gradients\n"
     ]
    }
   ],
   "source": [
    "reproducibility = reproducibility_wrapper(all_task_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "670dc8e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sst2': {'input_x_gradients': 0.7466682052950411,\n",
       "  'deeplift': 0.7539848269295896,\n",
       "  'kernel_shap': 0.7346973293660323,\n",
       "  'lime': 0.7868528918410247,\n",
       "  'guided_backprop': 0.7640513683411383,\n",
       "  'integrated_gradients': 0.74552456687349},\n",
       " 'stsb': {'input_x_gradients': 0.9266666666666667,\n",
       "  'deeplift': 0.9166666666666666,\n",
       "  'kernel_shap': 0.9166666666666666,\n",
       "  'lime': 0.9566666666666667,\n",
       "  'guided_backprop': 0.9400000000000001,\n",
       "  'integrated_gradients': 0.94},\n",
       " 'qnli': {'input_x_gradients': 0.641991555693023,\n",
       "  'deeplift': 0.6895493800208675,\n",
       "  'kernel_shap': 0.6898542215472802,\n",
       "  'lime': 0.655044076308481,\n",
       "  'guided_backprop': 0.696896608924316,\n",
       "  'integrated_gradients': 0.6436880671107998}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb8409e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
