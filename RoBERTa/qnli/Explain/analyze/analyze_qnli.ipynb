{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "733ed20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from nltk.metrics.agreement import AnnotationTask\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58deb599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    try:\n",
    "        return log_loss(y_true, y_pred, labels=[0,1])\n",
    "    except ValueError:\n",
    "        print(f'y_true {y_true}, {len(y_true)}')\n",
    "        print(f'y_pred {y_pred}, {len(y_pred)}')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fcc493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(l1, l2):  #expected two lists of words or two sets of words\n",
    "    l1, l2 = set(l1), set(l2)\n",
    "    intersection = l1.intersection(l2)\n",
    "    union = l1.union(l2)\n",
    "    try:\n",
    "        return float(len(intersection)) / len(union)\n",
    "    except ZeroDivisionError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9307b9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_out_and_results_files(frame_name):\n",
    "    frame_out_name = f'{frame_name}_out.pkl'\n",
    "    frame_res_name =  f'{frame_name}_results.csv'\n",
    "    frame_out = {}\n",
    "    with open(f'{frame_out_name}', 'rb') as f:\n",
    "        frame_out = pickle.load(f)\n",
    "    frame_res = pd.read_csv(f'{frame_res_name}')\n",
    "#     print(f'{frame_res.columns}')\n",
    "    return frame_out, frame_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "292850cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#process frame_out's information to be used by calc score\n",
    "def get_organized_frame_out(frame_out):\n",
    "    #get features (words)\n",
    "    organized = {'feats_pos': [], 'feats_neg': [], 'N_Chunks': []}\n",
    "    for i, (ri, ca) in enumerate(zip(frame_out['raw_input_list'], frame_out['conti_attr_list'])):\n",
    "        #subout beginnining <s> and end </s> tokens for ['BEGIN'] and ['END']\n",
    "        raw_input_i = ['[BEGIN]'if f == '<s>' else '[END]' if f == '</s>' else f for f in ri]\n",
    "        attr_appearance_cutoff = 5e-2\n",
    "        ca = ca.to(torch.float32)\n",
    "        \n",
    "        #filtering out by zeroing non-appearing features\n",
    "        ca_i = torch.where(torch.abs(ca) < attr_appearance_cutoff, torch.zeros(1), ca) \n",
    "        \n",
    "        #get positive and negative features\n",
    "        ca_i_pos = torch.where(ca_i > 0, ca_i, torch.zeros(1))\n",
    "        ca_i_neg = torch.where(ca_i < 0, ca_i, torch.zeros(1))\n",
    "        \n",
    "        try:\n",
    "            #get idx of pos/neg identified feature\n",
    "            ca_i_pos_idx = torch.nonzero(ca_i_pos).squeeze().numpy()\n",
    "            ca_i_neg_idx = torch.nonzero(ca_i_neg).squeeze().numpy() \n",
    "            #don't account for empty ''s or empty arrays\n",
    "            features_pos = [raw_input_i[idx] for idx in ca_i_pos_idx if ri[idx] != ''] \n",
    "            features_neg = [raw_input_i[idx] for idx in ca_i_neg_idx if ri[idx] != ''] \n",
    "        except TypeError: #TypeError: iteration over a 0-d array\n",
    "            #         print(f'i: {i}')\n",
    "            #         print(f'{ri}')\n",
    "            #         print(f'i: {raw_input_i}')\n",
    "            #         print(f'{ca}')\n",
    "            #         print(f'{ca_i}')\n",
    "            #         print(f'{ca_i_idx}')\n",
    "            #         print(f'features frame {features_frame}')\n",
    "            #         print(f'N_Chunks {N_Chunks}')\n",
    "            #         print(organized)\n",
    "            features_pos = []\n",
    "            features_neg = []\n",
    "            \n",
    "\n",
    "        \n",
    "            \n",
    "        organized['feats_pos'].append(features_pos)\n",
    "        organized['feats_neg'].append(features_neg)\n",
    "        \n",
    "        N_cs = len(features_pos) + len(features_neg)\n",
    "        organized['N_Chunks'].append(N_cs)\n",
    "        \n",
    "#      \n",
    "    frame_out.update(organized)\n",
    "    return frame_out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3418be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process frame_res to be used by calc_score\n",
    "def get_organized_frame_res(frame_res):\n",
    "    organized = {'yh': [], 'non_neg': [], 'non_pos': [], 'should_neg': [], 'should_pos': [], 'trust_numbers': []}\n",
    "    for x in frame_res.groupby('Input.qnli_number'):  # edit this groupby thing for different tasks\n",
    "        task_answers = x[1]['Answer.taskAnswers']\n",
    "        entailments, trusts = [], []\n",
    "        non_red_ins, non_green_ins, fiat_red_ins, fiat_green_ins = [], [], [], []\n",
    "        for answer_string in task_answers:  # edit this portion below to adapt\n",
    "            json_obj = json.loads(answer_string)[0]\n",
    "#             print(f'json obj {json_obj}')\n",
    "            entailment = 1 if json_obj['entailment_radio']['1'] else 0\n",
    "            entailments.append(entailment)\n",
    "            trust = json_obj['trust_number'] if 'trust_number' in json_obj else 0         \n",
    "            trusts.append(trust)\n",
    "            \n",
    "            if 'non_red_in' in json_obj.keys():\n",
    "                non_red_ins.append([k.strip() for k in json_obj['non_red_in'].split(',')])\n",
    "            else:\n",
    "                non_red_ins.append([])\n",
    "\n",
    "            if 'non_green_in' in json_obj.keys():\n",
    "                non_green_ins.append([k.strip() for k in json_obj['non_green_in'].split(',')])\n",
    "            else:\n",
    "                non_green_ins.append([])\n",
    "\n",
    "            if 'fiat_red_in' in json_obj.keys():\n",
    "                fiat_red_ins.append([k.strip() for k in json_obj['fiat_red_in'].split(',')])\n",
    "            else:\n",
    "                fiat_red_ins.append([])\n",
    "\n",
    "            if 'fiat_green_in' in json_obj.keys():\n",
    "                fiat_green_ins.append([k.strip() for k in json_obj['fiat_green_in'].split(',')])\n",
    "            else:\n",
    "                fiat_green_ins.append([])\n",
    "\n",
    "        organized['yh'].append(entailments)\n",
    "        organized['non_neg'].append(non_red_ins)\n",
    "        organized['non_pos'].append(non_green_ins)\n",
    "        organized['should_neg'].append(fiat_red_ins)\n",
    "        organized['should_pos'].append(fiat_green_ins)\n",
    "        organized['trust_numbers'].append(trusts)\n",
    "        \n",
    "    # see agreement rate of turks:\n",
    "    # assume 3 annotators\n",
    "        \n",
    "    annotation_triples = []\n",
    "    for i, y_res in enumerate(organized['yh'], start=1):\n",
    "        if len(y_res) != 3:\n",
    "            print(f'i:{i}, don\\'t have 3 answers')\n",
    "            continue\n",
    "        a1 = ('a1', str(i), y_res[0])\n",
    "        a2 = ('a2', str(i), y_res[1])\n",
    "        a3 = ('a3', str(i), y_res[2])\n",
    "        annotation_triples.append(a1)\n",
    "        annotation_triples.append(a2)\n",
    "        annotation_triples.append(a3)      \n",
    "    annotation_task = AnnotationTask(annotation_triples)\n",
    "    average_ao = annotation_task.avg_Ao()\n",
    "\n",
    "    return organized, average_ao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f258d339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metr1_simulatability(yh, yg, ym, beta_1=1, beta_2=1):    \n",
    "    loss_func = cross_entropy_loss\n",
    "    l_yhyg = loss_func(yg, yh)\n",
    "    l_yhym = loss_func(ym, yh)\n",
    "    denom = beta_1 * l_yhyg + beta_2 * l_yhym + 1\n",
    "    comp1 = (1/denom)\n",
    "    return comp1\n",
    "\n",
    "def metr1_wrapper(org_frame_out, org_frame_results):\n",
    "    metr1s = []\n",
    "    \n",
    "    yhs = org_frame_results['yh']\n",
    "    yms = np.round(org_frame_out['model_out_list'])\n",
    "    ygs = org_frame_out['targets']\n",
    "    yh_0, yh_1, yh_2 = [], [], [] #assume 3 annotaters\n",
    "    for yh in yhs:\n",
    "        if len(yh) != 3:\n",
    "            print(f'len not 3 {yh}')\n",
    "            continue \n",
    "        yh_0.append(yh[0])\n",
    "        yh_1.append(yh[1])\n",
    "        yh_2.append(yh[2])\n",
    "    \n",
    "    annotations = [yh_0, yh_1, yh_2]\n",
    "    for yh in annotations:\n",
    "        metr1s.append(calc_metr1_simulatability(yh, ygs, yms))\n",
    "#     print(np.mean(metr1s), metr1s)\n",
    "    return np.mean(metr1s), metr1s\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ae6a867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metr2_fidelity(feat_f_pos, feat_f_neg, feat_h_pos, feat_h_neg):\n",
    "    jaccard_pos = jaccard_similarity(feat_f_pos, feat_h_pos)\n",
    "    jaccard_neg = jaccard_similarity(feat_f_neg, feat_h_neg)\n",
    "    fidelity = np.mean([jaccard_pos, jaccard_neg])\n",
    "#     print(f'pos jaccard {jaccard_pos}')\n",
    "#     print(f'neg jaccard {jaccard_neg}')\n",
    "#     print(f'fidelity {fidelity}')\n",
    "    return fidelity \n",
    "\n",
    "def metr2_wrapper(org_frame_out, org_frame_results):\n",
    "    metr2s = []\n",
    "    for ff_pos, ff_neg, fh_nn_all, fh_np_all, fh_sn_all, fh_sp_all\\\n",
    "                            in zip(org_frame_out['feats_pos'], \n",
    "                               org_frame_out['feats_neg'], \n",
    "                               org_frame_results['non_neg'],\n",
    "                               org_frame_results['non_pos'],\n",
    "                               org_frame_results['should_neg'],\n",
    "                               org_frame_results['should_pos']):\n",
    "        metr2_annos = []\n",
    "        for fh_nn, fh_np, fh_sn, fh_sp\\\n",
    "                            in zip(fh_nn_all, fh_np_all, fh_sn_all, fh_sp_all):\n",
    "            fh_neg = set(ff_neg).difference(fh_nn).union(fh_sn)\n",
    "            fh_pos = set(ff_pos).difference(fh_nn).union(fh_sp)\n",
    "            \n",
    "            metr2_an = calc_metr2_fidelity(ff_pos, ff_neg, fh_pos, fh_neg)\n",
    "            metr2_annos.append(metr2_an)\n",
    "        metr2s.append(metr2_annos)\n",
    "    metr2s = np.array(metr2s)\n",
    "    metr2s_average = metr2s.mean(axis=1).mean(axis=0)\n",
    "    return metr2s_average, metr2s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "354db9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metr3_complexity(N_c):\n",
    "    if N_c == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1/(np.log(N_c)+1)\n",
    "\n",
    "def metr3_wrapper(org_frame_out, org_frame_results):\n",
    "    metr3s = []\n",
    "    N_Chunks = org_frame_out['N_Chunks']\n",
    "    for N_c in N_Chunks:\n",
    "        metr3 = calc_metr3_complexity(N_c)\n",
    "        metr3s.append(metr3)\n",
    "    metr3s_average = np.mean(metr3s)\n",
    "#     print(metr3s_average, metr3s)\n",
    "    return metr3s_average, metr3s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26997907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_m1m2m3(org_frame_out, org_frame_results):\n",
    "    m1, metric1s = metr1_wrapper(org_frame_out, org_frame_results)\n",
    "    m2, metric2s = metr2_wrapper(org_frame_out, org_frame_results)\n",
    "    m3, metric3s = metr3_wrapper(org_frame_out, org_frame_results)\n",
    "    return m1, m2, m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f4e5244",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def score_wrapper(frame_names=['deep_lift', 'guided_backprop', 'input_x_gradients', 'integrated_gradients', 'kernel_shap', 'lime']):\n",
    "    avg_aos = []\n",
    "    m1s, m2s, m3s = [], [], []\n",
    "    for frame_name in frame_names:\n",
    "        print(f'Framework processed: {frame_name}')\n",
    "        frame_out, frame_results = load_out_and_results_files(frame_name)\n",
    "        org_frame_results, avg_ao = get_organized_frame_res(frame_results)\n",
    "        avg_aos.append(avg_ao)\n",
    "        org_frame_out = get_organized_frame_out(frame_out)    \n",
    "        m1, m2, m3 = calc_m1m2m3(org_frame_out, org_frame_results)\n",
    "        m1s.append(m1)\n",
    "        m2s.append(m2)\n",
    "        m3s.append(m3)\n",
    "        print(f'm1: {m1:4f}, m2: {m2:4f}, m3: {m3:4f}')\n",
    "    print(f'average average agreement {np.mean(avg_aos):.2f}')\n",
    "    return frame_names, m1s, m2s, m3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8436936c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Framework processed: deep_lift\n",
      "m1: 0.057034, m2: 0.859048, m3: 0.235495\n",
      "Framework processed: guided_backprop\n",
      "m1: 0.054720, m2: 0.866368, m3: 0.228977\n",
      "Framework processed: input_x_gradients\n",
      "m1: 0.055151, m2: 0.872433, m3: 0.235495\n",
      "Framework processed: integrated_gradients\n",
      "m1: 0.050538, m2: 0.793053, m3: 0.232914\n",
      "Framework processed: kernel_shap\n",
      "m1: 0.059342, m2: 0.854397, m3: 0.230393\n",
      "Framework processed: lime\n",
      "m1: 0.054025, m2: 0.850321, m3: 0.216652\n",
      "average average agreement 0.65\n"
     ]
    }
   ],
   "source": [
    "frame_names, m1s, m2s, m3s = score_wrapper(['deep_lift', 'guided_backprop', 'input_x_gradients', 'integrated_gradients', 'kernel_shap', 'lime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58fe3b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\textbf{f} & 0.0190 & 0.2863 & 0.0785 & 0.3839 \\\\ deep_lift\n",
      "\\textbf{f} & 0.0182 & 0.2888 & 0.0763 & 0.3834 \\\\ guided_backprop\n",
      "\\textbf{f} & 0.0184 & 0.2908 & 0.0785 & 0.3877 \\\\ input_x_gradients\n",
      "\\textbf{f} & 0.0168 & 0.2644 & 0.0776 & 0.3588 \\\\ integrated_gradients\n",
      "\\textbf{f} & 0.0198 & 0.2848 & 0.0768 & 0.3814 \\\\ kernel_shap\n",
      "\\textbf{f} & 0.0180 & 0.2834 & 0.0722 & 0.3737 \\\\ lime\n"
     ]
    }
   ],
   "source": [
    "def see_1_3_alpha(frame_names, m1s, m2s, m3s):\n",
    "    for f, m1, m2, m3 in zip(frame_names, m1s, m2s, m3s):\n",
    "        m1_13 = m1 * (1/3)\n",
    "        m2_13 = m2 * (1/3)\n",
    "        m3_13 = m3 * (1/3)\n",
    "        score_13 = m1_13 + m2_13 + m3_13\n",
    "        print(F\"\\\\textbf{{f}} & {m1_13:.4f} & {m2_13:.4f} & {m3_13:.4f} & {score_13:.4f} \\\\\\\\ {f}\")\n",
    "\n",
    "see_1_3_alpha(frame_names, m1s, m2s, m3s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f1b2366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_alpha_combos():\n",
    "    import itertools\n",
    "    alphas = np.arange(0, 11, step=1, dtype=np.uint8)\n",
    "    all_combos = [(a/10,b/10,c/10) for (a,b,c) in itertools.product(alphas, alphas, alphas) if np.sum([a,b,c]) == 10]\n",
    "    all_combos.reverse()\n",
    "    return all_combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1646be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_combos = generate_alpha_combos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1106340b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_alphas(frame_names, m1s, m2s, m3s, alpha_combos):\n",
    "    scores_list = [] #indexed by the alpha combinations\n",
    "    for combo in alpha_combos:\n",
    "        a1, a2, a3 = combo[0], combo[1], combo[2]\n",
    "        scores_for_fs = []\n",
    "        for f, m1, m2, m3 in zip(frame_names, m1s, m2s, m3s):\n",
    "            a1m1, a2m2, a3m3 = a1 * m1, a2 * m2, a3 * m3\n",
    "            score = a1m1 + a2m2 + a3m3\n",
    "            scores_for_fs.append(score)      \n",
    "        scores_list.append([frame_names, scores_for_fs])\n",
    "    return scores_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5160ec09",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_list = apply_alphas(frame_names, m1s, m2s, m3s, alpha_combos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e56a5b2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def normalize_score_list(scores_list):\n",
    "    normalized_scores_list = []\n",
    "    from sklearn.preprocessing import normalize\n",
    "    def min_max_norm(scores):\n",
    "        norm_scores = (scores-np.min(scores))/(np.max(scores)-np.min(scores))\n",
    "        return norm_scores\n",
    "    \n",
    "    for (frame_names, scores) in scores_list:\n",
    "        scores = np.array(scores)\n",
    "#         normalized_scores = normalize([scores])[0]\n",
    "#         normalized_scores = scores / np.sum(scores)\n",
    "        normalized_scores = min_max_norm(scores)\n",
    "#         print(f'after normalizing: {normalized_scores}\\n-------------------------------------')\n",
    "        normalized_scores_list.append([frame_names, normalized_scores])\n",
    "    return normalized_scores_list\n",
    "\n",
    "# scores_list = normalize_score_list(scores_list)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0d94f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_scores(scores_list, alpha_combos):\n",
    "    frame_names = scores_list[0][0]\n",
    "    frame_scores = {}\n",
    "    for i in range(len(frame_names)):\n",
    "        frame_name = frame_names[i]\n",
    "        frame_scores[frame_name] = [scores_list[j][1][i] for j in range(len(scores_list))]\n",
    "    \n",
    "   \n",
    "    \n",
    "    #sort frames based on average scores\n",
    "    average_scores_dict = {}\n",
    "    for frame, frame_scores_list in frame_scores.items():\n",
    "        print(f'Average score for {frame}: {np.mean(frame_scores_list)}, std: {np.std(frame_scores_list)}')\n",
    "        average_scores_dict[frame] = np.mean(frame_scores_list)\n",
    "    sorted_average_scores_list =[[k, v] for k, v in sorted(average_scores_dict.items(), \n",
    "                                                          key=lambda item: item[1], reverse=True)]\n",
    "    print(f'sorted average scores {sorted_average_scores_list}')\n",
    "\n",
    "    ordered_frame_names = [k for [k,v] in sorted_average_scores_list]\n",
    "    #sort based on top frame\n",
    "    top_frame_name = ordered_frame_names[0]\n",
    "    print(f'top_frame_name {top_frame_name}')\n",
    "    sorted_idxs = np.argsort(frame_scores[top_frame_name])\n",
    "    sorted_frame_scores = {}\n",
    "    for frame in frame_names:\n",
    "        sorted_frame_scores[frame] = np.array(frame_scores[frame])[sorted_idxs]\n",
    "    \n",
    "    permuted_alphas = np.array(np.array(alpha_combos)[sorted_idxs])\n",
    "    a1_idx = np.where(permuted_alphas[:,0]==1)[0][0]\n",
    "    a2_idx = np.where(permuted_alphas[:,1]==1)[0][0]\n",
    "    a3_idx = np.where(permuted_alphas[:,2]==1)[0][0]\n",
    "    \n",
    "    \n",
    "    return sorted_frame_scores, a1_idx, a2_idx, a3_idx, ordered_frame_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ff2011b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score for deep_lift: 0.38385919302479765, std: 0.19600612899591524\n",
      "Average score for guided_backprop: 0.38335495793487806, std: 0.19888767450482805\n",
      "Average score for input_x_gradients: 0.38769273437917373, std: 0.19986198806580951\n",
      "Average score for integrated_gradients: 0.35883494044870007, std: 0.18011163446782238\n",
      "Average score for kernel_shap: 0.38137741598965935, std: 0.1947917476373307\n",
      "Average score for lime: 0.3736662240371027, std: 0.1958380147200183\n",
      "sorted average scores [['input_x_gradients', 0.38769273437917373], ['deep_lift', 0.38385919302479765], ['guided_backprop', 0.38335495793487806], ['kernel_shap', 0.38137741598965935], ['lime', 0.3736662240371027], ['integrated_gradients', 0.35883494044870007]]\n",
      "top_frame_name input_x_gradients\n"
     ]
    }
   ],
   "source": [
    "frame_scores, a1_idx, a2_idx, a3_idx, ordered_frame_names = get_frame_scores(scores_list, alpha_combos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c932952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_graph_info(frame_scores, a1_idx, a2_idx, a3_idx, ordered_frame_names, task_name='QNLI'):\n",
    "    out_dict = {\n",
    "        'task_name': task_name,\n",
    "        'frame_scores': frame_scores, \n",
    "        'a1_idx': a1_idx, \n",
    "        'a2_idx': a2_idx,\n",
    "        'a3_idx': a3_idx,\n",
    "        'ordered_frame_names': ordered_frame_names\n",
    "    }\n",
    "    out_file_name = f'{task_name}_graph.pkl'\n",
    "    with open(out_file_name, 'wb') as f:\n",
    "        pickle.dump(out_dict, f)\n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0021a8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_name': 'QNLI',\n",
       " 'frame_scores': {'deep_lift': array([0.0570342 , 0.07488027, 0.09272634, 0.11057241, 0.12841848,\n",
       "         0.13723563, 0.14626455, 0.1550817 , 0.16411062, 0.17292777,\n",
       "         0.18195668, 0.19077384, 0.19980275, 0.20861991, 0.21764882,\n",
       "         0.21743706, 0.22646597, 0.23549489, 0.23528313, 0.24431204,\n",
       "         0.25312919, 0.26215811, 0.27097526, 0.28000418, 0.28882133,\n",
       "         0.29785025, 0.29763848, 0.3066674 , 0.31548455, 0.32451347,\n",
       "         0.33333062, 0.34235954, 0.35117669, 0.36020561, 0.36902276,\n",
       "         0.37783991, 0.38686883, 0.39568598, 0.4047149 , 0.41353205,\n",
       "         0.42256097, 0.43137812, 0.44922419, 0.45804134, 0.46707026,\n",
       "         0.47588741, 0.48491633, 0.49373348, 0.51157955, 0.52942562,\n",
       "         0.53824277, 0.54727169, 0.55608884, 0.57393491, 0.59178098,\n",
       "         0.60962705, 0.6184442 , 0.63629027, 0.65413634, 0.67198241,\n",
       "         0.69864563, 0.7164917 , 0.73433777, 0.77884706, 0.79669313,\n",
       "         0.85904849]),\n",
       "  'guided_backprop': array([0.05472028, 0.0721459 , 0.08957152, 0.10699715, 0.12442277,\n",
       "         0.13588506, 0.14184839, 0.15331068, 0.15927402, 0.1707363 ,\n",
       "         0.17669964, 0.18816193, 0.19412526, 0.20558755, 0.21155089,\n",
       "         0.21704984, 0.22301317, 0.22897651, 0.23447546, 0.2404388 ,\n",
       "         0.25190109, 0.25786442, 0.26932671, 0.27529004, 0.28675233,\n",
       "         0.29271567, 0.29821462, 0.30417796, 0.31564024, 0.32160358,\n",
       "         0.33306587, 0.3390292 , 0.35049149, 0.35645483, 0.36791711,\n",
       "         0.3793794 , 0.38534274, 0.39680502, 0.40276836, 0.41423065,\n",
       "         0.42019398, 0.43165627, 0.44908189, 0.46054418, 0.46650752,\n",
       "         0.47796981, 0.48393314, 0.49539543, 0.51282105, 0.53024668,\n",
       "         0.54170896, 0.5476723 , 0.55913459, 0.57656021, 0.59398583,\n",
       "         0.61141146, 0.62287374, 0.64029937, 0.65772499, 0.67515061,\n",
       "         0.70403853, 0.72146415, 0.73888977, 0.78520331, 0.80262893,\n",
       "         0.86636809]),\n",
       "  'input_x_gradients': array([0.05515056, 0.07318499, 0.09121943, 0.10925386, 0.12728829,\n",
       "         0.13687878, 0.14532273, 0.15491321, 0.16335716, 0.17294765,\n",
       "         0.18139159, 0.19098208, 0.19942603, 0.20901651, 0.21746046,\n",
       "         0.218607  , 0.22705095, 0.23549489, 0.23664143, 0.24508538,\n",
       "         0.25467586, 0.26311981, 0.2727103 , 0.28115425, 0.29074473,\n",
       "         0.29918868, 0.30033522, 0.30877916, 0.31836965, 0.3268136 ,\n",
       "         0.33640408, 0.34484803, 0.35443852, 0.36288246, 0.37247295,\n",
       "         0.38206344, 0.39050738, 0.40009787, 0.40854182, 0.4181323 ,\n",
       "         0.42657625, 0.43616674, 0.45420117, 0.46379165, 0.4722356 ,\n",
       "         0.48182609, 0.49027004, 0.49986052, 0.51789495, 0.53592939,\n",
       "         0.54551987, 0.55396382, 0.56355431, 0.58158874, 0.59962317,\n",
       "         0.61765761, 0.62724809, 0.64528253, 0.66331696, 0.68135139,\n",
       "         0.70897631, 0.72701074, 0.74504518, 0.79070453, 0.80873896,\n",
       "         0.87243275]),\n",
       "  'integrated_gradients': array([0.05053842, 0.06877595, 0.08701347, 0.10525099, 0.12348852,\n",
       "         0.12478986, 0.14172604, 0.14302738, 0.15996356, 0.1612649 ,\n",
       "         0.17820109, 0.17950243, 0.19643861, 0.19773995, 0.21467613,\n",
       "         0.19904129, 0.21597747, 0.23291366, 0.21727881, 0.234215  ,\n",
       "         0.23551633, 0.25245252, 0.25375386, 0.27069004, 0.27199138,\n",
       "         0.28892757, 0.27329272, 0.2902289 , 0.29153024, 0.30846643,\n",
       "         0.30976777, 0.32670395, 0.32800529, 0.34494147, 0.34624281,\n",
       "         0.34754415, 0.36448034, 0.36578167, 0.38271786, 0.3840192 ,\n",
       "         0.40095538, 0.40225672, 0.42049424, 0.42179558, 0.43873177,\n",
       "         0.44003311, 0.45696929, 0.45827063, 0.47650815, 0.49474568,\n",
       "         0.49604701, 0.5129832 , 0.51428454, 0.53252206, 0.55075958,\n",
       "         0.56899711, 0.57029844, 0.58853597, 0.60677349, 0.62501101,\n",
       "         0.64454988, 0.6627874 , 0.68102492, 0.71880131, 0.73703883,\n",
       "         0.79305274]),\n",
       "  'kernel_shap': array([0.05934246, 0.07644747, 0.09355248, 0.11065749, 0.1277625 ,\n",
       "         0.13884794, 0.14486751, 0.15595295, 0.16197251, 0.17305796,\n",
       "         0.17907752, 0.19016297, 0.19618253, 0.20726797, 0.21328754,\n",
       "         0.21835342, 0.22437298, 0.23039255, 0.23545843, 0.24147799,\n",
       "         0.25256344, 0.258583  , 0.26966844, 0.27568801, 0.28677345,\n",
       "         0.29279302, 0.2978589 , 0.30387846, 0.3149639 , 0.32098347,\n",
       "         0.33206891, 0.33808848, 0.34917392, 0.35519349, 0.36627893,\n",
       "         0.37736437, 0.38338394, 0.39446938, 0.40048895, 0.41157439,\n",
       "         0.41759395, 0.4286794 , 0.44578441, 0.45686985, 0.46288941,\n",
       "         0.47397486, 0.47999442, 0.49107987, 0.50818488, 0.52528988,\n",
       "         0.53637533, 0.54239489, 0.55348034, 0.57058534, 0.58769035,\n",
       "         0.60479536, 0.6158808 , 0.63298581, 0.65009082, 0.66719583,\n",
       "         0.69538628, 0.71249129, 0.7295963 , 0.77489176, 0.79199677,\n",
       "         0.85439724]),\n",
       "  'lime': array([0.05402546, 0.07028814, 0.08655082, 0.1028135 , 0.11907618,\n",
       "         0.13365501, 0.13533886, 0.14991769, 0.15160154, 0.16618037,\n",
       "         0.16786422, 0.18244305, 0.1841269 , 0.19870573, 0.20038957,\n",
       "         0.21328456, 0.21496841, 0.21665225, 0.22954724, 0.23123109,\n",
       "         0.24580992, 0.24749377, 0.2620726 , 0.26375644, 0.27833528,\n",
       "         0.28001912, 0.29291411, 0.29459796, 0.30917679, 0.31086064,\n",
       "         0.32543947, 0.32712331, 0.34170215, 0.34338599, 0.35796483,\n",
       "         0.37254366, 0.37422751, 0.38880634, 0.39049018, 0.40506902,\n",
       "         0.40675286, 0.4213317 , 0.43759438, 0.45217321, 0.45385706,\n",
       "         0.46843589, 0.47011973, 0.48469857, 0.50096125, 0.51722393,\n",
       "         0.53180276, 0.5334866 , 0.54806544, 0.56432812, 0.5805908 ,\n",
       "         0.59685347, 0.61143231, 0.62769499, 0.64395767, 0.66022034,\n",
       "         0.69106186, 0.70732454, 0.72358721, 0.77069141, 0.78695409,\n",
       "         0.85032096])},\n",
       " 'a1_idx': 0,\n",
       " 'a2_idx': 65,\n",
       " 'a3_idx': 17,\n",
       " 'ordered_frame_names': ['input_x_gradients',\n",
       "  'deep_lift',\n",
       "  'guided_backprop',\n",
       "  'kernel_shap',\n",
       "  'lime',\n",
       "  'integrated_gradients']}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_graph_info(frame_scores, a1_idx, a2_idx, a3_idx, ordered_frame_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c64460e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
