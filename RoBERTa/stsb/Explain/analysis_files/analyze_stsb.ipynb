{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "733ed20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "from nltk.metrics.agreement import AnnotationTask\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58deb599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_error_loss(y_true, y_pred):\n",
    "    try:\n",
    "        return mean_squared_error(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        print(f'y_true {y_true}')\n",
    "        print(f'y_pred {y_pred}')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5384672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    try:\n",
    "        return log_loss(y_true, y_pred, labels=[0,1])\n",
    "    except ValueError:\n",
    "        print(f'y_true {y_true}')\n",
    "        print(f'y_pred {y_pred}')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fcc493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(l1, l2):  #expected two lists of words or two sets of words\n",
    "    l1, l2 = set(l1), set(l2)\n",
    "    intersection = l1.intersection(l2)\n",
    "    union = l1.union(l2)\n",
    "    try:\n",
    "        return float(len(intersection)) / len(union)\n",
    "    except ZeroDivisionError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9307b9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_out_and_results_files(frame_name):\n",
    "    frame_out_name = f'{frame_name}_out.pkl'\n",
    "    frame_res_name =  f'{frame_name}_results.csv'\n",
    "    frame_out = {}\n",
    "    with open(f'{frame_out_name}', 'rb') as f:\n",
    "        frame_out = pickle.load(f)\n",
    "    frame_res = pd.read_csv(f'{frame_res_name}')\n",
    "#     print(f'{frame_res.columns}')\n",
    "    return frame_out, frame_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "292850cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#process frame_out's information to be used by calc score\n",
    "def get_organized_frame_out(frame_out):\n",
    "    #get features (words)\n",
    "    organized = {'feats_pos': [], 'feats_neg': [], 'N_Chunks': []}\n",
    "    for i, (ri, ca) in enumerate(zip(frame_out['raw_input_list'], frame_out['conti_attr_list'])):\n",
    "        #subout beginnining <s> and end </s> tokens for ['BEGIN'] and ['END']\n",
    "        raw_input_i = ['[BEGIN]'if f == '<s>' else '[END]' if f == '</s>' else f for f in ri]\n",
    "        attr_appearance_cutoff = 5e-2\n",
    "        ca = ca.to(torch.float32)\n",
    "        \n",
    "        #filtering out by zeroing non-appearing features\n",
    "        ca_i = torch.where(torch.abs(ca) < attr_appearance_cutoff, torch.zeros(1), ca) \n",
    "        \n",
    "        #get positive and negative features\n",
    "        ca_i_pos = torch.where(ca_i > 0, ca_i, torch.zeros(1))\n",
    "        ca_i_neg = torch.where(ca_i < 0, ca_i, torch.zeros(1))\n",
    "        \n",
    "        try:\n",
    "            #get idx of pos/neg identified feature\n",
    "            ca_i_pos_idx = torch.nonzero(ca_i_pos).squeeze().numpy()\n",
    "            ca_i_neg_idx = torch.nonzero(ca_i_neg).squeeze().numpy() \n",
    "            #don't account for empty ''s or empty arrays\n",
    "            features_pos = [raw_input_i[idx] for idx in ca_i_pos_idx if ri[idx] != ''] \n",
    "            features_neg = [raw_input_i[idx] for idx in ca_i_neg_idx if ri[idx] != ''] \n",
    "        except TypeError: #TypeError: iteration over a 0-d array\n",
    "            #         print(f'i: {i}')\n",
    "            #         print(f'{ri}')\n",
    "            #         print(f'i: {raw_input_i}')\n",
    "            #         print(f'{ca}')\n",
    "            #         print(f'{ca_i}')\n",
    "            #         print(f'{ca_i_idx}')\n",
    "            #         print(f'features frame {features_frame}')\n",
    "            #         print(f'N_Chunks {N_Chunks}')\n",
    "            #         print(organized)\n",
    "            features_pos = []\n",
    "            features_neg = []\n",
    "            \n",
    "\n",
    "        \n",
    "            \n",
    "        organized['feats_pos'].append(features_pos)\n",
    "        organized['feats_neg'].append(features_neg)\n",
    "        \n",
    "        N_cs = len(features_pos) + len(features_neg)\n",
    "        organized['N_Chunks'].append(N_cs)\n",
    "        \n",
    "#      \n",
    "    frame_out.update(organized)\n",
    "    return frame_out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3418be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process frame_res to be used by calc_score\n",
    "def get_organized_frame_res(frame_res):\n",
    "    organized = {'yh': [], 'non_neg': [], 'non_pos': [], 'should_neg': [], 'should_pos': [], 'trust_numbers': []}\n",
    "    for x in frame_res.groupby('Input.stsb_number'):  # edit this groupby thing for different tasks\n",
    "        task_answers = x[1]['Answer.taskAnswers']\n",
    "        similarities, trusts = [], []\n",
    "        non_red_ins, non_green_ins, fiat_red_ins, fiat_green_ins = [], [], [], []\n",
    "        for answer_string in task_answers:  # edit this portion below to adapt\n",
    "            json_obj = json.loads(answer_string)[0]\n",
    "#             print(f'json obj {json_obj}')\n",
    "            similarity = json_obj['similarity'] if 'similarity' in json_obj else 2.5\n",
    "            similarity = 1 if float(similarity) > 2.5 else 0\n",
    "            similarities.append(similarity)\n",
    "            trust = json_obj['trust_number'] if 'trust_number' in json_obj else 0         \n",
    "            trusts.append(trust)\n",
    "            \n",
    "            if 'non_red_in' in json_obj.keys():\n",
    "                non_red_ins.append([k.strip() for k in json_obj['non_red_in'].split(',')])\n",
    "            else:\n",
    "                non_red_ins.append([])\n",
    "\n",
    "            if 'non_green_in' in json_obj.keys():\n",
    "                non_green_ins.append([k.strip() for k in json_obj['non_green_in'].split(',')])\n",
    "            else:\n",
    "                non_green_ins.append([])\n",
    "\n",
    "            if 'fiat_red_in' in json_obj.keys():\n",
    "                fiat_red_ins.append([k.strip() for k in json_obj['fiat_red_in'].split(',')])\n",
    "            else:\n",
    "                fiat_red_ins.append([])\n",
    "\n",
    "            if 'fiat_green_in' in json_obj.keys():\n",
    "                fiat_green_ins.append([k.strip() for k in json_obj['fiat_green_in'].split(',')])\n",
    "            else:\n",
    "                fiat_green_ins.append([])\n",
    "\n",
    "        organized['yh'].append(similarities)\n",
    "        organized['non_neg'].append(non_red_ins)\n",
    "        organized['non_pos'].append(non_green_ins)\n",
    "        organized['should_neg'].append(fiat_red_ins)\n",
    "        organized['should_pos'].append(fiat_green_ins)\n",
    "        organized['trust_numbers'].append(trusts)\n",
    "        \n",
    "    # see agreement rate of turks:\n",
    "    # assume 3 annotators\n",
    "        \n",
    "    annotation_triples = []\n",
    "    for i, y_res in enumerate(organized['yh'], start=1):\n",
    "        a1 = ('a1', str(i), y_res[0])\n",
    "        a2 = ('a2', str(i), y_res[1])\n",
    "        a3 = ('a3', str(i), y_res[2])\n",
    "        annotation_triples.append(a1)\n",
    "        annotation_triples.append(a2)\n",
    "        annotation_triples.append(a3)      \n",
    "    annotation_task = AnnotationTask(annotation_triples)\n",
    "    average_ao = annotation_task.avg_Ao()\n",
    "\n",
    "    return organized, average_ao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f258d339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metr1_simulatability(yh, yg, ym, beta_1=1, beta_2=1):    \n",
    "    loss_func = mean_absolute_error_loss\n",
    "    loss = cross_entropy_loss\n",
    "    l_yhyg = loss_func(yh, yg)\n",
    "    l_yhym = loss_func(yh, ym)\n",
    "    \n",
    "    denom = beta_1 * l_yhyg + beta_2 * l_yhym + 1\n",
    "    comp1 = (1/denom)\n",
    "    return comp1\n",
    "\n",
    "def metr1_wrapper(org_frame_out, org_frame_results):\n",
    "    metr1s = []\n",
    "    \n",
    "    yhs = org_frame_results['yh']\n",
    "    yms = np.round(org_frame_out['model_out_list'])\n",
    "    ygs = org_frame_out['targets']\n",
    "\n",
    "    yh_0, yh_1, yh_2 = [], [], [] #assume 3 annotaters\n",
    "    for yh in yhs:\n",
    "        yh_0.append(yh[0])\n",
    "        yh_1.append(yh[1])\n",
    "        yh_2.append(yh[2])\n",
    "    \n",
    "    annotations = [yh_0, yh_1, yh_2]\n",
    "    for yh in annotations:\n",
    "        metr1s.append(calc_metr1_simulatability(yh, ygs, yms))\n",
    "    print(np.mean(metr1s), metr1s)\n",
    "    return np.mean(metr1s), metr1s\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ae6a867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metr2_fidelity(feat_f_pos, feat_f_neg, feat_h_pos, feat_h_neg):\n",
    "    jaccard_pos = jaccard_similarity(feat_f_pos, feat_h_pos)\n",
    "    jaccard_neg = jaccard_similarity(feat_f_neg, feat_h_neg)\n",
    "    fidelity = np.mean([jaccard_pos, jaccard_neg])\n",
    "#     print(f'pos jaccard {jaccard_pos}')\n",
    "#     print(f'neg jaccard {jaccard_neg}')\n",
    "#     print(f'fidelity {fidelity}')\n",
    "    return fidelity \n",
    "\n",
    "def metr2_wrapper(org_frame_out, org_frame_results):\n",
    "    metr2s = []\n",
    "    for ff_pos, ff_neg, fh_nn_all, fh_np_all, fh_sn_all, fh_sp_all\\\n",
    "                            in zip(org_frame_out['feats_pos'], \n",
    "                               org_frame_out['feats_neg'], \n",
    "                               org_frame_results['non_neg'],\n",
    "                               org_frame_results['non_pos'],\n",
    "                               org_frame_results['should_neg'],\n",
    "                               org_frame_results['should_pos']):\n",
    "        metr2_annos = []\n",
    "        for fh_nn, fh_np, fh_sn, fh_sp\\\n",
    "                            in zip(fh_nn_all, fh_np_all, fh_sn_all, fh_sp_all):\n",
    "            fh_neg = set(ff_neg).difference(fh_nn).union(fh_sn)\n",
    "            fh_pos = set(ff_pos).difference(fh_nn).union(fh_sp)\n",
    "            \n",
    "            metr2_an = calc_metr2_fidelity(ff_pos, ff_neg, fh_pos, fh_neg)\n",
    "            metr2_annos.append(metr2_an)\n",
    "        metr2s.append(metr2_annos)\n",
    "    metr2s = np.array(metr2s)\n",
    "    metr2s_average = metr2s.mean(axis=1).mean(axis=0)\n",
    "    return metr2s_average, metr2s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "354db9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metr3_complexity(N_c):\n",
    "    if N_c == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1/(np.log(N_c)+1)\n",
    "\n",
    "def metr3_wrapper(org_frame_out, org_frame_results):\n",
    "    metr3s = []\n",
    "    N_Chunks = org_frame_out['N_Chunks']\n",
    "    for N_c in N_Chunks:\n",
    "        metr3 = calc_metr3_complexity(N_c)\n",
    "        metr3s.append(metr3)\n",
    "    metr3s_average = np.mean(metr3s)\n",
    "#     print(metr3s_average, metr3s)\n",
    "    return metr3s_average, metr3s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26997907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_m1m2m3(org_frame_out, org_frame_results):\n",
    "    m1, metric1s = metr1_wrapper(org_frame_out, org_frame_results)\n",
    "    m2, metric2s = metr2_wrapper(org_frame_out, org_frame_results)\n",
    "    m3, metric3s = metr3_wrapper(org_frame_out, org_frame_results)\n",
    "    return m1, m2, m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f4e5244",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def score_wrapper(frame_names=['deep_lift', 'guided_backprop', 'input_x_gradients', 'integrated_gradients', 'kernel_shap', 'lime']):\n",
    "    avg_aos = []\n",
    "    m1s, m2s, m3s = [], [], []\n",
    "    for frame_name in frame_names:\n",
    "        print(f'Framework processed: {frame_name}')\n",
    "        frame_out, frame_results = load_out_and_results_files(frame_name)\n",
    "        org_frame_results, avg_ao = get_organized_frame_res(frame_results)\n",
    "        avg_aos.append(avg_ao)\n",
    "        org_frame_out = get_organized_frame_out(frame_out)    \n",
    "        m1, m2, m3 = calc_m1m2m3(org_frame_out, org_frame_results)\n",
    "        m1s.append(m1)\n",
    "        m2s.append(m2)\n",
    "        m3s.append(m3)\n",
    "        print(f'm1: {m1:4f}, m2: {m2:4f}, m3: {m3:4f}')\n",
    "    print(f'average average agreement {np.mean(avg_aos):.2f}')\n",
    "    return frame_names, m1s, m2s, m3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8436936c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Framework processed: deep_lift\n",
      "0.16762823127291723 [0.1679722764473708, 0.1719582995572309, 0.16295411781414998]\n",
      "m1: 0.167628, m2: 0.736511, m3: 0.275904\n",
      "Framework processed: guided_backprop\n",
      "0.1646881977073654 [0.17231386924134376, 0.16047852398630413, 0.1612721998944483]\n",
      "m1: 0.164688, m2: 0.669615, m3: 0.243247\n",
      "Framework processed: input_x_gradients\n",
      "0.16314113039154496 [0.17066700491910095, 0.16099524954040628, 0.15776113671512756]\n",
      "m1: 0.163141, m2: 0.730964, m3: 0.275904\n",
      "Framework processed: integrated_gradients\n",
      "0.16102210858852564 [0.1702601955859047, 0.15889754612755, 0.1539085840521222]\n",
      "m1: 0.161022, m2: 0.391813, m3: 0.160254\n",
      "Framework processed: kernel_shap\n",
      "0.16428563082536954 [0.16161972982134606, 0.1723732739378948, 0.1588638887168677]\n",
      "m1: 0.164286, m2: 0.717572, m3: 0.255860\n",
      "Framework processed: lime\n",
      "0.1620254116889915 [0.16844384119179182, 0.16122019902375356, 0.15641219485142915]\n",
      "m1: 0.162025, m2: 0.632343, m3: 0.223920\n",
      "average average agreement 0.83\n"
     ]
    }
   ],
   "source": [
    "frame_names, m1s, m2s, m3s = score_wrapper(['deep_lift', 'guided_backprop', 'input_x_gradients', 'integrated_gradients', 'kernel_shap', 'lime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2307f6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\textbf{f} & 0.0559 & 0.2455 & 0.0920 & 0.3933 \\\\ deep_lift\n",
      "\\textbf{f} & 0.0549 & 0.2232 & 0.0811 & 0.3592 \\\\ guided_backprop\n",
      "\\textbf{f} & 0.0544 & 0.2437 & 0.0920 & 0.3900 \\\\ input_x_gradients\n",
      "\\textbf{f} & 0.0537 & 0.1306 & 0.0534 & 0.2377 \\\\ integrated_gradients\n",
      "\\textbf{f} & 0.0548 & 0.2392 & 0.0853 & 0.3792 \\\\ kernel_shap\n",
      "\\textbf{f} & 0.0540 & 0.2108 & 0.0746 & 0.3394 \\\\ lime\n"
     ]
    }
   ],
   "source": [
    "def see_1_3_alpha(frame_names, m1s, m2s, m3s):\n",
    "    for f, m1, m2, m3 in zip(frame_names, m1s, m2s, m3s):\n",
    "        m1_13 = m1 * (1/3)\n",
    "        m2_13 = m2 * (1/3)\n",
    "        m3_13 = m3 * (1/3)\n",
    "        score_13 = m1_13 + m2_13 + m3_13\n",
    "        print(F\"\\\\textbf{{f}} & {m1_13:.4f} & {m2_13:.4f} & {m3_13:.4f} & {score_13:.4f} \\\\\\\\ {f}\")\n",
    "\n",
    "see_1_3_alpha(frame_names, m1s, m2s, m3s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f1b2366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_alpha_combos():\n",
    "    import itertools\n",
    "    alphas = np.arange(0, 11, step=1, dtype=np.uint8)\n",
    "    all_combos = [(a/10,b/10,c/10) for (a,b,c) in itertools.product(alphas, alphas, alphas) if np.sum([a,b,c]) == 10]\n",
    "    all_combos.reverse()\n",
    "    return all_combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1646be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_combos = generate_alpha_combos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1106340b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_alphas(frame_names, m1s, m2s, m3s, alpha_combos):\n",
    "    scores_list = [] #indexed by the alpha combinations\n",
    "    for combo in alpha_combos:\n",
    "        a1, a2, a3 = combo[0], combo[1], combo[2]\n",
    "        scores_for_fs = []\n",
    "        for f, m1, m2, m3 in zip(frame_names, m1s, m2s, m3s):\n",
    "            a1m1, a2m2, a3m3 = a1 * m1, a2 * m2, a3 * m3\n",
    "            score = a1m1 + a2m2 + a3m3\n",
    "            scores_for_fs.append(score)      \n",
    "        scores_list.append([frame_names, scores_for_fs])\n",
    "    return scores_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5160ec09",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_list = apply_alphas(frame_names, m1s, m2s, m3s, alpha_combos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e56a5b2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def normalize_score_list(scores_list):\n",
    "    normalized_scores_list = []\n",
    "    from sklearn.preprocessing import normalize\n",
    "    def min_max_norm(scores):\n",
    "        norm_scores = (scores-np.min(scores))/(np.max(scores)-np.min(scores))\n",
    "        return norm_scores\n",
    "    \n",
    "    for (frame_names, scores) in scores_list:\n",
    "        scores = np.array(scores)\n",
    "#         normalized_scores = normalize([scores])[0]\n",
    "#         normalized_scores = scores / np.sum(scores)\n",
    "#         normalized_scores = min_max_norm(scores)\n",
    "#         print(f'after normalizing: {normalized_scores}\\n-------------------------------------')\n",
    "        normalized_scores_list.append([frame_names, normalized_scores])\n",
    "    return normalized_scores_list\n",
    "\n",
    "# scores_list = normalize_score_list(scores_list)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e25b9dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_scores(scores_list, alpha_combos):\n",
    "    frame_names = scores_list[0][0]\n",
    "    frame_scores = {}\n",
    "    for i in range(len(frame_names)):\n",
    "        frame_name = frame_names[i]\n",
    "        frame_scores[frame_name] = [scores_list[j][1][i] for j in range(len(scores_list))]\n",
    "    \n",
    "   \n",
    "    \n",
    "    #sort frames based on average scores\n",
    "    average_scores_dict = {}\n",
    "    for frame, frame_scores_list in frame_scores.items():\n",
    "        print(f'Average score for {frame}: {np.mean(frame_scores_list)}, std: {np.std(frame_scores_list)}')\n",
    "        average_scores_dict[frame] = np.mean(frame_scores_list)\n",
    "    sorted_average_scores_list =[[k, v] for k, v in sorted(average_scores_dict.items(), \n",
    "                                                          key=lambda item: item[1], reverse=True)]\n",
    "    print(f'sorted average scores {sorted_average_scores_list}')\n",
    "\n",
    "    ordered_frame_names = [k for [k,v] in sorted_average_scores_list]\n",
    "    #sort based on top frame\n",
    "    top_frame_name = ordered_frame_names[0]\n",
    "    print(f'top_frame_name {top_frame_name}')\n",
    "    sorted_idxs = np.argsort(frame_scores[top_frame_name])\n",
    "    sorted_frame_scores = {}\n",
    "    for frame in frame_names:\n",
    "        sorted_frame_scores[frame] = np.array(frame_scores[frame])[sorted_idxs]\n",
    "    \n",
    "    permuted_alphas = np.array(np.array(alpha_combos)[sorted_idxs])\n",
    "    a1_idx = np.where(permuted_alphas[:,0]==1)[0][0]\n",
    "    a2_idx = np.where(permuted_alphas[:,1]==1)[0][0]\n",
    "    a3_idx = np.where(permuted_alphas[:,2]==1)[0][0]\n",
    "    \n",
    "    \n",
    "    return sorted_frame_scores, a1_idx, a2_idx, a3_idx, ordered_frame_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14886024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score for deep_lift: 0.3933477476083399, std: 0.1406101957192756\n",
      "Average score for guided_backprop: 0.35918325640586224, std: 0.12646762951815255\n",
      "Average score for input_x_gradients: 0.3900029478797944, std: 0.13992890480926223\n",
      "Average score for integrated_gradients: 0.2376961574474313, std: 0.06212668586597922\n",
      "Average score for kernel_shap: 0.37923918657281225, std: 0.13804137409650583\n",
      "Average score for lime: 0.3394294894557374, std: 0.11895267522488624\n",
      "sorted average scores [['deep_lift', 0.3933477476083399], ['input_x_gradients', 0.3900029478797944], ['kernel_shap', 0.37923918657281225], ['guided_backprop', 0.35918325640586224], ['lime', 0.3394294894557374], ['integrated_gradients', 0.2376961574474313]]\n",
      "top_frame_name deep_lift\n"
     ]
    }
   ],
   "source": [
    "frame_scores, a1_idx, a2_idx, a3_idx, ordered_frame_names = get_frame_scores(scores_list, alpha_combos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d64501f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_graph_info(frame_scores, a1_idx, a2_idx, a3_idx, ordered_frame_names, task_name='STSB'):\n",
    "    out_dict = {\n",
    "        'task_name': task_name,\n",
    "        'frame_scores': frame_scores, \n",
    "        'a1_idx': a1_idx, \n",
    "        'a2_idx': a2_idx,\n",
    "        'a3_idx': a3_idx,\n",
    "        'ordered_frame_names': ordered_frame_names\n",
    "    }\n",
    "    out_file_name = f'{task_name}_graph.pkl'\n",
    "    with open(out_file_name, 'wb') as f:\n",
    "        pickle.dump(out_dict, f)\n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a8baba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_name': 'STSB',\n",
       " 'frame_scores': {'deep_lift': array([0.16762823, 0.17845578, 0.18928333, 0.20011087, 0.21093842,\n",
       "         0.22176597, 0.22451654, 0.23259351, 0.23534409, 0.24342106,\n",
       "         0.24617163, 0.25424861, 0.25699918, 0.26507615, 0.26782673,\n",
       "         0.2759037 , 0.27865427, 0.28140485, 0.28948182, 0.29223239,\n",
       "         0.30030937, 0.30305994, 0.31113691, 0.31388749, 0.32196446,\n",
       "         0.32471504, 0.33554258, 0.33829316, 0.34637013, 0.3491207 ,\n",
       "         0.35719768, 0.35994825, 0.36802522, 0.3707758 , 0.38160334,\n",
       "         0.39243089, 0.39518146, 0.40325844, 0.40600901, 0.41408598,\n",
       "         0.41683656, 0.4276641 , 0.43849165, 0.4493192 , 0.45206977,\n",
       "         0.46014674, 0.46289732, 0.47372486, 0.48455241, 0.49537996,\n",
       "         0.50620751, 0.50895808, 0.51978563, 0.53061317, 0.54144072,\n",
       "         0.55226827, 0.56584639, 0.57667393, 0.58750148, 0.59832903,\n",
       "         0.62273469, 0.63356224, 0.64438979, 0.679623  , 0.69045055,\n",
       "         0.73651131]),\n",
       "  'guided_backprop': array([0.1646882 , 0.17254404, 0.18039988, 0.18825572, 0.19611156,\n",
       "         0.2039674 , 0.21518088, 0.21182324, 0.22303672, 0.21967908,\n",
       "         0.23089256, 0.22753492, 0.2387484 , 0.23539076, 0.24660423,\n",
       "         0.2432466 , 0.25446007, 0.26567355, 0.26231591, 0.27352939,\n",
       "         0.27017175, 0.28138523, 0.27802759, 0.28924107, 0.28588343,\n",
       "         0.29709691, 0.30495275, 0.31616623, 0.31280859, 0.32402207,\n",
       "         0.32066443, 0.33187791, 0.32852027, 0.33973375, 0.34758959,\n",
       "         0.35544543, 0.36665891, 0.36330127, 0.37451475, 0.37115711,\n",
       "         0.38237059, 0.39022643, 0.39808227, 0.40593811, 0.41715159,\n",
       "         0.41379395, 0.42500743, 0.43286327, 0.44071911, 0.44857495,\n",
       "         0.45643079, 0.46764426, 0.4755001 , 0.48335594, 0.49121178,\n",
       "         0.49906762, 0.51813694, 0.52599278, 0.53384862, 0.54170446,\n",
       "         0.56862962, 0.57648546, 0.5843413 , 0.6191223 , 0.62697814,\n",
       "         0.66961498]),\n",
       "  'input_x_gradients': array([0.16314113, 0.17441739, 0.18569364, 0.1969699 , 0.20824616,\n",
       "         0.21952242, 0.21992342, 0.23079867, 0.23119968, 0.24207493,\n",
       "         0.24247593, 0.25335119, 0.25375219, 0.26462744, 0.26502845,\n",
       "         0.2759037 , 0.2763047 , 0.27670571, 0.28758096, 0.28798196,\n",
       "         0.29885722, 0.29925822, 0.31013348, 0.31053448, 0.32140973,\n",
       "         0.32181073, 0.33308699, 0.33348799, 0.34436325, 0.34476425,\n",
       "         0.35563951, 0.35604051, 0.36691576, 0.36731677, 0.37859302,\n",
       "         0.38986928, 0.39027028, 0.40114554, 0.40154654, 0.41242179,\n",
       "         0.4128228 , 0.42409905, 0.43537531, 0.44665157, 0.44705257,\n",
       "         0.45792783, 0.45832883, 0.46960509, 0.48088134, 0.4921576 ,\n",
       "         0.50343386, 0.50383486, 0.51511112, 0.52638737, 0.53766363,\n",
       "         0.54893989, 0.56061715, 0.5718934 , 0.58316966, 0.59444592,\n",
       "         0.61739944, 0.62867569, 0.63995195, 0.67418172, 0.68545798,\n",
       "         0.73096401]),\n",
       "  'integrated_gradients': array([0.16102211, 0.16094525, 0.16086839, 0.16079153, 0.16071467,\n",
       "         0.16063781, 0.18410118, 0.16056095, 0.18402432, 0.16048409,\n",
       "         0.18394746, 0.16040723, 0.1838706 , 0.16033037, 0.18379374,\n",
       "         0.16025351, 0.18371688, 0.20718026, 0.18364002, 0.2071034 ,\n",
       "         0.18356316, 0.20702654, 0.1834863 , 0.20694968, 0.18340944,\n",
       "         0.20687282, 0.20679596, 0.23025933, 0.2067191 , 0.23018247,\n",
       "         0.20664224, 0.23010561, 0.20656538, 0.23002875, 0.22995189,\n",
       "         0.22987503, 0.25333841, 0.22979817, 0.25326155, 0.22972131,\n",
       "         0.25318469, 0.25310783, 0.25303097, 0.25295411, 0.27641748,\n",
       "         0.25287725, 0.27634062, 0.27626376, 0.2761869 , 0.27611004,\n",
       "         0.27603318, 0.29949656, 0.2994197 , 0.29934284, 0.29926598,\n",
       "         0.29918912, 0.32257563, 0.32249877, 0.32242191, 0.32234505,\n",
       "         0.34565471, 0.34557785, 0.34550099, 0.36873378, 0.36865692,\n",
       "         0.39181286]),\n",
       "  'kernel_shap': array([0.16428563, 0.1734431 , 0.18260057, 0.19175804, 0.20091551,\n",
       "         0.21007298, 0.21961423, 0.21923045, 0.2287717 , 0.22838792,\n",
       "         0.23792917, 0.23754539, 0.24708664, 0.24670286, 0.25624411,\n",
       "         0.25586033, 0.26540158, 0.27494282, 0.27455905, 0.28410029,\n",
       "         0.28371652, 0.29325776, 0.29287399, 0.30241523, 0.30203146,\n",
       "         0.3115727 , 0.32073017, 0.33027142, 0.32988764, 0.33942889,\n",
       "         0.33904511, 0.34858636, 0.34820258, 0.35774383, 0.3669013 ,\n",
       "         0.37605877, 0.38560002, 0.38521624, 0.39475749, 0.39437371,\n",
       "         0.40391496, 0.41307243, 0.4222299 , 0.43138737, 0.44092861,\n",
       "         0.44054484, 0.45008608, 0.45924355, 0.46840102, 0.47755849,\n",
       "         0.48671596, 0.49625721, 0.50541468, 0.51457215, 0.52372962,\n",
       "         0.53288709, 0.55158581, 0.56074328, 0.56990075, 0.57905822,\n",
       "         0.6069144 , 0.61607187, 0.62522934, 0.662243  , 0.67140047,\n",
       "         0.7175716 ]),\n",
       "  'lime': array([0.16202541, 0.16821487, 0.17440434, 0.1805938 , 0.18678326,\n",
       "         0.19297273, 0.20905717, 0.19916219, 0.21524664, 0.20535165,\n",
       "         0.2214361 , 0.21154111, 0.22762556, 0.21773058, 0.23381502,\n",
       "         0.22392004, 0.24000449, 0.25608893, 0.24619395, 0.2622784 ,\n",
       "         0.25238341, 0.26846786, 0.25857287, 0.27465732, 0.26476234,\n",
       "         0.28084678, 0.28703625, 0.30312069, 0.29322571, 0.30931016,\n",
       "         0.29941517, 0.31549962, 0.30560463, 0.32168908, 0.32787854,\n",
       "         0.33406801, 0.35015245, 0.34025747, 0.35634192, 0.34644693,\n",
       "         0.36253138, 0.36872084, 0.37491031, 0.38109977, 0.39718421,\n",
       "         0.38728923, 0.40337368, 0.40956314, 0.4157526 , 0.42194207,\n",
       "         0.42813153, 0.44421598, 0.45040544, 0.4565949 , 0.46278436,\n",
       "         0.46897383, 0.49124774, 0.4974372 , 0.50362666, 0.50981612,\n",
       "         0.5382795 , 0.54446896, 0.55065842, 0.58531126, 0.59150072,\n",
       "         0.63234302])},\n",
       " 'a1_idx': 0,\n",
       " 'a2_idx': 65,\n",
       " 'a3_idx': 15,\n",
       " 'ordered_frame_names': ['deep_lift',\n",
       "  'input_x_gradients',\n",
       "  'kernel_shap',\n",
       "  'guided_backprop',\n",
       "  'lime',\n",
       "  'integrated_gradients']}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_graph_info(frame_scores, a1_idx, a2_idx, a3_idx, ordered_frame_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8589991",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
