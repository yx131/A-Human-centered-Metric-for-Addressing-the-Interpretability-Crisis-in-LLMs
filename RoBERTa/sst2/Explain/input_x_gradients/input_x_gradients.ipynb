{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "806fb4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, time, pickle, torch\n",
    "sys.path.insert(0, '../../Models')\n",
    "sys.path.insert(0, '../../Utils')\n",
    "sys.path.insert(0, '../../Preprocess')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from preload_models import get_sst2_tok_n_model\n",
    "from _utils import sample_random_glue_sst2, get_continuation_mapping, \\\n",
    "                    get_continuous_attributions, get_continuous_raw_inputs, \\\n",
    "                    collect_info_for_metric, save_info\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fb4d46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tens = torch.randn(size=(128, 50, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "774f9c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "tens2 = torch.randn(size=(1024,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94f3473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_stack = []\n",
    "for i in range(tens.shape[0]):\n",
    "    nu_i = torch.mv(tens[i], tens2.squeeze())\n",
    "    batch_stack.append(nu_i)\n",
    "\n",
    "batch_stack = torch.stack(batch_stack, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "812b47ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 50])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc4f5654",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas1 = torch.nn.functional.softmax(batch_stack, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "00a21b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 50])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c92ddd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1024])\n"
     ]
    }
   ],
   "source": [
    "attentioned_samples = []\n",
    "for sample_alphas, sample_hidden in zip(alphas, tens):\n",
    "    S_i = torch.mm(sample_alphas.unsqueeze(0), sample_hidden).squeeze(0)\n",
    "    attentioned_samples.append(S_i) \n",
    "attentioned_samples = torch.stack(attentioned_samples, dim=0)\n",
    "print(attentioned_samples.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "57506c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1024])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attentioned_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1ccb7f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "protos = torch.randn(size=(34, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9510602f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "betas shape: torch.Size([128, 34])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_372870/3368276438.py:4: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  beta_p = F.softmax(nu_P)\n"
     ]
    }
   ],
   "source": [
    "betas = []\n",
    "for phi_s in attentioned_samples:\n",
    "    nu_P = torch.sum(F.tanh(phi_s * protos), dim=1)\n",
    "    beta_p = F.softmax(nu_P)\n",
    "    betas.append(beta_p)\n",
    "    \n",
    "betas = torch.stack(betas, dim=0)\n",
    "print(f'betas shape: {betas.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ffbe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "tanned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd38a1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst2_data_raw, targets, idxs = sample_random_glue_sst2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90c47e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer, model = get_sst2_tok_n_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17be71bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define some containers to save some info\n",
    "model_out_list, raw_attr_list, conti_attr_list, raw_input_list = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d272625c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import InputXGradient\n",
    "from captum.attr import visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8067da5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x_gradient  = InputXGradient(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47d4631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_record(raw_review, target):\n",
    "    #tokenizer operations\n",
    "    tokenized = tokenizer(raw_review, truncation=True, return_offsets_mapping=True)\n",
    "    offset_mapping = tokenized['offset_mapping']\n",
    "    conti_map = get_continuation_mapping(offset_mapping)\n",
    "    input_ids = torch.tensor(tokenized['input_ids']).unsqueeze(0)\n",
    "    detokenized = [t.replace('Ä ', '') for t in tokenizer.convert_ids_to_tokens(input_ids[0])]\n",
    "    \n",
    "    #feeding input forward \n",
    "    input_emb = model.get_embeddings(input_ids)\n",
    "    pred_prob = model(input_emb).item()\n",
    "    \n",
    "    #categorizing results\n",
    "    pred_class = 'Pos' if pred_prob > 0.5 else 'Neg' \n",
    "    true_class = 'Pos' if target > 0.5 else 'Neg' \n",
    "    \n",
    "    #attribution algorithm working\n",
    "    attribution = input_x_gradient.attribute(input_emb)\n",
    "    word_attributions = attribution.squeeze(0).sum(dim=1)\n",
    "    word_attributions /= torch.norm(word_attributions)\n",
    "    attr_score = torch.sum(word_attributions)\n",
    "    attr_class = 'Pos' if attr_score > 0.5 else 'Neg'\n",
    "    convergence_score = None\n",
    "    \n",
    "    \n",
    "    #re-organizing tensors and arrays because words get split down\n",
    "    conti_attr = get_continuous_attributions(conti_map, word_attributions)\n",
    "    raw_input = get_continuous_raw_inputs(conti_map, detokenized)\n",
    "\n",
    "#     print(f'word attributions {word_attributions}')\n",
    "#     print(f'pred_prob {pred_prob}')\n",
    "#     print(f'pred_class {pred_class}')\n",
    "#     print(f'true_class {true_class}')\n",
    "#     print(f'attribution {attribution}')\n",
    "#     print(f'attr_class {attr_class}')\n",
    "#     print(f'attr_score {attr_score}')\n",
    "#     print(f'raw_input {raw_input}')\n",
    "\n",
    "        \n",
    "#     collect info for metrics later\n",
    "    collect_info_for_metric(model_out_list, pred_prob, raw_attr_list, attribution, conti_attr_list, conti_attr, raw_input_list, raw_input)\n",
    "        \n",
    "    \n",
    "    visual_record = visualization.VisualizationDataRecord(word_attributions=conti_attr,\n",
    "                                                         pred_prob=pred_prob,\n",
    "                                                         pred_class=pred_class,\n",
    "                                                         true_class=true_class,\n",
    "                                                         attr_class=attr_class,\n",
    "                                                         attr_score=attr_score,\n",
    "                                                         raw_input=raw_input,\n",
    "                                                         convergence_score=convergence_score)\n",
    "        \n",
    "        \n",
    "    return visual_record\n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37efa6df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, (datum_raw, target) in enumerate(zip(sst2_data_raw, targets), start=1):\n",
    "    print(f'Raw review: {datum_raw}')\n",
    "    print(f'GT target: {target}')\n",
    "    visual_record=generate_record(datum_raw, target)\n",
    "    print(visualization.visualize_text([visual_record]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6344a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_info(idxs, sst2_data_raw, targets, model_out_list, raw_attr_list, conti_attr_list, raw_input_list, fname='input_x_gradients.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4c3622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
