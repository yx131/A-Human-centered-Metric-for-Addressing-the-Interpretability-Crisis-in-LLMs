{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "733ed20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from sklearn.metrics import log_loss, mean_absolute_error, mean_squared_error\n",
    "from nltk.metrics.agreement import AnnotationTask\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4949403d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_mi_loss(y_true, y_pred):\n",
    "    return 1 - normalized_mutual_info_score(y_true, np.round(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58deb599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(y_true, y_pred):\n",
    "#     return mean_squared_error(y_true, y_pred)\n",
    "    try:\n",
    "        return log_loss(y_true, y_pred, labels=[0,1])\n",
    "    except ValueError:\n",
    "        print(f'y_true {y_true}')\n",
    "        print(f'y_pred {y_pred}')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fcc493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(l1, l2):  #expected two lists of words or two sets of words\n",
    "    l1, l2 = set(l1), set(l2)\n",
    "    intersection = l1.intersection(l2)\n",
    "    union = l1.union(l2)\n",
    "    try:\n",
    "        return float(len(intersection)) / len(union)\n",
    "    except ZeroDivisionError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9307b9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_out_and_results_files(frame_name):\n",
    "    frame_out_name = f'{frame_name}_out.pkl'\n",
    "    frame_res_name =  f'{frame_name}_results.csv'\n",
    "    frame_out = {}\n",
    "    with open(f'{frame_out_name}', 'rb') as f:\n",
    "        frame_out = pickle.load(f)\n",
    "    frame_res = pd.read_csv(f'{frame_res_name}')\n",
    "#     print(f'{frame_res.columns}')\n",
    "    return frame_out, frame_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "292850cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#process frame_out's information to be used by calc score\n",
    "def get_organized_frame_out(frame_out):\n",
    "    #get features (words)\n",
    "    organized = {'feats_pos': [], 'feats_neg': [], 'N_Chunks': []}\n",
    "    for i, (ri, ca) in enumerate(zip(frame_out['raw_input_list'], frame_out['conti_attr_list'])):\n",
    "        #subout beginnining <s> and end </s> tokens for ['BEGIN'] and ['END']\n",
    "        raw_input_i = ['[BEGIN]'if f == '<s>' else '[END]' if f == '</s>' else f for f in ri]\n",
    "        attr_appearance_cutoff = 5e-2\n",
    "        ca = ca.to(torch.float32)\n",
    "        \n",
    "        #filtering out by zeroing non-appearing features\n",
    "        ca_i = torch.where(torch.abs(ca) < attr_appearance_cutoff, torch.zeros(1), ca) \n",
    "        \n",
    "        #get positive and negative features\n",
    "        ca_i_pos = torch.where(ca_i > 0, ca_i, torch.zeros(1))\n",
    "        ca_i_neg = torch.where(ca_i < 0, ca_i, torch.zeros(1))\n",
    "        \n",
    "        try:\n",
    "            #get idx of pos/neg identified feature\n",
    "            ca_i_pos_idx = torch.nonzero(ca_i_pos).squeeze().numpy()\n",
    "            ca_i_neg_idx = torch.nonzero(ca_i_neg).squeeze().numpy() \n",
    "            #don't account for empty ''s or empty arrays\n",
    "            features_pos = [raw_input_i[idx] for idx in ca_i_pos_idx if ri[idx] != ''] \n",
    "            features_neg = [raw_input_i[idx] for idx in ca_i_neg_idx if ri[idx] != ''] \n",
    "        except TypeError: #TypeError: iteration over a 0-d array\n",
    "            #         print(f'i: {i}')\n",
    "            #         print(f'{ri}')\n",
    "            #         print(f'i: {raw_input_i}')\n",
    "            #         print(f'{ca}')\n",
    "            #         print(f'{ca_i}')\n",
    "            #         print(f'{ca_i_idx}')\n",
    "            #         print(f'features frame {features_frame}')\n",
    "            #         print(f'N_Chunks {N_Chunks}')\n",
    "            #         print(organized)\n",
    "            features_pos = []\n",
    "            features_neg = []\n",
    "            \n",
    "\n",
    "        \n",
    "            \n",
    "        organized['feats_pos'].append(features_pos)\n",
    "        organized['feats_neg'].append(features_neg)\n",
    "        \n",
    "        N_cs = len(features_pos) + len(features_neg)\n",
    "        organized['N_Chunks'].append(N_cs)\n",
    "        \n",
    "#      \n",
    "    frame_out.update(organized)\n",
    "    return frame_out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3418be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process frame_res to be used by calc_score\n",
    "def get_organized_frame_res(frame_res):\n",
    "    organized = {'yh': [], 'non_neg': [], 'non_pos': [], 'should_neg': [], 'should_pos': []}\n",
    "    for x in frame_res.groupby('Input.sst2_number'):  # edit this groupby thing for different tasks\n",
    "        task_answers = x[1]['Answer.taskAnswers']\n",
    "        sentiments = []\n",
    "        non_red_ins, non_green_ins, fiat_red_ins, fiat_green_ins = [], [], [], []\n",
    "        for answer_string in task_answers:  # edit this portion below to adapt\n",
    "            json_obj = json.loads(answer_string)[0]\n",
    "            senti = 1 if json_obj['sentiment_radio']['1'] else 0\n",
    "            sentiments.append(senti)\n",
    "\n",
    "            if 'non_red_in' in json_obj.keys():\n",
    "                non_red_ins.append([k.strip() for k in json_obj['non_red_in'].split(',')])\n",
    "            else:\n",
    "                non_red_ins.append([])\n",
    "\n",
    "            if 'non_green_in' in json_obj.keys():\n",
    "                non_green_ins.append([k.strip() for k in json_obj['non_green_in'].split(',')])\n",
    "            else:\n",
    "                non_green_ins.append([])\n",
    "\n",
    "            if 'fiat_red_in' in json_obj.keys():\n",
    "                fiat_red_ins.append([k.strip() for k in json_obj['fiat_red_in'].split(',')])\n",
    "            else:\n",
    "                fiat_red_ins.append([])\n",
    "\n",
    "            if 'fiat_green_in' in json_obj.keys():\n",
    "                fiat_green_ins.append([k.strip() for k in json_obj['fiat_green_in'].split(',')])\n",
    "            else:\n",
    "                fiat_green_ins.append([])\n",
    "\n",
    "        organized['yh'].append(sentiments)\n",
    "        organized['non_neg'].append(non_red_ins)\n",
    "        organized['non_pos'].append(non_green_ins)\n",
    "        organized['should_neg'].append(fiat_red_ins)\n",
    "        organized['should_pos'].append(fiat_green_ins)\n",
    "\n",
    "    # see agreement rate of turks:\n",
    "    # assume 3 annotators\n",
    "        \n",
    "    annotation_triples = []\n",
    "    for i, senti in enumerate(organized['yh'], start=1):\n",
    "        a1 = ('a1', str(i), senti[0])\n",
    "        a2 = ('a2', str(i), senti[1])\n",
    "        a3 = ('a3', str(i), senti[2])\n",
    "        annotation_triples.append(a1)\n",
    "        annotation_triples.append(a2)\n",
    "        annotation_triples.append(a3)      \n",
    "    annotation_task = AnnotationTask(annotation_triples)\n",
    "    average_ao = annotation_task.avg_Ao()\n",
    "\n",
    "    return organized, average_ao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f258d339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metr1_simulatability(yh, yg, ym, beta_1=1, beta_2=1):    \n",
    "    loss_func = cross_entropy_loss\n",
    "#     loss_func = normalized_mi_loss\n",
    "\n",
    "    l_yhyg = loss_func(yh, yg)\n",
    "    l_yhym = loss_func(yh, ym)\n",
    "    print(yh, yg, l_yhyg, l_yhym)\n",
    "    \n",
    "    denom = beta_1 * l_yhyg + beta_2 * l_yhym + 1\n",
    "    comp1 = (1/denom)\n",
    "    return comp1\n",
    "\n",
    "def metr1_wrapper(org_frame_out, org_frame_results):\n",
    "    metr1s = []\n",
    "    \n",
    "    yhs = org_frame_results['yh']\n",
    "    yms = np.round(org_frame_out['model_out_list'])\n",
    "    ygs = org_frame_out['targets']\n",
    "\n",
    "    yh_0, yh_1, yh_2 = [], [], [] #assume 3 annotaters\n",
    "    for yh in yhs:\n",
    "        yh_0.append(yh[0])\n",
    "        yh_1.append(yh[1])\n",
    "        yh_2.append(yh[2])\n",
    "    \n",
    "    annotations = [yh_0, yh_1, yh_2]\n",
    "    for yh in annotations:\n",
    "        metr1s.append(calc_metr1_simulatability(yh, ygs, yms))\n",
    "#     print(np.mean(metr1s), metr1s)\n",
    "    return np.mean(metr1s), metr1s\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ae6a867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metr2_fidelity(feat_f_pos, feat_f_neg, feat_h_pos, feat_h_neg):\n",
    "    jaccard_pos = jaccard_similarity(feat_f_pos, feat_h_pos)\n",
    "    jaccard_neg = jaccard_similarity(feat_f_neg, feat_h_neg)\n",
    "    fidelity = np.mean([jaccard_pos, jaccard_neg])\n",
    "#     print(f'pos jaccard {jaccard_pos}')\n",
    "#     print(f'neg jaccard {jaccard_neg}')\n",
    "#     print(f'fidelity {fidelity}')\n",
    "    return fidelity \n",
    "\n",
    "def metr2_wrapper(org_frame_out, org_frame_results):\n",
    "    metr2s = []\n",
    "    for ff_pos, ff_neg, fh_nn_all, fh_np_all, fh_sn_all, fh_sp_all\\\n",
    "                            in zip(org_frame_out['feats_pos'], \n",
    "                               org_frame_out['feats_neg'], \n",
    "                               org_frame_results['non_neg'],\n",
    "                               org_frame_results['non_pos'],\n",
    "                               org_frame_results['should_neg'],\n",
    "                               org_frame_results['should_pos']):\n",
    "        metr2_annos = []\n",
    "        for fh_nn, fh_np, fh_sn, fh_sp\\\n",
    "                            in zip(fh_nn_all, fh_np_all, fh_sn_all, fh_sp_all):\n",
    "            fh_neg = set(ff_neg).difference(fh_nn).union(fh_sn)\n",
    "            fh_pos = set(ff_pos).difference(fh_nn).union(fh_sp)\n",
    "            \n",
    "            metr2_an = calc_metr2_fidelity(ff_pos, ff_neg, fh_pos, fh_neg)\n",
    "            metr2_annos.append(metr2_an)\n",
    "        metr2s.append(metr2_annos)\n",
    "    metr2s = np.array(metr2s)\n",
    "    metr2s_average = metr2s.mean(axis=1).mean(axis=0)\n",
    "    return metr2s_average, metr2s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "354db9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metr3_complexity(N_c):\n",
    "    if N_c == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1/(np.log(N_c)+1)\n",
    "\n",
    "def metr3_wrapper(org_frame_out, org_frame_results):\n",
    "    metr3s = []\n",
    "    N_Chunks = org_frame_out['N_Chunks']\n",
    "    for N_c in N_Chunks:\n",
    "        metr3 = calc_metr3_complexity(N_c)\n",
    "        metr3s.append(metr3)\n",
    "    metr3s_average = np.mean(metr3s)\n",
    "#     print(metr3s_average, metr3s)\n",
    "    return metr3s_average, metr3s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26997907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_m1m2m3(org_frame_out, org_frame_results):\n",
    "    m1, metric1s = metr1_wrapper(org_frame_out, org_frame_results)\n",
    "    m2, metric2s = metr2_wrapper(org_frame_out, org_frame_results)\n",
    "    m3, metric3s = metr3_wrapper(org_frame_out, org_frame_results)\n",
    "    return m1, m2, m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f4e5244",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def score_wrapper(frame_names=['deep_lift', 'guided_backprop', 'input_x_gradients', 'integrated_gradients', 'kernel_shap', 'lime']):\n",
    "    avg_aos = []\n",
    "    m1s, m2s, m3s = [], [], []\n",
    "    for frame_name in frame_names:\n",
    "        print(f'Framework processed: {frame_name}')\n",
    "        frame_out, frame_results = load_out_and_results_files(frame_name)\n",
    "        org_frame_results, avg_ao = get_organized_frame_res(frame_results)\n",
    "        avg_aos.append(avg_ao)\n",
    "        org_frame_out = get_organized_frame_out(frame_out)    \n",
    "        m1, m2, m3 = calc_m1m2m3(org_frame_out, org_frame_results)\n",
    "        m1s.append(m1)\n",
    "        m2s.append(m2)\n",
    "        m3s.append(m3)\n",
    "        print(f'm1: {m1:4f}, m2: {m2:4f}, m3: {m3:4f}')\n",
    "    print(f'average average agreement {np.mean(avg_aos):.2f}')\n",
    "    return frame_names, m1s, m2s, m3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8436936c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Framework processed: deep_lift\n",
      "[1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0] [1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0] 7.598642750520578 6.907867222622364\n",
      "[1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1] [1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0] 13.815606509655895 14.506398029502712\n",
      "[1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0] [1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0] 0.6907755278982145 1.3815670477450324\n",
      "m1: 0.141359, m2: 0.729053, m3: 0.320205\n",
      "Framework processed: guided_backprop\n",
      "[1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0] [1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0] 5.526268190980126 6.217059710826943\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1] [1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0] 13.815606509655895 13.124830981757682\n",
      "[1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1] [1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0] 1.3815670477450324 2.07235856759185\n",
      "m1: 0.112928, m2: 0.535154, m3: 0.241420\n",
      "Framework processed: input_x_gradients\n",
      "[1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0] [1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0] 4.144733127132302 4.8355246469791195\n",
      "[1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] [1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0] 17.96024368509657 17.269468157198357\n",
      "[1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0] [1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0] 0.6907915198468184 1.381583039693636\n",
      "m1: 0.151094, m2: 0.738490, m3: 0.320205\n",
      "Framework processed: integrated_gradients\n",
      "[1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0] [1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0] 7.598642750520578 8.289434270367394\n",
      "[1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1] [1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0] 13.815638493553104 14.506430013399923\n",
      "[1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0] [1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0] 9.992007221626415e-16 0.6907915198468185\n",
      "m1: 0.228252, m2: 0.509369, m3: 0.243131\n",
      "Framework processed: kernel_shap\n",
      "[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0] [1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0] 8.289434270367394 8.980225790214213\n",
      "[0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1] [1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0] 13.815670477450313 13.124894949552099\n",
      "[1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0] [1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0] 2.0723745595404535 2.763166079387271\n",
      "m1: 0.087297, m2: 0.766518, m3: 0.318820\n",
      "Framework processed: lime\n",
      "[1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0] [1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0] 13.815622501604501 13.124846973706287\n",
      "[1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0] [1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0] 2.7631660793872714 3.453957599234089\n",
      "[1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0] [1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0] 1.381583039693636 2.0723745595404535\n",
      "m1: 0.132956, m2: 0.517804, m3: 0.251756\n",
      "average average agreement 0.65\n"
     ]
    }
   ],
   "source": [
    "frame_names, m1s, m2s, m3s = score_wrapper(['deep_lift', 'guided_backprop', 'input_x_gradients', 'integrated_gradients', 'kernel_shap', 'lime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e177012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\textbf{f} & 0.0471 & 0.2430 & 0.1067 & 0.3969 \\\\ deep_lift\n",
      "\\textbf{f} & 0.0376 & 0.1784 & 0.0805 & 0.2965 \\\\ guided_backprop\n",
      "\\textbf{f} & 0.0504 & 0.2462 & 0.1067 & 0.4033 \\\\ input_x_gradients\n",
      "\\textbf{f} & 0.0761 & 0.1698 & 0.0810 & 0.3269 \\\\ integrated_gradients\n",
      "\\textbf{f} & 0.0291 & 0.2555 & 0.1063 & 0.3909 \\\\ kernel_shap\n",
      "\\textbf{f} & 0.0443 & 0.1726 & 0.0839 & 0.3008 \\\\ lime\n"
     ]
    }
   ],
   "source": [
    "def see_1_3_alpha(frame_names, m1s, m2s, m3s):\n",
    "    for f, m1, m2, m3 in zip(frame_names, m1s, m2s, m3s):\n",
    "        m1_13 = m1 * (1/3)\n",
    "        m2_13 = m2 * (1/3)\n",
    "        m3_13 = m3 * (1/3)\n",
    "        score_13 = m1_13 + m2_13 + m3_13\n",
    "        print(F\"\\\\textbf{{f}} & {m1_13:.4f} & {m2_13:.4f} & {m3_13:.4f} & {score_13:.4f} \\\\\\\\ {f}\")\n",
    "\n",
    "see_1_3_alpha(frame_names, m1s, m2s, m3s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f1b2366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_alpha_combos():\n",
    "    import itertools\n",
    "    alphas = np.arange(0, 11, step=1, dtype=np.uint8)\n",
    "    all_combos = [(a/10,b/10,c/10) for (a,b,c) in itertools.product(alphas, alphas, alphas) if np.sum([a,b,c]) == 10]\n",
    "    #reverse all_combos\n",
    "    all_combos.reverse()\n",
    "    return all_combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1646be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_combos = generate_alpha_combos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1106340b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_alphas(frame_names, m1s, m2s, m3s, alpha_combos):\n",
    "    scores_list = [] #indexed by the alpha combinations\n",
    "    for combo in alpha_combos:\n",
    "        a1, a2, a3 = combo[0], combo[1], combo[2]\n",
    "        scores_for_fs = []\n",
    "        for f, m1, m2, m3 in zip(frame_names, m1s, m2s, m3s):\n",
    "            a1m1, a2m2, a3m3 = a1 * m1, a2 * m2, a3 * m3\n",
    "            score = a1m1 + a2m2 + a3m3\n",
    "            scores_for_fs.append(score)      \n",
    "        scores_list.append([frame_names, scores_for_fs])\n",
    "    return scores_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5160ec09",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_list = apply_alphas(frame_names, m1s, m2s, m3s, alpha_combos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e56a5b2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# def normalize_score_list(scores_list):\n",
    "#     normalized_scores_list = []\n",
    "#     from sklearn.preprocessing import normalize\n",
    "#     def min_max_norm(scores):\n",
    "#         norm_scores = (scores-np.min(scores))/(np.max(scores)-np.min(scores))\n",
    "#         return norm_scores\n",
    "    \n",
    "#     for (frame_names, scores) in scores_list:\n",
    "#         scores = np.array(scores)\n",
    "# #         normalized_scores = normalize([scores])[0]\n",
    "# #         normalized_scores = scores / np.sum(scores)\n",
    "#         normalized_scores = min_max_norm(scores)\n",
    "# #         print(f'after normalizing: {normalized_scores}\\n-------------------------------------')\n",
    "#         normalized_scores_list.append([frame_names, normalized_scores])\n",
    "#     return normalized_scores_list\n",
    "\n",
    "# scores_list = normalize_score_list(scores_list)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb0fe0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_scores(scores_list, alpha_combos):\n",
    "    frame_names = scores_list[0][0]\n",
    "    frame_scores = {}\n",
    "    for i in range(len(frame_names)):\n",
    "        frame_name = frame_names[i]\n",
    "        frame_scores[frame_name] = [scores_list[j][1][i] for j in range(len(scores_list))]\n",
    "    \n",
    "   \n",
    "    \n",
    "    #sort frames based on average scores\n",
    "    average_scores_dict = {}\n",
    "    for frame, frame_scores_list in frame_scores.items():\n",
    "        print(f'Average score for {frame}: {np.mean(frame_scores_list)}, std: {np.std(frame_scores_list)}')\n",
    "        average_scores_dict[frame] = np.mean(frame_scores_list)\n",
    "    sorted_average_scores_list =[[k, v] for k, v in sorted(average_scores_dict.items(), \n",
    "                                                          key=lambda item: item[1], reverse=True)]\n",
    "    print(f'sorted average scores {sorted_average_scores_list}')\n",
    "\n",
    "    ordered_frame_names = [k for [k,v] in sorted_average_scores_list]\n",
    "    #sort based on top frame\n",
    "    top_frame_name = ordered_frame_names[0]\n",
    "    print(f'top_frame_name {top_frame_name}')\n",
    "    sorted_idxs = np.argsort(frame_scores[top_frame_name])\n",
    "    sorted_frame_scores = {}\n",
    "    for frame in frame_names:\n",
    "        sorted_frame_scores[frame] = np.array(frame_scores[frame])[sorted_idxs]\n",
    "    \n",
    "    permuted_alphas = np.array(np.array(alpha_combos)[sorted_idxs])\n",
    "    a1_idx = np.where(permuted_alphas[:,0]==1)[0][0]\n",
    "    a2_idx = np.where(permuted_alphas[:,1]==1)[0][0]\n",
    "    a3_idx = np.where(permuted_alphas[:,2]==1)[0][0]\n",
    "    \n",
    "    \n",
    "    return sorted_frame_scores, a1_idx, a2_idx, a3_idx, ordered_frame_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fab0f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score for deep_lift: 0.39687235533397397, std: 0.14022648230580823\n",
      "Average score for guided_backprop: 0.2965005900629861, std: 0.10074505842962399\n",
      "Average score for input_x_gradients: 0.40326281885313825, std: 0.1407494709018223\n",
      "Average score for integrated_gradients: 0.3269174591340922, std: 0.07363006464432033\n",
      "Average score for kernel_shap: 0.3908783973524882, std: 0.1607269017494883\n",
      "Average score for lime: 0.30083882738174844, std: 0.09172773480152567\n",
      "sorted average scores [['input_x_gradients', 0.40326281885313825], ['deep_lift', 0.39687235533397397], ['kernel_shap', 0.3908783973524882], ['integrated_gradients', 0.3269174591340922], ['lime', 0.30083882738174844], ['guided_backprop', 0.2965005900629861]]\n",
      "top_frame_name input_x_gradients\n"
     ]
    }
   ],
   "source": [
    "frame_scores, a1_idx, a2_idx, a3_idx, ordered_frame_names = get_frame_scores(scores_list, alpha_combos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bf1f6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_x_gradients',\n",
       " 'deep_lift',\n",
       " 'kernel_shap',\n",
       " 'integrated_gradients',\n",
       " 'lime',\n",
       " 'guided_backprop']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def output_graph_info(frame_scores, a1_idx, a2_idx, a3_idx, ordered_frame_names, name='sst2.pkl'):\n",
    "    out_dict = {\n",
    "        'frame_scores': frame_scores, \n",
    "        'a1_idx': a1_idx, \n",
    "        'a2_idx': a2_idx,\n",
    "        'a3_idx': a3_idx,\n",
    "        'ordered_frame_names': ordered_frame_names\n",
    "    }\n",
    "    with open(name, 'wb') as f:\n",
    "        pickle.dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a7df50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
