{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "806fb4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, time, pickle, torch\n",
    "sys.path.insert(0, '../../Models')\n",
    "sys.path.insert(0, '../../Utils')\n",
    "sys.path.insert(0, '../../Preprocess')\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import RobertaTokenizerFast, RobertaForSequenceClassification\n",
    "from _utils import sample_random_glue_sst2, get_continuation_mapping, get_continuous_attributions, get_continuous_raw_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb1e2bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/user/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "130a8f77a9364a68b7361da292388dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/user/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-3b24abff24d1d8c0.arrow\n",
      "Loading cached processed dataset at /home/user/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-5960909ab3834668.arrow\n"
     ]
    }
   ],
   "source": [
    "reviews_raw, targets, idxs = sample_random_glue_sst2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a505f205",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained('siebert/sentiment-roberta-large-english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b148ff4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_Wrapper(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model_Wrapper, self).__init__()\n",
    "        self.model = RobertaForSequenceClassification.from_pretrained('siebert/sentiment-roberta-large-english')\n",
    "    \n",
    "    def get_embeddings(self, input_ids):\n",
    "        return self.model.roberta.embeddings(input_ids)\n",
    "    \n",
    "    def forward(self, embeddings):        \n",
    "        encoder_outputs = self.model.roberta.encoder(embeddings)\n",
    "        sequence_output = encoder_outputs[0]\n",
    "#         pooled_output = self.model.roberta.pooler(sequence_output) if self.model.roberta.pooler is not None else None\n",
    "#         roberta_outputs = (sequence_output, pooled_output) + encoder_outputs[1:]\n",
    "        \n",
    "        logits = self.model.classifier(sequence_output)\n",
    "#         print(f'logits {logits} {logits.size()} {logits.dtype} {logits.requires_grad}')\n",
    "        pred_prob = torch.softmax(logits, dim=1)[:, 1]\n",
    "        #get the item at idx 1 because it corresponds to probability of being positive\n",
    "        \n",
    "        return pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0337b4cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Model_Wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17be71bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define some containers to save some info\n",
    "model_out_list, attr_list, wrd_attr_list = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d272625c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import DeepLift\n",
    "from captum.attr import visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8067da5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lime = Lime(forward_func=model.forward)\n",
    "deep_lift = DeepLift(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e160ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c47d4631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_record(raw_review, target):\n",
    "    #tokenizer operations\n",
    "    tokenized = tokenizer(raw_review, truncation=True, return_offsets_mapping=True)\n",
    "    offset_mapping = tokenized['offset_mapping']\n",
    "    conti_map = get_continuation_mapping(offset_mapping)\n",
    "    input_ids = torch.tensor(tokenized['input_ids']).unsqueeze(0)\n",
    "    detokenized = [t.replace('Ä ', '') for t in tokenizer.convert_ids_to_tokens(input_ids[0])]\n",
    "    \n",
    "    #feeding input forward \n",
    "    input_emb = model.get_embeddings(input_ids)\n",
    "    pred_prob = model(input_emb).item()\n",
    "    \n",
    "    #categorizing results\n",
    "    pred_class = 'Pos' if pred_prob > 0.5 else 'Neg' \n",
    "    true_class = 'Pos' if target > 0.5 else 'Neg' \n",
    "    \n",
    "    #attribution algorithm working\n",
    "    attribution, delta = deep_lift.attribute(input_emb, return_convergence_delta=True)\n",
    "    word_attributions = attribution.squeeze(0).sum(dim=1)\n",
    "    word_attributions /= torch.norm(word_attributions)\n",
    "    attr_score = torch.sum(word_attributions)\n",
    "    attr_class = 'Pos' if attr_score > 0.5 else 'Neg'\n",
    "    convergence_score = delta\n",
    "    \n",
    "    \n",
    "    #re-organizing tensors and arrays because words get split down\n",
    "    conti_attr = get_continuous_attributions(conti_map, word_attributions)\n",
    "    raw_input = get_continuous_raw_inputs(conti_map, detokenized)\n",
    "\n",
    "#     print(f'word attributions {word_attributions}')\n",
    "#     print(f'pred_prob {pred_prob}')\n",
    "#     print(f'pred_class {pred_class}')\n",
    "#     print(f'true_class {true_class}')\n",
    "#     print(f'attribution {attribution}')\n",
    "#     print(f'attr_class {attr_class}')\n",
    "#     print(f'attr_score {attr_score}')\n",
    "#     print(f'raw_input {raw_input}')\n",
    "\n",
    "        \n",
    "#     collect info for metrics later\n",
    "#     collect_info_for_metric(model_out_list, pred_prob, attr_list, attribution, wrd_attr_list, wrd_attr_dict)\n",
    "        \n",
    "    \n",
    "    visual_record = visualization.VisualizationDataRecord(word_attributions=word_attributions,\n",
    "                                                         pred_prob=pred_prob,\n",
    "                                                         pred_class=pred_class,\n",
    "                                                         true_class=true_class,\n",
    "                                                         attr_class=attr_class,\n",
    "                                                         attr_score=attr_score,\n",
    "                                                         raw_input=raw_input,\n",
    "                                                         convergence_score=convergence_score)\n",
    "        \n",
    "        \n",
    "    return visual_record\n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37efa6df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw review: against all odds \n",
      "GT target: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/py38/lib/python3.9/site-packages/captum/attr/_core/deep_lift.py:322: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asd 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>Pos</b></text></td><td><text style=\"padding-right:2em\"><b>Pos (0.99)</b></text></td><td><text style=\"padding-right:2em\"><b>Neg</b></text></td><td><text style=\"padding-right:2em\"><b>-0.45</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 78%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #s                    </font></mark><mark style=\"background-color: hsl(0, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> against                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> all                    </font></mark><mark style=\"background-color: hsl(120, 75%, 65%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> odds                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">                     </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #/s                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n"
     ]
    }
   ],
   "source": [
    "for i, (rev_raw, target) in enumerate(zip(reviews_raw, targets), start=1):\n",
    "    print(f'Raw review: {rev_raw}')\n",
    "    print(f'GT target: {target}')\n",
    "    visual_record=generate_record(rev_raw, target)\n",
    "    print(visualization.visualize_text([visual_record]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6344a01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
